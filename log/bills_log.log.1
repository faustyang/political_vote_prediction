2017-08-18 08:41:31,745 - Task:Scrapy_bills - INFO - The number of the search result is:403644
2017-08-18 08:44:03,111 - Task:Scrapy_bills - INFO - The work on page20 has finished.
2017-08-18 08:46:33,559 - Task:Scrapy_bills - INFO - The work on page21 has finished.
2017-08-18 08:49:05,469 - Task:Scrapy_bills - INFO - The work on page22 has finished.
2017-08-18 08:51:53,800 - Task:Scrapy_bills - INFO - The work on page23 has finished.
2017-08-18 08:54:25,787 - Task:Scrapy_bills - INFO - The work on page24 has finished.
2017-08-18 08:56:57,174 - Task:Scrapy_bills - INFO - The work on page25 has finished.
2017-08-18 08:59:29,117 - Task:Scrapy_bills - INFO - The work on page26 has finished.
2017-08-18 09:02:00,781 - Task:Scrapy_bills - INFO - The work on page27 has finished.
2017-08-18 09:04:32,444 - Task:Scrapy_bills - INFO - The work on page28 has finished.
2017-08-18 09:07:05,086 - Task:Scrapy_bills - INFO - The work on page29 has finished.
2017-08-18 09:07:05,927 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation21-30.txt
2017-08-18 09:09:40,300 - Task:Scrapy_bills - INFO - The work on page30 has finished.
2017-08-18 09:12:12,282 - Task:Scrapy_bills - INFO - The work on page31 has finished.
2017-08-18 09:14:44,041 - Task:Scrapy_bills - INFO - The work on page32 has finished.
2017-08-18 09:17:18,415 - Task:Scrapy_bills - INFO - The work on page33 has finished.
2017-08-18 09:19:52,400 - Task:Scrapy_bills - INFO - The work on page34 has finished.
2017-08-18 09:22:24,410 - Task:Scrapy_bills - INFO - The work on page35 has finished.
2017-08-18 09:23:25,566 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:23:25,566 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:24:35,628 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:24:35,628 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:25:46,026 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:25:46,026 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:26:56,860 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:26:56,861 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:28:07,582 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:28:07,582 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:29:18,154 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:29:18,154 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:30:28,621 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:30:28,621 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:31:39,045 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:31:39,046 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:32:49,793 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:32:49,793 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:34:00,583 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:34:00,583 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:35:10,959 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:35:10,959 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:36:20,777 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:36:20,778 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:37:31,785 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:37:31,785 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:38:42,099 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:38:42,099 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:39:53,412 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:39:53,412 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:41:03,699 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:41:03,700 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:42:14,470 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:42:14,470 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:43:24,730 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:43:24,730 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:44:36,013 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:44:36,013 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:45:48,010 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:45:48,010 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:47:00,011 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:47:00,012 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:48:11,266 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:48:11,266 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:49:23,409 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:49:23,410 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:50:34,224 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:50:34,224 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:51:45,855 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:51:45,855 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:52:57,931 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:52:57,932 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:54:09,341 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:54:09,342 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:55:20,473 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:55:20,473 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:56:23,512 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:56:23,526 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
KeyboardInterrupt

2017-08-18 09:57:35,976 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:57:35,977 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:58:46,948 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:58:46,948 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 09:59:57,788 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 09:59:57,788 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-926443c96456>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 10:01:05,762 - Task:Scrapy_bills - INFO - The number of the search result is:403644
2017-08-18 10:03:41,645 - Task:Scrapy_bills - INFO - The work on page30 has finished.
2017-08-18 10:06:15,951 - Task:Scrapy_bills - INFO - The work on page31 has finished.
2017-08-18 10:08:51,433 - Task:Scrapy_bills - INFO - The work on page32 has finished.
2017-08-18 10:11:26,928 - Task:Scrapy_bills - INFO - The work on page33 has finished.
2017-08-18 10:14:02,389 - Task:Scrapy_bills - INFO - The work on page34 has finished.
2017-08-18 10:16:37,254 - Task:Scrapy_bills - INFO - The work on page35 has finished.
2017-08-18 10:17:40,153 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 10:17:40,153 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-30e2ab1d2064>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 10:18:51,649 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 10:18:51,649 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-30e2ab1d2064>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 10:19:19,486 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 10:19:19,496 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-30e2ab1d2064>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
KeyboardInterrupt

2017-08-18 10:20:31,172 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 10:20:31,173 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-30e2ab1d2064>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 10:21:42,053 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 10:21:42,054 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-30e2ab1d2064>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-18 10:22:44,204 - Task:Scrapy_bills - INFO - The number of the search result is:403644
2017-08-18 10:26:40,077 - Task:Scrapy_bills - INFO - The work on page40 has finished.
2017-08-18 10:30:31,277 - Task:Scrapy_bills - INFO - The work on page41 has finished.
2017-08-18 10:34:16,299 - Task:Scrapy_bills - INFO - The work on page42 has finished.
2017-08-18 10:37:45,437 - Task:Scrapy_bills - INFO - The work on page43 has finished.
2017-08-18 10:40:59,279 - Task:Scrapy_bills - INFO - The work on page44 has finished.
2017-08-18 10:44:14,811 - Task:Scrapy_bills - INFO - The work on page45 has finished.
2017-08-18 10:47:57,545 - Task:Scrapy_bills - INFO - The work on page46 has finished.
2017-08-18 10:51:47,235 - Task:Scrapy_bills - INFO - The work on page47 has finished.
2017-08-18 10:55:30,320 - Task:Scrapy_bills - INFO - The work on page48 has finished.
2017-08-18 10:58:47,594 - Task:Scrapy_bills - INFO - The work on page49 has finished.
2017-08-18 11:21:23,442 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation41-50.txt
2017-08-18 11:26:40,965 - Task:Scrapy_bills - INFO - The work on page50 has finished.
2017-08-18 11:27:14,949 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-18 11:27:14,956 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-34-48b8b8b82660>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-18 11:31:15,582 - Task:Scrapy_bills - INFO - The work on page51 has finished.
2017-08-18 11:35:07,997 - Task:Scrapy_bills - INFO - The work on page52 has finished.
2017-08-18 11:39:02,821 - Task:Scrapy_bills - INFO - The work on page53 has finished.
2017-08-18 11:42:58,719 - Task:Scrapy_bills - INFO - The work on page54 has finished.
2017-08-18 11:46:59,177 - Task:Scrapy_bills - INFO - The work on page55 has finished.
2017-08-18 11:50:57,745 - Task:Scrapy_bills - INFO - The work on page56 has finished.
2017-08-18 11:54:54,320 - Task:Scrapy_bills - INFO - The work on page57 has finished.
2017-08-18 11:59:05,288 - Task:Scrapy_bills - INFO - The work on page58 has finished.
2017-08-18 12:03:00,502 - Task:Scrapy_bills - INFO - The work on page59 has finished.
2017-08-18 12:03:01,344 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation51-60.txt
2017-08-18 12:06:57,562 - Task:Scrapy_bills - INFO - The work on page60 has finished.
2017-08-18 12:10:52,669 - Task:Scrapy_bills - INFO - The work on page61 has finished.
2017-08-18 12:14:39,524 - Task:Scrapy_bills - INFO - The work on page62 has finished.
2017-08-18 12:17:17,425 - Task:Scrapy_bills - INFO - The work on page63 has finished.
2017-08-18 12:19:55,452 - Task:Scrapy_bills - INFO - The work on page64 has finished.
2017-08-18 12:23:52,858 - Task:Scrapy_bills - INFO - The work on page65 has finished.
2017-08-18 12:27:38,581 - Task:Scrapy_bills - INFO - The work on page66 has finished.
2017-08-18 12:31:02,579 - Task:Scrapy_bills - INFO - The work on page67 has finished.
2017-08-18 12:34:24,496 - Task:Scrapy_bills - INFO - The work on page68 has finished.
2017-08-18 12:38:09,880 - Task:Scrapy_bills - INFO - The work on page69 has finished.
2017-08-18 12:42:44,517 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation61-70.txt
2017-08-18 12:48:42,697 - Task:Scrapy_bills - INFO - The work on page70 has finished.
2017-08-18 12:51:34,644 - Task:Scrapy_bills - INFO - The work on page71 has finished.
2017-08-18 12:54:23,785 - Task:Scrapy_bills - INFO - The work on page72 has finished.
2017-08-18 12:57:14,775 - Task:Scrapy_bills - INFO - The work on page73 has finished.
2017-08-18 13:00:18,661 - Task:Scrapy_bills - INFO - The work on page74 has finished.
2017-08-18 13:03:47,957 - Task:Scrapy_bills - INFO - The work on page75 has finished.
2017-08-18 13:07:09,908 - Task:Scrapy_bills - INFO - The work on page76 has finished.
2017-08-18 13:10:36,112 - Task:Scrapy_bills - INFO - The work on page77 has finished.
2017-08-18 13:14:00,182 - Task:Scrapy_bills - INFO - The work on page78 has finished.
2017-08-18 13:17:22,768 - Task:Scrapy_bills - INFO - The work on page79 has finished.
2017-08-19 06:10:43,110 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation71-80.txt
2017-08-19 06:15:10,416 - Task:Scrapy_bills - INFO - The work on page80 has finished.
2017-08-19 06:18:29,992 - Task:Scrapy_bills - INFO - The work on page81 has finished.
2017-08-19 06:21:47,019 - Task:Scrapy_bills - INFO - The work on page82 has finished.
2017-08-19 06:24:59,664 - Task:Scrapy_bills - INFO - The work on page83 has finished.
2017-08-19 06:28:20,721 - Task:Scrapy_bills - INFO - The work on page84 has finished.
2017-08-19 06:31:30,806 - Task:Scrapy_bills - INFO - The work on page85 has finished.
2017-08-19 06:34:46,370 - Task:Scrapy_bills - INFO - The work on page86 has finished.
2017-08-19 06:38:15,295 - Task:Scrapy_bills - INFO - The work on page87 has finished.
2017-08-19 06:41:28,321 - Task:Scrapy_bills - INFO - The work on page88 has finished.
2017-08-19 06:44:38,337 - Task:Scrapy_bills - INFO - The work on page89 has finished.
2017-08-19 06:44:39,199 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation81-90.txt
2017-08-19 06:47:55,010 - Task:Scrapy_bills - INFO - The work on page90 has finished.
2017-08-19 06:51:05,197 - Task:Scrapy_bills - INFO - The work on page91 has finished.
2017-08-19 06:54:15,220 - Task:Scrapy_bills - INFO - The work on page92 has finished.
2017-08-19 06:57:22,486 - Task:Scrapy_bills - INFO - The work on page93 has finished.
2017-08-19 07:00:33,689 - Task:Scrapy_bills - INFO - The work on page94 has finished.
2017-08-19 07:03:42,535 - Task:Scrapy_bills - INFO - The work on page95 has finished.
2017-08-19 07:06:57,824 - Task:Scrapy_bills - INFO - The work on page96 has finished.
2017-08-19 07:10:13,974 - Task:Scrapy_bills - INFO - The work on page97 has finished.
2017-08-19 07:13:26,213 - Task:Scrapy_bills - INFO - The work on page98 has finished.
2017-08-19 07:16:35,902 - Task:Scrapy_bills - INFO - The work on page99 has finished.
2017-08-19 07:16:36,749 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation91-100.txt
2017-08-19 07:19:45,441 - Task:Scrapy_bills - INFO - The work on page100 has finished.
2017-08-19 07:23:20,009 - Task:Scrapy_bills - INFO - The work on page101 has finished.
2017-08-19 07:26:30,584 - Task:Scrapy_bills - INFO - The work on page102 has finished.
2017-08-19 07:29:45,708 - Task:Scrapy_bills - INFO - The work on page103 has finished.
2017-08-19 07:32:59,253 - Task:Scrapy_bills - INFO - The work on page104 has finished.
2017-08-19 07:36:10,185 - Task:Scrapy_bills - INFO - The work on page105 has finished.
2017-08-19 07:39:23,425 - Task:Scrapy_bills - INFO - The work on page106 has finished.
2017-08-19 08:02:12,369 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:02:12,372 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 18, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:03:46,779 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:03:46,781 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 18, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:04:52,599 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:04:52,599 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:05:51,205 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:05:51,205 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:07:10,268 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:07:10,270 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:08:20,414 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:08:20,414 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:09:15,255 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:09:15,258 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:10:46,255 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:10:46,256 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 18, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:11:43,590 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:11:43,591 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:12:42,716 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:12:42,716 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:13:40,648 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:13:40,649 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:14:56,903 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:14:56,904 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-19 08:15:34,477 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:15:34,485 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-19 08:16:19,044 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:16:19,045 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:629: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error _ssl.c:629: The handshake operation timed out>

2017-08-19 08:17:00,641 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:17:00,645 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-19 08:17:35,214 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:17:35,216 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-19 08:18:09,823 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:18:09,826 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-19 08:18:43,100 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:18:43,101 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

2017-08-19 08:20:02,043 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:20:02,046 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 18, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error EOF occurred in violation of protocol (_ssl.c:645)>

2017-08-19 08:20:54,287 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-19 08:20:54,289 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-43-60af6ce8a736>", line 12, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

2017-08-21 10:56:30,013 - Task:Scrapy_bills - INFO - The number of the search result is:403654
2017-08-21 10:56:30,013 - Task:Scrapy_bills - INFO - The number of the search result is:403654
2017-08-21 10:59:41,340 - Task:Scrapy_bills - INFO - The work on page100 has finished.
2017-08-21 10:59:41,340 - Task:Scrapy_bills - INFO - The work on page100 has finished.
2017-08-21 11:03:12,778 - Task:Scrapy_bills - INFO - The work on page101 has finished.
2017-08-21 11:03:12,778 - Task:Scrapy_bills - INFO - The work on page101 has finished.
2017-08-21 11:06:24,520 - Task:Scrapy_bills - INFO - The work on page102 has finished.
2017-08-21 11:06:24,520 - Task:Scrapy_bills - INFO - The work on page102 has finished.
2017-08-21 11:09:51,295 - Task:Scrapy_bills - INFO - The work on page103 has finished.
2017-08-21 11:09:51,295 - Task:Scrapy_bills - INFO - The work on page103 has finished.
2017-08-21 11:13:02,411 - Task:Scrapy_bills - INFO - The work on page104 has finished.
2017-08-21 11:13:02,411 - Task:Scrapy_bills - INFO - The work on page104 has finished.
2017-08-21 11:16:14,276 - Task:Scrapy_bills - INFO - The work on page105 has finished.
2017-08-21 11:16:14,276 - Task:Scrapy_bills - INFO - The work on page105 has finished.
2017-08-21 11:19:24,478 - Task:Scrapy_bills - INFO - The work on page106 has finished.
2017-08-21 11:19:24,478 - Task:Scrapy_bills - INFO - The work on page106 has finished.
2017-08-21 11:22:35,823 - Task:Scrapy_bills - INFO - The work on page107 has finished.
2017-08-21 11:22:35,823 - Task:Scrapy_bills - INFO - The work on page107 has finished.
2017-08-21 11:25:45,385 - Task:Scrapy_bills - INFO - The work on page108 has finished.
2017-08-21 11:25:45,385 - Task:Scrapy_bills - INFO - The work on page108 has finished.
2017-08-21 11:28:56,922 - Task:Scrapy_bills - INFO - The work on page109 has finished.
2017-08-21 11:28:56,922 - Task:Scrapy_bills - INFO - The work on page109 has finished.
2017-08-21 11:28:57,960 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation101-110.json
2017-08-21 11:28:57,960 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation101-110.json
2017-08-21 11:32:08,198 - Task:Scrapy_bills - INFO - The work on page110 has finished.
2017-08-21 11:32:08,198 - Task:Scrapy_bills - INFO - The work on page110 has finished.
2017-08-21 11:35:22,985 - Task:Scrapy_bills - INFO - The work on page111 has finished.
2017-08-21 11:35:22,985 - Task:Scrapy_bills - INFO - The work on page111 has finished.
2017-08-21 11:38:33,358 - Task:Scrapy_bills - INFO - The work on page112 has finished.
2017-08-21 11:38:33,358 - Task:Scrapy_bills - INFO - The work on page112 has finished.
2017-08-21 11:41:48,992 - Task:Scrapy_bills - INFO - The work on page113 has finished.
2017-08-21 11:41:48,992 - Task:Scrapy_bills - INFO - The work on page113 has finished.
2017-08-21 11:45:04,650 - Task:Scrapy_bills - INFO - The work on page114 has finished.
2017-08-21 11:45:04,650 - Task:Scrapy_bills - INFO - The work on page114 has finished.
2017-08-21 11:48:16,026 - Task:Scrapy_bills - INFO - The work on page115 has finished.
2017-08-21 11:48:16,026 - Task:Scrapy_bills - INFO - The work on page115 has finished.
2017-08-21 11:51:30,835 - Task:Scrapy_bills - INFO - The work on page116 has finished.
2017-08-21 11:51:30,835 - Task:Scrapy_bills - INFO - The work on page116 has finished.
2017-08-21 11:54:43,742 - Task:Scrapy_bills - INFO - The work on page117 has finished.
2017-08-21 11:54:43,742 - Task:Scrapy_bills - INFO - The work on page117 has finished.
2017-08-21 11:57:55,467 - Task:Scrapy_bills - INFO - The work on page118 has finished.
2017-08-21 11:57:55,467 - Task:Scrapy_bills - INFO - The work on page118 has finished.
2017-08-21 12:01:18,393 - Task:Scrapy_bills - INFO - The work on page119 has finished.
2017-08-21 12:01:18,393 - Task:Scrapy_bills - INFO - The work on page119 has finished.
2017-08-21 12:01:19,230 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation111-120.json
2017-08-21 12:01:19,230 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation111-120.json
2017-08-21 12:04:37,677 - Task:Scrapy_bills - INFO - The work on page120 has finished.
2017-08-21 12:04:37,677 - Task:Scrapy_bills - INFO - The work on page120 has finished.
2017-08-21 12:07:52,860 - Task:Scrapy_bills - INFO - The work on page121 has finished.
2017-08-21 12:07:52,860 - Task:Scrapy_bills - INFO - The work on page121 has finished.
2017-08-21 12:11:09,917 - Task:Scrapy_bills - INFO - The work on page122 has finished.
2017-08-21 12:11:09,917 - Task:Scrapy_bills - INFO - The work on page122 has finished.
2017-08-21 12:14:23,892 - Task:Scrapy_bills - INFO - The work on page123 has finished.
2017-08-21 12:14:23,892 - Task:Scrapy_bills - INFO - The work on page123 has finished.
2017-08-21 12:17:36,236 - Task:Scrapy_bills - INFO - The work on page124 has finished.
2017-08-21 12:17:36,236 - Task:Scrapy_bills - INFO - The work on page124 has finished.
2017-08-21 12:20:54,089 - Task:Scrapy_bills - INFO - The work on page125 has finished.
2017-08-21 12:20:54,089 - Task:Scrapy_bills - INFO - The work on page125 has finished.
2017-08-21 12:24:06,323 - Task:Scrapy_bills - INFO - The work on page126 has finished.
2017-08-21 12:24:06,323 - Task:Scrapy_bills - INFO - The work on page126 has finished.
2017-08-21 12:27:22,645 - Task:Scrapy_bills - INFO - The work on page127 has finished.
2017-08-21 12:27:22,645 - Task:Scrapy_bills - INFO - The work on page127 has finished.
2017-08-21 12:30:34,499 - Task:Scrapy_bills - INFO - The work on page128 has finished.
2017-08-21 12:30:34,499 - Task:Scrapy_bills - INFO - The work on page128 has finished.
2017-08-21 12:33:44,061 - Task:Scrapy_bills - INFO - The work on page129 has finished.
2017-08-21 12:33:44,061 - Task:Scrapy_bills - INFO - The work on page129 has finished.
2017-08-21 12:33:44,885 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation121-130.json
2017-08-21 12:33:44,885 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation121-130.json
2017-08-21 12:36:59,405 - Task:Scrapy_bills - INFO - The work on page130 has finished.
2017-08-21 12:36:59,405 - Task:Scrapy_bills - INFO - The work on page130 has finished.
2017-08-21 12:40:11,992 - Task:Scrapy_bills - INFO - The work on page131 has finished.
2017-08-21 12:40:11,992 - Task:Scrapy_bills - INFO - The work on page131 has finished.
2017-08-21 12:43:25,919 - Task:Scrapy_bills - INFO - The work on page132 has finished.
2017-08-21 12:43:25,919 - Task:Scrapy_bills - INFO - The work on page132 has finished.
2017-08-21 12:46:41,538 - Task:Scrapy_bills - INFO - The work on page133 has finished.
2017-08-21 12:46:41,538 - Task:Scrapy_bills - INFO - The work on page133 has finished.
2017-08-21 12:49:55,282 - Task:Scrapy_bills - INFO - The work on page134 has finished.
2017-08-21 12:49:55,282 - Task:Scrapy_bills - INFO - The work on page134 has finished.
2017-08-21 12:53:10,642 - Task:Scrapy_bills - INFO - The work on page135 has finished.
2017-08-21 12:53:10,642 - Task:Scrapy_bills - INFO - The work on page135 has finished.
2017-08-21 12:56:24,596 - Task:Scrapy_bills - INFO - The work on page136 has finished.
2017-08-21 12:56:24,596 - Task:Scrapy_bills - INFO - The work on page136 has finished.
2017-08-21 12:59:37,744 - Task:Scrapy_bills - INFO - The work on page137 has finished.
2017-08-21 12:59:37,744 - Task:Scrapy_bills - INFO - The work on page137 has finished.
2017-08-21 13:02:47,616 - Task:Scrapy_bills - INFO - The work on page138 has finished.
2017-08-21 13:02:47,616 - Task:Scrapy_bills - INFO - The work on page138 has finished.
2017-08-21 13:05:33,350 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:05:33,350 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:05:33,351 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:05:33,351 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:07:56,670 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:07:56,670 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:07:56,671 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:07:56,671 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:10:19,400 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:10:19,400 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:10:19,401 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:10:19,401 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:12:44,959 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:12:44,959 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:12:44,960 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:12:44,960 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:15:07,565 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:15:07,565 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:15:07,565 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:15:07,565 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:17:31,047 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:17:31,047 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:17:31,047 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:17:31,047 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:19:54,961 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:19:54,961 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:19:54,961 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:19:54,961 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:21:00,964 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:21:00,964 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:21:00,970 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
KeyboardInterrupt

2017-08-21 13:21:00,970 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
KeyboardInterrupt

2017-08-21 13:23:24,288 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:23:24,288 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:23:24,289 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:23:24,289 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-4-f52580f8cd4d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:24:30,085 - Task:Scrapy_bills - INFO - The number of the search result is:403654
2017-08-21 13:27:03,788 - Task:Scrapy_bills - INFO - The work on page130 has finished.
2017-08-21 13:29:37,997 - Task:Scrapy_bills - INFO - The work on page131 has finished.
2017-08-21 13:32:12,033 - Task:Scrapy_bills - INFO - The work on page132 has finished.
2017-08-21 13:34:22,594 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:34:22,601 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
KeyboardInterrupt

2017-08-21 13:34:38,160 - Task:Scrapy_bills - INFO - The work on page134 has finished.
2017-08-21 13:37:12,372 - Task:Scrapy_bills - INFO - The work on page135 has finished.
2017-08-21 13:39:46,437 - Task:Scrapy_bills - INFO - The work on page136 has finished.
2017-08-21 13:42:21,662 - Task:Scrapy_bills - INFO - The work on page137 has finished.
2017-08-21 13:44:56,012 - Task:Scrapy_bills - INFO - The work on page138 has finished.
2017-08-21 13:47:29,815 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:47:29,815 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:47:45,299 - Task:Scrapy_bills - INFO - The work on page140 has finished.
2017-08-21 13:47:46,110 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation131-140.json
2017-08-21 13:48:00,139 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 13:48:00,140 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 13:48:15,529 - Task:Scrapy_bills - INFO - The work on page141 has finished.
2017-08-21 13:48:31,428 - Task:Scrapy_bills - INFO - The work on page142 has finished.
2017-08-21 13:51:40,393 - Task:Scrapy_bills - INFO - The work on page143 has finished.
2017-08-21 13:54:50,618 - Task:Scrapy_bills - INFO - The work on page144 has finished.
2017-08-21 13:58:17,910 - Task:Scrapy_bills - INFO - The work on page145 has finished.
2017-08-21 14:01:23,187 - Task:Scrapy_bills - INFO - The work on page146 has finished.
2017-08-21 14:02:25,189 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 14:02:25,194 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-21 14:02:41,142 - Task:Scrapy_bills - INFO - The work on page148 has finished.
2017-08-21 14:05:50,604 - Task:Scrapy_bills - INFO - The work on page149 has finished.
2017-08-21 14:05:51,288 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation141-150.json
2017-08-21 14:09:02,942 - Task:Scrapy_bills - INFO - The work on page150 has finished.
2017-08-21 14:12:12,088 - Task:Scrapy_bills - INFO - The work on page151 has finished.
2017-08-21 14:15:28,192 - Task:Scrapy_bills - INFO - The work on page152 has finished.
2017-08-21 14:18:42,746 - Task:Scrapy_bills - INFO - The work on page153 has finished.
2017-08-21 14:21:58,646 - Task:Scrapy_bills - INFO - The work on page154 has finished.
2017-08-21 14:25:13,736 - Task:Scrapy_bills - INFO - The work on page155 has finished.
2017-08-21 14:28:27,722 - Task:Scrapy_bills - INFO - The work on page156 has finished.
2017-08-21 14:31:44,512 - Task:Scrapy_bills - INFO - The work on page157 has finished.
2017-08-21 14:34:59,514 - Task:Scrapy_bills - INFO - The work on page158 has finished.
2017-08-21 14:38:19,701 - Task:Scrapy_bills - INFO - The work on page159 has finished.
2017-08-21 14:38:20,474 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation151-160.json
2017-08-21 14:41:38,151 - Task:Scrapy_bills - INFO - The work on page160 has finished.
2017-08-21 14:44:55,766 - Task:Scrapy_bills - INFO - The work on page161 has finished.
2017-08-21 14:48:06,924 - Task:Scrapy_bills - INFO - The work on page162 has finished.
2017-08-21 14:51:24,770 - Task:Scrapy_bills - INFO - The work on page163 has finished.
2017-08-21 14:54:37,986 - Task:Scrapy_bills - INFO - The work on page164 has finished.
2017-08-21 14:57:54,364 - Task:Scrapy_bills - INFO - The work on page165 has finished.
2017-08-21 15:01:06,578 - Task:Scrapy_bills - INFO - The work on page166 has finished.
2017-08-21 15:04:28,437 - Task:Scrapy_bills - INFO - The work on page167 has finished.
2017-08-21 15:07:54,187 - Task:Scrapy_bills - INFO - The work on page168 has finished.
2017-08-21 15:11:13,288 - Task:Scrapy_bills - INFO - The work on page169 has finished.
2017-08-21 15:11:14,063 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation161-170.json
2017-08-21 15:14:38,672 - Task:Scrapy_bills - INFO - The work on page170 has finished.
2017-08-21 15:17:51,962 - Task:Scrapy_bills - INFO - The work on page171 has finished.
2017-08-21 15:21:07,915 - Task:Scrapy_bills - INFO - The work on page172 has finished.
2017-08-21 15:24:21,119 - Task:Scrapy_bills - INFO - The work on page173 has finished.
2017-08-21 15:27:36,044 - Task:Scrapy_bills - INFO - The work on page174 has finished.
2017-08-21 15:30:46,743 - Task:Scrapy_bills - INFO - The work on page175 has finished.
2017-08-21 15:34:03,630 - Task:Scrapy_bills - INFO - The work on page176 has finished.
2017-08-21 15:37:10,318 - Task:Scrapy_bills - INFO - The work on page177 has finished.
2017-08-21 15:40:19,260 - Task:Scrapy_bills - INFO - The work on page178 has finished.
2017-08-21 15:43:30,631 - Task:Scrapy_bills - INFO - The work on page179 has finished.
2017-08-21 15:43:31,479 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation171-180.json
2017-08-21 15:46:43,944 - Task:Scrapy_bills - INFO - The work on page180 has finished.
2017-08-21 15:49:52,979 - Task:Scrapy_bills - INFO - The work on page181 has finished.
2017-08-21 15:53:03,394 - Task:Scrapy_bills - INFO - The work on page182 has finished.
2017-08-21 15:56:12,014 - Task:Scrapy_bills - INFO - The work on page183 has finished.
2017-08-21 15:59:22,682 - Task:Scrapy_bills - INFO - The work on page184 has finished.
2017-08-21 16:02:33,023 - Task:Scrapy_bills - INFO - The work on page185 has finished.
2017-08-21 16:05:47,486 - Task:Scrapy_bills - INFO - The work on page186 has finished.
2017-08-21 16:09:00,867 - Task:Scrapy_bills - INFO - The work on page187 has finished.
2017-08-21 16:12:11,125 - Task:Scrapy_bills - INFO - The work on page188 has finished.
2017-08-21 16:15:25,949 - Task:Scrapy_bills - INFO - The work on page189 has finished.
2017-08-21 16:15:26,781 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation181-190.json
2017-08-21 16:18:38,285 - Task:Scrapy_bills - INFO - The work on page190 has finished.
2017-08-21 16:21:47,093 - Task:Scrapy_bills - INFO - The work on page191 has finished.
2017-08-21 16:24:56,042 - Task:Scrapy_bills - INFO - The work on page192 has finished.
2017-08-21 16:28:05,222 - Task:Scrapy_bills - INFO - The work on page193 has finished.
2017-08-21 16:31:26,165 - Task:Scrapy_bills - INFO - The work on page194 has finished.
2017-08-21 16:34:36,715 - Task:Scrapy_bills - INFO - The work on page195 has finished.
2017-08-21 16:37:48,956 - Task:Scrapy_bills - INFO - The work on page196 has finished.
2017-08-21 16:41:02,431 - Task:Scrapy_bills - INFO - The work on page197 has finished.
2017-08-21 16:44:16,034 - Task:Scrapy_bills - INFO - The work on page198 has finished.
2017-08-21 16:47:25,742 - Task:Scrapy_bills - INFO - The work on page199 has finished.
2017-08-21 16:47:26,570 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation191-200.json
2017-08-21 16:50:41,581 - Task:Scrapy_bills - INFO - The work on page200 has finished.
2017-08-21 16:54:05,280 - Task:Scrapy_bills - INFO - The work on page201 has finished.
2017-08-21 16:56:49,347 - Task:Scrapy_bills - INFO - The work on page202 has finished.
2017-08-21 16:57:24,416 - Task:Scrapy_bills - INFO - The work on page203 has finished.
2017-08-21 17:00:33,475 - Task:Scrapy_bills - INFO - The work on page204 has finished.
2017-08-21 17:03:40,391 - Task:Scrapy_bills - INFO - The work on page205 has finished.
2017-08-21 17:06:49,617 - Task:Scrapy_bills - INFO - The work on page206 has finished.
2017-08-21 17:09:58,406 - Task:Scrapy_bills - INFO - The work on page207 has finished.
2017-08-21 17:13:06,626 - Task:Scrapy_bills - INFO - The work on page208 has finished.
2017-08-21 17:16:18,595 - Task:Scrapy_bills - INFO - The work on page209 has finished.
2017-08-21 17:16:19,395 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation201-210.json
2017-08-21 17:19:39,844 - Task:Scrapy_bills - INFO - The work on page210 has finished.
2017-08-21 17:22:59,584 - Task:Scrapy_bills - INFO - The work on page211 has finished.
2017-08-21 17:26:16,470 - Task:Scrapy_bills - INFO - The work on page212 has finished.
2017-08-21 17:29:37,072 - Task:Scrapy_bills - INFO - The work on page213 has finished.
2017-08-21 17:32:56,045 - Task:Scrapy_bills - INFO - The work on page214 has finished.
2017-08-21 17:36:19,140 - Task:Scrapy_bills - INFO - The work on page215 has finished.
2017-08-21 17:39:39,858 - Task:Scrapy_bills - INFO - The work on page216 has finished.
2017-08-21 17:43:00,838 - Task:Scrapy_bills - INFO - The work on page217 has finished.
2017-08-21 17:46:23,612 - Task:Scrapy_bills - INFO - The work on page218 has finished.
2017-08-21 17:49:47,601 - Task:Scrapy_bills - INFO - The work on page219 has finished.
2017-08-21 17:49:48,356 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation211-220.json
2017-08-21 17:53:20,998 - Task:Scrapy_bills - INFO - The work on page220 has finished.
2017-08-21 17:56:38,792 - Task:Scrapy_bills - INFO - The work on page221 has finished.
2017-08-21 17:59:59,170 - Task:Scrapy_bills - INFO - The work on page222 has finished.
2017-08-21 18:03:17,542 - Task:Scrapy_bills - INFO - The work on page223 has finished.
2017-08-21 18:06:34,355 - Task:Scrapy_bills - INFO - The work on page224 has finished.
2017-08-21 18:09:58,764 - Task:Scrapy_bills - INFO - The work on page225 has finished.
2017-08-21 18:13:20,391 - Task:Scrapy_bills - INFO - The work on page226 has finished.
2017-08-21 18:16:40,239 - Task:Scrapy_bills - INFO - The work on page227 has finished.
2017-08-21 18:20:02,480 - Task:Scrapy_bills - INFO - The work on page228 has finished.
2017-08-21 18:23:21,962 - Task:Scrapy_bills - INFO - The work on page229 has finished.
2017-08-21 18:23:22,704 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation221-230.json
2017-08-21 18:26:47,887 - Task:Scrapy_bills - INFO - The work on page230 has finished.
2017-08-21 18:30:07,342 - Task:Scrapy_bills - INFO - The work on page231 has finished.
2017-08-21 18:33:26,927 - Task:Scrapy_bills - INFO - The work on page232 has finished.
2017-08-21 18:36:46,946 - Task:Scrapy_bills - INFO - The work on page233 has finished.
2017-08-21 18:40:06,177 - Task:Scrapy_bills - INFO - The work on page234 has finished.
2017-08-21 18:43:24,813 - Task:Scrapy_bills - INFO - The work on page235 has finished.
2017-08-21 18:46:46,161 - Task:Scrapy_bills - INFO - The work on page236 has finished.
2017-08-21 18:50:12,472 - Task:Scrapy_bills - INFO - The work on page237 has finished.
2017-08-21 18:53:33,592 - Task:Scrapy_bills - INFO - The work on page238 has finished.
2017-08-21 18:56:54,444 - Task:Scrapy_bills - INFO - The work on page239 has finished.
2017-08-21 18:56:55,201 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation231-240.json
2017-08-21 19:00:26,968 - Task:Scrapy_bills - INFO - The work on page240 has finished.
2017-08-21 19:03:55,811 - Task:Scrapy_bills - INFO - The work on page241 has finished.
2017-08-21 19:07:40,292 - Task:Scrapy_bills - INFO - The work on page242 has finished.
2017-08-21 19:11:13,970 - Task:Scrapy_bills - INFO - The work on page243 has finished.
2017-08-21 19:15:22,015 - Task:Scrapy_bills - INFO - The work on page244 has finished.
2017-08-21 19:18:59,164 - Task:Scrapy_bills - INFO - The work on page245 has finished.
2017-08-21 19:22:20,173 - Task:Scrapy_bills - INFO - The work on page246 has finished.
2017-08-21 19:25:42,548 - Task:Scrapy_bills - INFO - The work on page247 has finished.
2017-08-21 19:29:01,638 - Task:Scrapy_bills - INFO - The work on page248 has finished.
2017-08-21 19:32:20,485 - Task:Scrapy_bills - INFO - The work on page249 has finished.
2017-08-21 19:32:21,255 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation241-250.json
2017-08-21 19:35:42,279 - Task:Scrapy_bills - INFO - The work on page250 has finished.
2017-08-21 19:38:59,970 - Task:Scrapy_bills - INFO - The work on page251 has finished.
2017-08-21 19:42:19,466 - Task:Scrapy_bills - INFO - The work on page252 has finished.
2017-08-21 19:45:38,370 - Task:Scrapy_bills - INFO - The work on page253 has finished.
2017-08-21 19:48:56,339 - Task:Scrapy_bills - INFO - The work on page254 has finished.
2017-08-21 19:52:14,349 - Task:Scrapy_bills - INFO - The work on page255 has finished.
2017-08-21 19:55:25,500 - Task:Scrapy_bills - INFO - The work on page256 has finished.
2017-08-21 19:58:38,148 - Task:Scrapy_bills - INFO - The work on page257 has finished.
2017-08-21 20:02:12,833 - Task:Scrapy_bills - INFO - The work on page258 has finished.
2017-08-21 20:05:31,875 - Task:Scrapy_bills - INFO - The work on page259 has finished.
2017-08-21 20:05:32,755 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation251-260.json
2017-08-21 20:08:52,684 - Task:Scrapy_bills - INFO - The work on page260 has finished.
2017-08-21 20:12:09,440 - Task:Scrapy_bills - INFO - The work on page261 has finished.
2017-08-21 20:15:18,159 - Task:Scrapy_bills - INFO - The work on page262 has finished.
2017-08-21 20:18:29,168 - Task:Scrapy_bills - INFO - The work on page263 has finished.
2017-08-21 20:21:37,537 - Task:Scrapy_bills - INFO - The work on page264 has finished.
2017-08-21 20:24:45,481 - Task:Scrapy_bills - INFO - The work on page265 has finished.
2017-08-21 20:27:54,638 - Task:Scrapy_bills - INFO - The work on page266 has finished.
2017-08-21 20:31:02,977 - Task:Scrapy_bills - INFO - The work on page267 has finished.
2017-08-21 20:34:10,657 - Task:Scrapy_bills - INFO - The work on page268 has finished.
2017-08-21 20:37:20,759 - Task:Scrapy_bills - INFO - The work on page269 has finished.
2017-08-21 20:37:21,773 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation261-270.json
2017-08-21 20:40:36,821 - Task:Scrapy_bills - INFO - The work on page270 has finished.
2017-08-21 20:43:46,974 - Task:Scrapy_bills - INFO - The work on page271 has finished.
2017-08-21 20:47:00,642 - Task:Scrapy_bills - INFO - The work on page272 has finished.
2017-08-21 20:50:12,626 - Task:Scrapy_bills - INFO - The work on page273 has finished.
2017-08-21 20:53:19,870 - Task:Scrapy_bills - INFO - The work on page274 has finished.
2017-08-21 20:56:27,621 - Task:Scrapy_bills - INFO - The work on page275 has finished.
2017-08-21 20:59:39,183 - Task:Scrapy_bills - INFO - The work on page276 has finished.
2017-08-21 21:02:51,205 - Task:Scrapy_bills - INFO - The work on page277 has finished.
2017-08-21 21:06:02,865 - Task:Scrapy_bills - INFO - The work on page278 has finished.
2017-08-21 21:09:12,805 - Task:Scrapy_bills - INFO - The work on page279 has finished.
2017-08-21 21:09:13,877 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation271-280.json
2017-08-21 21:12:28,369 - Task:Scrapy_bills - INFO - The work on page280 has finished.
2017-08-21 21:15:41,060 - Task:Scrapy_bills - INFO - The work on page281 has finished.
2017-08-21 21:16:15,089 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 21:16:15,095 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-21 21:19:34,997 - Task:Scrapy_bills - INFO - The work on page282 has finished.
2017-08-21 21:22:43,215 - Task:Scrapy_bills - INFO - The work on page283 has finished.
2017-08-21 21:25:53,440 - Task:Scrapy_bills - INFO - The work on page284 has finished.
2017-08-21 21:29:05,970 - Task:Scrapy_bills - INFO - The work on page285 has finished.
2017-08-21 21:32:16,879 - Task:Scrapy_bills - INFO - The work on page286 has finished.
2017-08-21 21:35:27,021 - Task:Scrapy_bills - INFO - The work on page287 has finished.
2017-08-21 21:38:40,350 - Task:Scrapy_bills - INFO - The work on page288 has finished.
2017-08-21 21:41:51,343 - Task:Scrapy_bills - INFO - The work on page289 has finished.
2017-08-21 21:41:52,219 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation281-290.json
2017-08-21 21:45:08,793 - Task:Scrapy_bills - INFO - The work on page290 has finished.
2017-08-21 21:48:21,763 - Task:Scrapy_bills - INFO - The work on page291 has finished.
2017-08-21 21:51:38,850 - Task:Scrapy_bills - INFO - The work on page292 has finished.
2017-08-21 21:54:53,387 - Task:Scrapy_bills - INFO - The work on page293 has finished.
2017-08-21 21:58:08,515 - Task:Scrapy_bills - INFO - The work on page294 has finished.
2017-08-21 22:01:20,731 - Task:Scrapy_bills - INFO - The work on page295 has finished.
2017-08-21 22:04:34,939 - Task:Scrapy_bills - INFO - The work on page296 has finished.
2017-08-21 22:07:50,283 - Task:Scrapy_bills - INFO - The work on page297 has finished.
2017-08-21 22:11:06,720 - Task:Scrapy_bills - INFO - The work on page298 has finished.
2017-08-21 22:14:23,813 - Task:Scrapy_bills - INFO - The work on page299 has finished.
2017-08-21 22:14:24,657 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation291-300.json
2017-08-21 22:17:40,033 - Task:Scrapy_bills - INFO - The work on page300 has finished.
2017-08-21 22:19:44,475 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 22:19:44,478 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-21 22:20:00,181 - Task:Scrapy_bills - INFO - The work on page302 has finished.
2017-08-21 22:23:14,738 - Task:Scrapy_bills - INFO - The work on page303 has finished.
2017-08-21 22:26:31,688 - Task:Scrapy_bills - INFO - The work on page304 has finished.
2017-08-21 22:29:43,570 - Task:Scrapy_bills - INFO - The work on page305 has finished.
2017-08-21 22:32:57,485 - Task:Scrapy_bills - INFO - The work on page306 has finished.
2017-08-21 22:36:14,043 - Task:Scrapy_bills - INFO - The work on page307 has finished.
2017-08-21 22:39:26,883 - Task:Scrapy_bills - INFO - The work on page308 has finished.
2017-08-21 22:42:48,474 - Task:Scrapy_bills - INFO - The work on page309 has finished.
2017-08-21 22:42:49,278 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation301-310.json
2017-08-21 22:46:10,504 - Task:Scrapy_bills - INFO - The work on page310 has finished.
2017-08-21 22:49:31,621 - Task:Scrapy_bills - INFO - The work on page311 has finished.
2017-08-21 22:52:42,972 - Task:Scrapy_bills - INFO - The work on page312 has finished.
2017-08-21 22:55:58,169 - Task:Scrapy_bills - INFO - The work on page313 has finished.
2017-08-21 22:59:12,968 - Task:Scrapy_bills - INFO - The work on page314 has finished.
2017-08-21 23:02:25,738 - Task:Scrapy_bills - INFO - The work on page315 has finished.
2017-08-21 23:05:39,707 - Task:Scrapy_bills - INFO - The work on page316 has finished.
2017-08-21 23:08:56,131 - Task:Scrapy_bills - INFO - The work on page317 has finished.
2017-08-21 23:12:09,734 - Task:Scrapy_bills - INFO - The work on page318 has finished.
2017-08-21 23:15:20,459 - Task:Scrapy_bills - INFO - The work on page319 has finished.
2017-08-21 23:15:21,295 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation311-320.json
2017-08-21 23:18:13,137 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-21 23:18:13,138 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-21 23:18:28,772 - Task:Scrapy_bills - INFO - The work on page321 has finished.
2017-08-21 23:18:33,283 - Task:Scrapy_bills - INFO - The work on page322 has finished.
2017-08-21 23:19:47,764 - Task:Scrapy_bills - INFO - The work on page323 has finished.
2017-08-21 23:22:54,179 - Task:Scrapy_bills - INFO - The work on page324 has finished.
2017-08-21 23:26:02,365 - Task:Scrapy_bills - INFO - The work on page325 has finished.
2017-08-21 23:29:09,904 - Task:Scrapy_bills - INFO - The work on page326 has finished.
2017-08-21 23:32:17,402 - Task:Scrapy_bills - INFO - The work on page327 has finished.
2017-08-21 23:35:25,354 - Task:Scrapy_bills - INFO - The work on page328 has finished.
2017-08-21 23:38:30,546 - Task:Scrapy_bills - INFO - The work on page329 has finished.
2017-08-21 23:38:31,290 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation321-330.json
2017-08-21 23:41:41,712 - Task:Scrapy_bills - INFO - The work on page330 has finished.
2017-08-21 23:44:55,233 - Task:Scrapy_bills - INFO - The work on page331 has finished.
2017-08-21 23:48:13,286 - Task:Scrapy_bills - INFO - The work on page332 has finished.
2017-08-21 23:51:34,285 - Task:Scrapy_bills - INFO - The work on page333 has finished.
2017-08-21 23:54:49,252 - Task:Scrapy_bills - INFO - The work on page334 has finished.
2017-08-21 23:58:03,273 - Task:Scrapy_bills - INFO - The work on page335 has finished.
2017-08-22 00:01:17,510 - Task:Scrapy_bills - INFO - The work on page336 has finished.
2017-08-22 00:04:32,453 - Task:Scrapy_bills - INFO - The work on page337 has finished.
2017-08-22 00:07:53,486 - Task:Scrapy_bills - INFO - The work on page338 has finished.
2017-08-22 00:11:10,082 - Task:Scrapy_bills - INFO - The work on page339 has finished.
2017-08-22 00:11:10,852 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation331-340.json
2017-08-22 00:14:27,321 - Task:Scrapy_bills - INFO - The work on page340 has finished.
2017-08-22 00:17:40,486 - Task:Scrapy_bills - INFO - The work on page341 has finished.
2017-08-22 00:20:57,378 - Task:Scrapy_bills - INFO - The work on page342 has finished.
2017-08-22 00:24:09,830 - Task:Scrapy_bills - INFO - The work on page343 has finished.
2017-08-22 00:27:16,865 - Task:Scrapy_bills - INFO - The work on page344 has finished.
2017-08-22 00:30:25,479 - Task:Scrapy_bills - INFO - The work on page345 has finished.
2017-08-22 00:33:36,264 - Task:Scrapy_bills - INFO - The work on page346 has finished.
2017-08-22 00:36:44,141 - Task:Scrapy_bills - INFO - The work on page347 has finished.
2017-08-22 00:39:54,035 - Task:Scrapy_bills - INFO - The work on page348 has finished.
2017-08-22 00:43:01,953 - Task:Scrapy_bills - INFO - The work on page349 has finished.
2017-08-22 00:43:02,773 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation341-350.json
2017-08-22 00:46:16,928 - Task:Scrapy_bills - INFO - The work on page350 has finished.
2017-08-22 00:49:27,848 - Task:Scrapy_bills - INFO - The work on page351 has finished.
2017-08-22 00:52:38,160 - Task:Scrapy_bills - INFO - The work on page352 has finished.
2017-08-22 00:55:48,326 - Task:Scrapy_bills - INFO - The work on page353 has finished.
2017-08-22 00:58:59,847 - Task:Scrapy_bills - INFO - The work on page354 has finished.
2017-08-22 01:02:09,495 - Task:Scrapy_bills - INFO - The work on page355 has finished.
2017-08-22 01:05:18,913 - Task:Scrapy_bills - INFO - The work on page356 has finished.
2017-08-22 01:08:28,164 - Task:Scrapy_bills - INFO - The work on page357 has finished.
2017-08-22 01:11:38,171 - Task:Scrapy_bills - INFO - The work on page358 has finished.
2017-08-22 01:14:53,309 - Task:Scrapy_bills - INFO - The work on page359 has finished.
2017-08-22 01:14:54,142 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation351-360.json
2017-08-22 01:18:11,614 - Task:Scrapy_bills - INFO - The work on page360 has finished.
2017-08-22 01:21:28,594 - Task:Scrapy_bills - INFO - The work on page361 has finished.
2017-08-22 01:24:43,913 - Task:Scrapy_bills - INFO - The work on page362 has finished.
2017-08-22 01:28:00,996 - Task:Scrapy_bills - INFO - The work on page363 has finished.
2017-08-22 01:31:18,151 - Task:Scrapy_bills - INFO - The work on page364 has finished.
2017-08-22 01:34:37,541 - Task:Scrapy_bills - INFO - The work on page365 has finished.
2017-08-22 01:37:58,428 - Task:Scrapy_bills - INFO - The work on page366 has finished.
2017-08-22 01:41:14,770 - Task:Scrapy_bills - INFO - The work on page367 has finished.
2017-08-22 01:44:32,763 - Task:Scrapy_bills - INFO - The work on page368 has finished.
2017-08-22 01:47:46,989 - Task:Scrapy_bills - INFO - The work on page369 has finished.
2017-08-22 01:47:47,822 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation361-370.json
2017-08-22 01:51:05,106 - Task:Scrapy_bills - INFO - The work on page370 has finished.
2017-08-22 01:54:18,644 - Task:Scrapy_bills - INFO - The work on page371 has finished.
2017-08-22 01:57:32,947 - Task:Scrapy_bills - INFO - The work on page372 has finished.
2017-08-22 01:58:24,514 - Task:Scrapy_bills - INFO - The work on page373 has finished.
2017-08-22 02:01:13,443 - Task:Scrapy_bills - INFO - The work on page374 has finished.
2017-08-22 02:04:21,841 - Task:Scrapy_bills - INFO - The work on page375 has finished.
2017-08-22 02:07:33,372 - Task:Scrapy_bills - INFO - The work on page376 has finished.
2017-08-22 02:10:45,876 - Task:Scrapy_bills - INFO - The work on page377 has finished.
2017-08-22 02:13:57,086 - Task:Scrapy_bills - INFO - The work on page378 has finished.
2017-08-22 02:17:08,605 - Task:Scrapy_bills - INFO - The work on page379 has finished.
2017-08-22 02:17:09,414 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation371-380.json
2017-08-22 02:20:33,864 - Task:Scrapy_bills - INFO - The work on page380 has finished.
2017-08-22 02:24:07,468 - Task:Scrapy_bills - INFO - The work on page381 has finished.
2017-08-22 02:27:27,955 - Task:Scrapy_bills - INFO - The work on page382 has finished.
2017-08-22 02:30:53,576 - Task:Scrapy_bills - INFO - The work on page383 has finished.
2017-08-22 02:34:23,123 - Task:Scrapy_bills - INFO - The work on page384 has finished.
2017-08-22 02:37:50,408 - Task:Scrapy_bills - INFO - The work on page385 has finished.
2017-08-22 02:41:14,726 - Task:Scrapy_bills - INFO - The work on page386 has finished.
2017-08-22 02:44:37,015 - Task:Scrapy_bills - INFO - The work on page387 has finished.
2017-08-22 02:47:58,436 - Task:Scrapy_bills - INFO - The work on page388 has finished.
2017-08-22 02:51:24,444 - Task:Scrapy_bills - INFO - The work on page389 has finished.
2017-08-22 02:51:25,210 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation381-390.json
2017-08-22 02:54:56,242 - Task:Scrapy_bills - INFO - The work on page390 has finished.
2017-08-22 02:58:24,392 - Task:Scrapy_bills - INFO - The work on page391 has finished.
2017-08-22 03:01:47,492 - Task:Scrapy_bills - INFO - The work on page392 has finished.
2017-08-22 03:05:06,925 - Task:Scrapy_bills - INFO - The work on page393 has finished.
2017-08-22 03:08:27,660 - Task:Scrapy_bills - INFO - The work on page394 has finished.
2017-08-22 03:11:48,562 - Task:Scrapy_bills - INFO - The work on page395 has finished.
2017-08-22 03:15:12,093 - Task:Scrapy_bills - INFO - The work on page396 has finished.
2017-08-22 03:18:32,309 - Task:Scrapy_bills - INFO - The work on page397 has finished.
2017-08-22 03:21:56,123 - Task:Scrapy_bills - INFO - The work on page398 has finished.
2017-08-22 03:25:19,072 - Task:Scrapy_bills - INFO - The work on page399 has finished.
2017-08-22 03:25:19,829 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation391-400.json
2017-08-22 03:28:43,656 - Task:Scrapy_bills - INFO - The work on page400 has finished.
2017-08-22 03:32:12,832 - Task:Scrapy_bills - INFO - The work on page401 has finished.
2017-08-22 03:35:31,881 - Task:Scrapy_bills - INFO - The work on page402 has finished.
2017-08-22 03:38:52,645 - Task:Scrapy_bills - INFO - The work on page403 has finished.
2017-08-22 03:42:16,162 - Task:Scrapy_bills - INFO - The work on page404 has finished.
2017-08-22 03:45:45,463 - Task:Scrapy_bills - INFO - The work on page405 has finished.
2017-08-22 03:49:14,105 - Task:Scrapy_bills - INFO - The work on page406 has finished.
2017-08-22 03:52:40,585 - Task:Scrapy_bills - INFO - The work on page407 has finished.
2017-08-22 03:55:59,202 - Task:Scrapy_bills - INFO - The work on page408 has finished.
2017-08-22 03:59:26,219 - Task:Scrapy_bills - INFO - The work on page409 has finished.
2017-08-22 03:59:26,979 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation401-410.json
2017-08-22 04:02:49,443 - Task:Scrapy_bills - INFO - The work on page410 has finished.
2017-08-22 04:06:11,433 - Task:Scrapy_bills - INFO - The work on page411 has finished.
2017-08-22 04:09:29,888 - Task:Scrapy_bills - INFO - The work on page412 has finished.
2017-08-22 04:12:47,812 - Task:Scrapy_bills - INFO - The work on page413 has finished.
2017-08-22 04:16:09,535 - Task:Scrapy_bills - INFO - The work on page414 has finished.
2017-08-22 04:19:35,052 - Task:Scrapy_bills - INFO - The work on page415 has finished.
2017-08-22 04:23:07,157 - Task:Scrapy_bills - INFO - The work on page416 has finished.
2017-08-22 04:26:28,228 - Task:Scrapy_bills - INFO - The work on page417 has finished.
2017-08-22 04:29:47,361 - Task:Scrapy_bills - INFO - The work on page418 has finished.
2017-08-22 04:33:11,713 - Task:Scrapy_bills - INFO - The work on page419 has finished.
2017-08-22 04:33:12,489 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation411-420.json
2017-08-22 04:36:40,462 - Task:Scrapy_bills - INFO - The work on page420 has finished.
2017-08-22 04:39:52,681 - Task:Scrapy_bills - INFO - The work on page421 has finished.
2017-08-22 04:42:59,158 - Task:Scrapy_bills - INFO - The work on page422 has finished.
2017-08-22 04:46:06,560 - Task:Scrapy_bills - INFO - The work on page423 has finished.
2017-08-22 04:49:14,291 - Task:Scrapy_bills - INFO - The work on page424 has finished.
2017-08-22 04:52:25,498 - Task:Scrapy_bills - INFO - The work on page425 has finished.
2017-08-22 04:55:34,221 - Task:Scrapy_bills - INFO - The work on page426 has finished.
2017-08-22 04:58:47,341 - Task:Scrapy_bills - INFO - The work on page427 has finished.
2017-08-22 04:59:21,851 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 04:59:21,854 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 05:02:43,592 - Task:Scrapy_bills - INFO - The work on page428 has finished.
2017-08-22 05:05:51,462 - Task:Scrapy_bills - INFO - The work on page429 has finished.
2017-08-22 05:05:52,300 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation421-430.json
2017-08-22 05:09:01,314 - Task:Scrapy_bills - INFO - The work on page430 has finished.
2017-08-22 05:09:35,983 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 05:09:35,985 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 05:12:54,089 - Task:Scrapy_bills - INFO - The work on page431 has finished.
2017-08-22 05:16:00,207 - Task:Scrapy_bills - INFO - The work on page432 has finished.
2017-08-22 05:19:04,799 - Task:Scrapy_bills - INFO - The work on page433 has finished.
2017-08-22 05:22:09,898 - Task:Scrapy_bills - INFO - The work on page434 has finished.
2017-08-22 05:25:13,815 - Task:Scrapy_bills - INFO - The work on page435 has finished.
2017-08-22 05:28:19,620 - Task:Scrapy_bills - INFO - The work on page436 has finished.
2017-08-22 05:31:25,033 - Task:Scrapy_bills - INFO - The work on page437 has finished.
2017-08-22 05:34:34,517 - Task:Scrapy_bills - INFO - The work on page438 has finished.
2017-08-22 05:35:09,009 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 05:35:09,011 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 05:38:25,016 - Task:Scrapy_bills - INFO - The work on page439 has finished.
2017-08-22 05:38:25,842 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation431-440.json
2017-08-22 05:41:36,007 - Task:Scrapy_bills - INFO - The work on page440 has finished.
2017-08-22 05:44:42,097 - Task:Scrapy_bills - INFO - The work on page441 has finished.
2017-08-22 05:47:46,466 - Task:Scrapy_bills - INFO - The work on page442 has finished.
2017-08-22 05:50:52,164 - Task:Scrapy_bills - INFO - The work on page443 has finished.
2017-08-22 05:53:58,449 - Task:Scrapy_bills - INFO - The work on page444 has finished.
2017-08-22 05:57:09,445 - Task:Scrapy_bills - INFO - The work on page445 has finished.
2017-08-22 06:00:18,187 - Task:Scrapy_bills - INFO - The work on page446 has finished.
2017-08-22 06:03:28,201 - Task:Scrapy_bills - INFO - The work on page447 has finished.
2017-08-22 06:06:39,439 - Task:Scrapy_bills - INFO - The work on page448 has finished.
2017-08-22 06:09:46,893 - Task:Scrapy_bills - INFO - The work on page449 has finished.
2017-08-22 06:09:47,733 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation441-450.json
2017-08-22 06:13:00,026 - Task:Scrapy_bills - INFO - The work on page450 has finished.
2017-08-22 06:16:08,141 - Task:Scrapy_bills - INFO - The work on page451 has finished.
2017-08-22 06:19:17,369 - Task:Scrapy_bills - INFO - The work on page452 has finished.
2017-08-22 06:22:27,453 - Task:Scrapy_bills - INFO - The work on page453 has finished.
2017-08-22 06:25:38,643 - Task:Scrapy_bills - INFO - The work on page454 has finished.
2017-08-22 06:28:49,140 - Task:Scrapy_bills - INFO - The work on page455 has finished.
2017-08-22 06:31:58,349 - Task:Scrapy_bills - INFO - The work on page456 has finished.
2017-08-22 06:35:07,198 - Task:Scrapy_bills - INFO - The work on page457 has finished.
2017-08-22 06:38:17,796 - Task:Scrapy_bills - INFO - The work on page458 has finished.
2017-08-22 06:41:25,265 - Task:Scrapy_bills - INFO - The work on page459 has finished.
2017-08-22 06:41:26,093 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation451-460.json
2017-08-22 06:44:37,862 - Task:Scrapy_bills - INFO - The work on page460 has finished.
2017-08-22 06:47:46,562 - Task:Scrapy_bills - INFO - The work on page461 has finished.
2017-08-22 06:50:56,997 - Task:Scrapy_bills - INFO - The work on page462 has finished.
2017-08-22 06:54:04,916 - Task:Scrapy_bills - INFO - The work on page463 has finished.
2017-08-22 06:57:15,488 - Task:Scrapy_bills - INFO - The work on page464 has finished.
2017-08-22 07:00:26,635 - Task:Scrapy_bills - INFO - The work on page465 has finished.
2017-08-22 07:03:34,022 - Task:Scrapy_bills - INFO - The work on page466 has finished.
2017-08-22 07:06:43,862 - Task:Scrapy_bills - INFO - The work on page467 has finished.
2017-08-22 07:09:56,424 - Task:Scrapy_bills - INFO - The work on page468 has finished.
2017-08-22 07:13:07,659 - Task:Scrapy_bills - INFO - The work on page469 has finished.
2017-08-22 07:13:08,505 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation461-470.json
2017-08-22 07:16:21,365 - Task:Scrapy_bills - INFO - The work on page470 has finished.
2017-08-22 07:19:28,921 - Task:Scrapy_bills - INFO - The work on page471 has finished.
2017-08-22 07:22:39,220 - Task:Scrapy_bills - INFO - The work on page472 has finished.
2017-08-22 07:25:49,372 - Task:Scrapy_bills - INFO - The work on page473 has finished.
2017-08-22 07:28:57,183 - Task:Scrapy_bills - INFO - The work on page474 has finished.
2017-08-22 07:32:10,824 - Task:Scrapy_bills - INFO - The work on page475 has finished.
2017-08-22 07:35:19,948 - Task:Scrapy_bills - INFO - The work on page476 has finished.
2017-08-22 07:38:27,091 - Task:Scrapy_bills - INFO - The work on page477 has finished.
2017-08-22 07:41:34,800 - Task:Scrapy_bills - INFO - The work on page478 has finished.
2017-08-22 07:44:46,302 - Task:Scrapy_bills - INFO - The work on page479 has finished.
2017-08-22 07:44:47,145 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation471-480.json
2017-08-22 07:48:03,003 - Task:Scrapy_bills - INFO - The work on page480 has finished.
2017-08-22 07:51:13,237 - Task:Scrapy_bills - INFO - The work on page481 has finished.
2017-08-22 07:54:21,746 - Task:Scrapy_bills - INFO - The work on page482 has finished.
2017-08-22 07:57:30,086 - Task:Scrapy_bills - INFO - The work on page483 has finished.
2017-08-22 08:00:41,076 - Task:Scrapy_bills - INFO - The work on page484 has finished.
2017-08-22 08:03:49,000 - Task:Scrapy_bills - INFO - The work on page485 has finished.
2017-08-22 08:06:57,846 - Task:Scrapy_bills - INFO - The work on page486 has finished.
2017-08-22 08:10:06,239 - Task:Scrapy_bills - INFO - The work on page487 has finished.
2017-08-22 08:11:40,078 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 08:11:40,078 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-22 08:11:55,674 - Task:Scrapy_bills - INFO - The work on page489 has finished.
2017-08-22 08:11:56,469 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation481-490.json
2017-08-22 08:12:05,220 - Task:Scrapy_bills - INFO - The work on page490 has finished.
2017-08-22 08:14:04,503 - Task:Scrapy_bills - INFO - The work on page491 has finished.
2017-08-22 08:17:12,115 - Task:Scrapy_bills - INFO - The work on page492 has finished.
2017-08-22 08:20:18,092 - Task:Scrapy_bills - INFO - The work on page493 has finished.
2017-08-22 08:23:25,417 - Task:Scrapy_bills - INFO - The work on page494 has finished.
2017-08-22 08:26:32,605 - Task:Scrapy_bills - INFO - The work on page495 has finished.
2017-08-22 08:29:40,378 - Task:Scrapy_bills - INFO - The work on page496 has finished.
2017-08-22 08:32:49,273 - Task:Scrapy_bills - INFO - The work on page497 has finished.
2017-08-22 08:35:55,898 - Task:Scrapy_bills - INFO - The work on page498 has finished.
2017-08-22 08:39:05,668 - Task:Scrapy_bills - INFO - The work on page499 has finished.
2017-08-22 08:39:06,448 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation491-500.json
2017-08-22 08:42:20,062 - Task:Scrapy_bills - INFO - The work on page500 has finished.
2017-08-22 08:45:37,294 - Task:Scrapy_bills - INFO - The work on page501 has finished.
2017-08-22 08:48:52,404 - Task:Scrapy_bills - INFO - The work on page502 has finished.
2017-08-22 08:52:07,333 - Task:Scrapy_bills - INFO - The work on page503 has finished.
2017-08-22 08:55:23,979 - Task:Scrapy_bills - INFO - The work on page504 has finished.
2017-08-22 08:58:38,182 - Task:Scrapy_bills - INFO - The work on page505 has finished.
2017-08-22 09:01:52,927 - Task:Scrapy_bills - INFO - The work on page506 has finished.
2017-08-22 09:05:29,845 - Task:Scrapy_bills - INFO - The work on page507 has finished.
2017-08-22 09:08:52,172 - Task:Scrapy_bills - INFO - The work on page508 has finished.
2017-08-22 09:12:08,920 - Task:Scrapy_bills - INFO - The work on page509 has finished.
2017-08-22 09:12:09,687 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation501-510.json
2017-08-22 09:15:28,267 - Task:Scrapy_bills - INFO - The work on page510 has finished.
2017-08-22 09:18:40,731 - Task:Scrapy_bills - INFO - The work on page511 has finished.
2017-08-22 09:21:56,428 - Task:Scrapy_bills - INFO - The work on page512 has finished.
2017-08-22 09:25:13,202 - Task:Scrapy_bills - INFO - The work on page513 has finished.
2017-08-22 09:28:26,101 - Task:Scrapy_bills - INFO - The work on page514 has finished.
2017-08-22 09:31:31,949 - Task:Scrapy_bills - INFO - The work on page515 has finished.
2017-08-22 09:34:42,806 - Task:Scrapy_bills - INFO - The work on page516 has finished.
2017-08-22 09:37:52,794 - Task:Scrapy_bills - INFO - The work on page517 has finished.
2017-08-22 09:41:01,103 - Task:Scrapy_bills - INFO - The work on page518 has finished.
2017-08-22 09:44:11,191 - Task:Scrapy_bills - INFO - The work on page519 has finished.
2017-08-22 09:44:11,986 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation511-520.json
2017-08-22 09:47:18,296 - Task:Scrapy_bills - INFO - The work on page520 has finished.
2017-08-22 09:50:23,425 - Task:Scrapy_bills - INFO - The work on page521 has finished.
2017-08-22 09:53:29,068 - Task:Scrapy_bills - INFO - The work on page522 has finished.
2017-08-22 09:56:35,010 - Task:Scrapy_bills - INFO - The work on page523 has finished.
2017-08-22 09:59:40,223 - Task:Scrapy_bills - INFO - The work on page524 has finished.
2017-08-22 10:02:47,309 - Task:Scrapy_bills - INFO - The work on page525 has finished.
2017-08-22 10:05:53,030 - Task:Scrapy_bills - INFO - The work on page526 has finished.
2017-08-22 10:08:59,849 - Task:Scrapy_bills - INFO - The work on page527 has finished.
2017-08-22 10:12:08,031 - Task:Scrapy_bills - INFO - The work on page528 has finished.
2017-08-22 10:15:15,061 - Task:Scrapy_bills - INFO - The work on page529 has finished.
2017-08-22 10:15:15,881 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation521-530.json
2017-08-22 10:18:24,918 - Task:Scrapy_bills - INFO - The work on page530 has finished.
2017-08-22 10:21:32,817 - Task:Scrapy_bills - INFO - The work on page531 has finished.
2017-08-22 10:24:41,307 - Task:Scrapy_bills - INFO - The work on page532 has finished.
2017-08-22 10:27:48,329 - Task:Scrapy_bills - INFO - The work on page533 has finished.
2017-08-22 10:30:54,509 - Task:Scrapy_bills - INFO - The work on page534 has finished.
2017-08-22 10:34:06,031 - Task:Scrapy_bills - INFO - The work on page535 has finished.
2017-08-22 10:37:15,456 - Task:Scrapy_bills - INFO - The work on page536 has finished.
2017-08-22 10:40:23,755 - Task:Scrapy_bills - INFO - The work on page537 has finished.
2017-08-22 10:43:30,443 - Task:Scrapy_bills - INFO - The work on page538 has finished.
2017-08-22 10:46:42,630 - Task:Scrapy_bills - INFO - The work on page539 has finished.
2017-08-22 10:46:43,461 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation531-540.json
2017-08-22 10:49:55,146 - Task:Scrapy_bills - INFO - The work on page540 has finished.
2017-08-22 10:53:03,866 - Task:Scrapy_bills - INFO - The work on page541 has finished.
2017-08-22 10:56:13,489 - Task:Scrapy_bills - INFO - The work on page542 has finished.
2017-08-22 10:59:23,435 - Task:Scrapy_bills - INFO - The work on page543 has finished.
2017-08-22 11:02:31,984 - Task:Scrapy_bills - INFO - The work on page544 has finished.
2017-08-22 11:05:43,717 - Task:Scrapy_bills - INFO - The work on page545 has finished.
2017-08-22 11:08:52,589 - Task:Scrapy_bills - INFO - The work on page546 has finished.
2017-08-22 11:12:02,490 - Task:Scrapy_bills - INFO - The work on page547 has finished.
2017-08-22 11:15:11,595 - Task:Scrapy_bills - INFO - The work on page548 has finished.
2017-08-22 11:18:19,153 - Task:Scrapy_bills - INFO - The work on page549 has finished.
2017-08-22 11:18:19,993 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation541-550.json
2017-08-22 11:21:24,626 - Task:Scrapy_bills - INFO - The work on page550 has finished.
2017-08-22 11:24:27,843 - Task:Scrapy_bills - INFO - The work on page551 has finished.
2017-08-22 11:24:41,609 - Task:Scrapy_bills - INFO - The work on page552 has finished.
2017-08-22 11:27:26,073 - Task:Scrapy_bills - INFO - The work on page553 has finished.
2017-08-22 11:30:39,677 - Task:Scrapy_bills - INFO - The work on page554 has finished.
2017-08-22 11:33:47,286 - Task:Scrapy_bills - INFO - The work on page555 has finished.
2017-08-22 11:36:53,487 - Task:Scrapy_bills - INFO - The work on page556 has finished.
2017-08-22 11:39:59,641 - Task:Scrapy_bills - INFO - The work on page557 has finished.
2017-08-22 11:43:08,334 - Task:Scrapy_bills - INFO - The work on page558 has finished.
2017-08-22 11:46:23,057 - Task:Scrapy_bills - INFO - The work on page559 has finished.
2017-08-22 11:46:23,855 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation551-560.json
2017-08-22 11:49:46,043 - Task:Scrapy_bills - INFO - The work on page560 has finished.
2017-08-22 11:53:13,124 - Task:Scrapy_bills - INFO - The work on page561 has finished.
2017-08-22 11:56:37,923 - Task:Scrapy_bills - INFO - The work on page562 has finished.
2017-08-22 11:59:57,905 - Task:Scrapy_bills - INFO - The work on page563 has finished.
2017-08-22 12:03:20,940 - Task:Scrapy_bills - INFO - The work on page564 has finished.
2017-08-22 12:06:48,360 - Task:Scrapy_bills - INFO - The work on page565 has finished.
2017-08-22 12:10:14,642 - Task:Scrapy_bills - INFO - The work on page566 has finished.
2017-08-22 12:13:37,760 - Task:Scrapy_bills - INFO - The work on page567 has finished.
2017-08-22 12:16:59,065 - Task:Scrapy_bills - INFO - The work on page568 has finished.
2017-08-22 12:20:22,171 - Task:Scrapy_bills - INFO - The work on page569 has finished.
2017-08-22 12:20:22,930 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation561-570.json
2017-08-22 12:23:45,120 - Task:Scrapy_bills - INFO - The work on page570 has finished.
2017-08-22 12:27:05,703 - Task:Scrapy_bills - INFO - The work on page571 has finished.
2017-08-22 12:30:24,446 - Task:Scrapy_bills - INFO - The work on page572 has finished.
2017-08-22 12:33:47,338 - Task:Scrapy_bills - INFO - The work on page573 has finished.
2017-08-22 12:37:08,937 - Task:Scrapy_bills - INFO - The work on page574 has finished.
2017-08-22 12:40:58,919 - Task:Scrapy_bills - INFO - The work on page575 has finished.
2017-08-22 12:44:18,353 - Task:Scrapy_bills - INFO - The work on page576 has finished.
2017-08-22 12:47:39,571 - Task:Scrapy_bills - INFO - The work on page577 has finished.
2017-08-22 12:51:22,705 - Task:Scrapy_bills - INFO - The work on page578 has finished.
2017-08-22 12:54:40,887 - Task:Scrapy_bills - INFO - The work on page579 has finished.
2017-08-22 12:54:41,623 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation571-580.json
2017-08-22 12:58:05,632 - Task:Scrapy_bills - INFO - The work on page580 has finished.
2017-08-22 13:01:49,917 - Task:Scrapy_bills - INFO - The work on page581 has finished.
2017-08-22 13:02:21,215 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 13:02:21,219 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

2017-08-22 13:07:13,336 - Task:Scrapy_bills - INFO - The work on page582 has finished.
2017-08-22 13:12:01,079 - Task:Scrapy_bills - INFO - The work on page583 has finished.
2017-08-22 13:17:08,391 - Task:Scrapy_bills - INFO - The work on page584 has finished.
2017-08-22 13:22:06,018 - Task:Scrapy_bills - INFO - The work on page585 has finished.
2017-08-22 13:26:51,056 - Task:Scrapy_bills - INFO - The work on page586 has finished.
2017-08-22 13:31:36,242 - Task:Scrapy_bills - INFO - The work on page587 has finished.
2017-08-22 13:36:15,083 - Task:Scrapy_bills - INFO - The work on page588 has finished.
2017-08-22 13:40:31,100 - Task:Scrapy_bills - INFO - The work on page589 has finished.
2017-08-22 13:40:31,868 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation581-590.json
2017-08-22 13:44:57,230 - Task:Scrapy_bills - INFO - The work on page590 has finished.
2017-08-22 13:49:26,851 - Task:Scrapy_bills - INFO - The work on page591 has finished.
2017-08-22 13:53:34,165 - Task:Scrapy_bills - INFO - The work on page592 has finished.
2017-08-22 13:57:19,822 - Task:Scrapy_bills - INFO - The work on page593 has finished.
2017-08-22 14:00:34,832 - Task:Scrapy_bills - INFO - The work on page594 has finished.
2017-08-22 14:03:53,042 - Task:Scrapy_bills - INFO - The work on page595 has finished.
2017-08-22 14:07:04,103 - Task:Scrapy_bills - INFO - The work on page596 has finished.
2017-08-22 14:10:15,167 - Task:Scrapy_bills - INFO - The work on page597 has finished.
2017-08-22 14:13:28,591 - Task:Scrapy_bills - INFO - The work on page598 has finished.
2017-08-22 14:16:44,329 - Task:Scrapy_bills - INFO - The work on page599 has finished.
2017-08-22 14:16:45,156 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation591-600.json
2017-08-22 14:20:04,170 - Task:Scrapy_bills - INFO - The work on page600 has finished.
2017-08-22 14:23:19,587 - Task:Scrapy_bills - INFO - The work on page601 has finished.
2017-08-22 14:26:34,249 - Task:Scrapy_bills - INFO - The work on page602 has finished.
2017-08-22 14:29:51,220 - Task:Scrapy_bills - INFO - The work on page603 has finished.
2017-08-22 14:33:08,454 - Task:Scrapy_bills - INFO - The work on page604 has finished.
2017-08-22 14:36:25,514 - Task:Scrapy_bills - INFO - The work on page605 has finished.
2017-08-22 14:39:50,918 - Task:Scrapy_bills - INFO - The work on page606 has finished.
2017-08-22 14:43:04,945 - Task:Scrapy_bills - INFO - The work on page607 has finished.
2017-08-22 14:46:31,405 - Task:Scrapy_bills - INFO - The work on page608 has finished.
2017-08-22 14:49:50,791 - Task:Scrapy_bills - INFO - The work on page609 has finished.
2017-08-22 14:49:51,617 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation601-610.json
2017-08-22 14:53:09,353 - Task:Scrapy_bills - INFO - The work on page610 has finished.
2017-08-22 14:56:26,412 - Task:Scrapy_bills - INFO - The work on page611 has finished.
2017-08-22 14:59:41,811 - Task:Scrapy_bills - INFO - The work on page612 has finished.
2017-08-22 15:02:55,748 - Task:Scrapy_bills - INFO - The work on page613 has finished.
2017-08-22 15:06:13,720 - Task:Scrapy_bills - INFO - The work on page614 has finished.
2017-08-22 15:09:31,414 - Task:Scrapy_bills - INFO - The work on page615 has finished.
2017-08-22 15:12:49,583 - Task:Scrapy_bills - INFO - The work on page616 has finished.
2017-08-22 15:16:03,451 - Task:Scrapy_bills - INFO - The work on page617 has finished.
2017-08-22 15:19:17,603 - Task:Scrapy_bills - INFO - The work on page618 has finished.
2017-08-22 15:21:26,578 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 15:21:26,582 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 711, in create_connection
    raise err
  File "D:\Applications\anaconda3\lib\socket.py", line 702, in create_connection
    sock.connect(sa)
OSError: [WinError 10065] 套接字操作尝试一个无法连接的主机。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-24ffe8338063>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10065] 套接字操作尝试一个无法连接的主机。>

2017-08-22 15:21:42,327 - Task:Scrapy_bills - INFO - The work on page620 has finished.
2017-08-22 15:21:43,137 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation611-620.json
2017-08-22 15:31:54,336 - Task:Scrapy_bills - INFO - The number of the search result is:403654
2017-08-22 15:35:03,027 - Task:Scrapy_bills - INFO - The work on page620 has finished.
2017-08-22 15:38:18,059 - Task:Scrapy_bills - INFO - The work on page621 has finished.
2017-08-22 15:41:32,399 - Task:Scrapy_bills - INFO - The work on page622 has finished.
2017-08-22 15:44:50,528 - Task:Scrapy_bills - INFO - The work on page623 has finished.
2017-08-22 15:48:03,615 - Task:Scrapy_bills - INFO - The work on page624 has finished.
2017-08-22 15:51:12,381 - Task:Scrapy_bills - INFO - The work on page625 has finished.
2017-08-22 15:54:26,517 - Task:Scrapy_bills - INFO - The work on page626 has finished.
2017-08-22 15:57:40,005 - Task:Scrapy_bills - INFO - The work on page627 has finished.
2017-08-22 16:00:51,020 - Task:Scrapy_bills - INFO - The work on page628 has finished.
2017-08-22 16:04:04,239 - Task:Scrapy_bills - INFO - The work on page629 has finished.
2017-08-22 16:04:05,108 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation621-630.json
2017-08-22 16:07:16,728 - Task:Scrapy_bills - INFO - The work on page630 has finished.
2017-08-22 16:10:28,657 - Task:Scrapy_bills - INFO - The work on page631 has finished.
2017-08-22 16:13:42,053 - Task:Scrapy_bills - INFO - The work on page632 has finished.
2017-08-22 16:16:52,612 - Task:Scrapy_bills - INFO - The work on page633 has finished.
2017-08-22 16:20:08,327 - Task:Scrapy_bills - INFO - The work on page634 has finished.
2017-08-22 16:23:25,709 - Task:Scrapy_bills - INFO - The work on page635 has finished.
2017-08-22 16:26:40,403 - Task:Scrapy_bills - INFO - The work on page636 has finished.
2017-08-22 16:29:53,622 - Task:Scrapy_bills - INFO - The work on page637 has finished.
2017-08-22 16:33:05,318 - Task:Scrapy_bills - INFO - The work on page638 has finished.
2017-08-22 16:36:19,595 - Task:Scrapy_bills - INFO - The work on page639 has finished.
2017-08-22 16:36:20,437 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation631-640.json
2017-08-22 16:39:38,134 - Task:Scrapy_bills - INFO - The work on page640 has finished.
2017-08-22 16:42:47,792 - Task:Scrapy_bills - INFO - The work on page641 has finished.
2017-08-22 16:46:05,068 - Task:Scrapy_bills - INFO - The work on page642 has finished.
2017-08-22 16:49:19,915 - Task:Scrapy_bills - INFO - The work on page643 has finished.
2017-08-22 16:52:29,949 - Task:Scrapy_bills - INFO - The work on page644 has finished.
2017-08-22 16:55:44,452 - Task:Scrapy_bills - INFO - The work on page645 has finished.
2017-08-22 16:59:00,416 - Task:Scrapy_bills - INFO - The work on page646 has finished.
2017-08-22 17:02:21,462 - Task:Scrapy_bills - INFO - The work on page647 has finished.
2017-08-22 17:05:39,898 - Task:Scrapy_bills - INFO - The work on page648 has finished.
2017-08-22 17:08:56,995 - Task:Scrapy_bills - INFO - The work on page649 has finished.
2017-08-22 17:08:57,825 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation641-650.json
2017-08-22 17:12:13,602 - Task:Scrapy_bills - INFO - The work on page650 has finished.
2017-08-22 17:15:24,068 - Task:Scrapy_bills - INFO - The work on page651 has finished.
2017-08-22 17:18:36,719 - Task:Scrapy_bills - INFO - The work on page652 has finished.
2017-08-22 17:21:49,314 - Task:Scrapy_bills - INFO - The work on page653 has finished.
2017-08-22 17:24:58,141 - Task:Scrapy_bills - INFO - The work on page654 has finished.
2017-08-22 17:28:09,838 - Task:Scrapy_bills - INFO - The work on page655 has finished.
2017-08-22 17:31:22,617 - Task:Scrapy_bills - INFO - The work on page656 has finished.
2017-08-22 17:34:33,148 - Task:Scrapy_bills - INFO - The work on page657 has finished.
2017-08-22 17:35:42,718 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 17:35:42,729 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 17:35:58,345 - Task:Scrapy_bills - INFO - The work on page659 has finished.
2017-08-22 17:35:59,117 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation651-660.json
2017-08-22 17:36:20,550 - Task:Scrapy_bills - INFO - The work on page660 has finished.
2017-08-22 17:36:25,865 - Task:Scrapy_bills - INFO - The work on page661 has finished.
2017-08-22 17:36:30,428 - Task:Scrapy_bills - INFO - The work on page662 has finished.
2017-08-22 17:36:35,549 - Task:Scrapy_bills - INFO - The work on page663 has finished.
2017-08-22 17:39:37,856 - Task:Scrapy_bills - INFO - The work on page664 has finished.
2017-08-22 17:42:53,324 - Task:Scrapy_bills - INFO - The work on page665 has finished.
2017-08-22 17:46:01,890 - Task:Scrapy_bills - INFO - The work on page666 has finished.
2017-08-22 17:49:16,297 - Task:Scrapy_bills - INFO - The work on page667 has finished.
2017-08-22 17:52:26,522 - Task:Scrapy_bills - INFO - The work on page668 has finished.
2017-08-22 17:55:40,139 - Task:Scrapy_bills - INFO - The work on page669 has finished.
2017-08-22 17:55:40,841 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation661-670.json
2017-08-22 17:58:53,735 - Task:Scrapy_bills - INFO - The work on page670 has finished.
2017-08-22 18:02:09,026 - Task:Scrapy_bills - INFO - The work on page671 has finished.
2017-08-22 18:05:24,089 - Task:Scrapy_bills - INFO - The work on page672 has finished.
2017-08-22 18:08:37,929 - Task:Scrapy_bills - INFO - The work on page673 has finished.
2017-08-22 18:11:57,225 - Task:Scrapy_bills - INFO - The work on page674 has finished.
2017-08-22 18:15:16,447 - Task:Scrapy_bills - INFO - The work on page675 has finished.
2017-08-22 18:18:34,170 - Task:Scrapy_bills - INFO - The work on page676 has finished.
2017-08-22 18:23:04,829 - Task:Scrapy_bills - INFO - The work on page677 has finished.
2017-08-22 18:27:04,015 - Task:Scrapy_bills - INFO - The work on page678 has finished.
2017-08-22 18:30:23,690 - Task:Scrapy_bills - INFO - The work on page679 has finished.
2017-08-22 18:30:24,613 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation671-680.json
2017-08-22 18:33:08,080 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 18:33:08,088 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error EOF occurred in violation of protocol (_ssl.c:645)>

2017-08-22 18:33:25,428 - Task:Scrapy_bills - INFO - The work on page681 has finished.
2017-08-22 18:36:43,942 - Task:Scrapy_bills - INFO - The work on page682 has finished.
2017-08-22 18:40:00,112 - Task:Scrapy_bills - INFO - The work on page683 has finished.
2017-08-22 18:43:17,606 - Task:Scrapy_bills - INFO - The work on page684 has finished.
2017-08-22 18:46:31,438 - Task:Scrapy_bills - INFO - The work on page685 has finished.
2017-08-22 18:49:46,479 - Task:Scrapy_bills - INFO - The work on page686 has finished.
2017-08-22 18:52:57,959 - Task:Scrapy_bills - INFO - The work on page687 has finished.
2017-08-22 18:56:14,572 - Task:Scrapy_bills - INFO - The work on page688 has finished.
2017-08-22 18:59:37,169 - Task:Scrapy_bills - INFO - The work on page689 has finished.
2017-08-22 18:59:37,900 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation681-690.json
2017-08-22 19:02:52,025 - Task:Scrapy_bills - INFO - The work on page690 has finished.
2017-08-22 19:06:05,973 - Task:Scrapy_bills - INFO - The work on page691 has finished.
2017-08-22 19:09:20,908 - Task:Scrapy_bills - INFO - The work on page692 has finished.
2017-08-22 19:12:36,063 - Task:Scrapy_bills - INFO - The work on page693 has finished.
2017-08-22 19:15:48,023 - Task:Scrapy_bills - INFO - The work on page694 has finished.
2017-08-22 19:19:05,142 - Task:Scrapy_bills - INFO - The work on page695 has finished.
2017-08-22 19:22:13,799 - Task:Scrapy_bills - INFO - The work on page696 has finished.
2017-08-22 19:25:28,195 - Task:Scrapy_bills - INFO - The work on page697 has finished.
2017-08-22 19:28:42,653 - Task:Scrapy_bills - INFO - The work on page698 has finished.
2017-08-22 19:31:52,283 - Task:Scrapy_bills - INFO - The work on page699 has finished.
2017-08-22 19:31:53,105 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation691-700.json
2017-08-22 19:35:08,405 - Task:Scrapy_bills - INFO - The work on page700 has finished.
2017-08-22 19:38:19,355 - Task:Scrapy_bills - INFO - The work on page701 has finished.
2017-08-22 19:41:30,952 - Task:Scrapy_bills - INFO - The work on page702 has finished.
2017-08-22 19:44:37,635 - Task:Scrapy_bills - INFO - The work on page703 has finished.
2017-08-22 19:47:44,214 - Task:Scrapy_bills - INFO - The work on page704 has finished.
2017-08-22 19:51:01,378 - Task:Scrapy_bills - INFO - The work on page705 has finished.
2017-08-22 19:54:09,845 - Task:Scrapy_bills - INFO - The work on page706 has finished.
2017-08-22 19:57:20,010 - Task:Scrapy_bills - INFO - The work on page707 has finished.
2017-08-22 20:00:25,585 - Task:Scrapy_bills - INFO - The work on page708 has finished.
2017-08-22 20:03:35,002 - Task:Scrapy_bills - INFO - The work on page709 has finished.
2017-08-22 20:03:35,844 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation701-710.json
2017-08-22 20:06:47,725 - Task:Scrapy_bills - INFO - The work on page710 has finished.
2017-08-22 20:10:00,033 - Task:Scrapy_bills - INFO - The work on page711 has finished.
2017-08-22 20:13:17,045 - Task:Scrapy_bills - INFO - The work on page712 has finished.
2017-08-22 20:16:31,706 - Task:Scrapy_bills - INFO - The work on page713 has finished.
2017-08-22 20:19:48,535 - Task:Scrapy_bills - INFO - The work on page714 has finished.
2017-08-22 20:23:01,580 - Task:Scrapy_bills - INFO - The work on page715 has finished.
2017-08-22 20:26:18,667 - Task:Scrapy_bills - INFO - The work on page716 has finished.
2017-08-22 20:29:47,577 - Task:Scrapy_bills - INFO - The work on page717 has finished.
2017-08-22 20:33:04,099 - Task:Scrapy_bills - INFO - The work on page718 has finished.
2017-08-22 20:36:25,762 - Task:Scrapy_bills - INFO - The work on page719 has finished.
2017-08-22 20:36:26,593 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation711-720.json
2017-08-22 20:39:59,104 - Task:Scrapy_bills - INFO - The work on page720 has finished.
2017-08-22 20:43:41,112 - Task:Scrapy_bills - INFO - The work on page721 has finished.
2017-08-22 20:47:40,573 - Task:Scrapy_bills - INFO - The work on page722 has finished.
2017-08-22 20:50:36,779 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 20:50:36,782 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 20:51:02,765 - Task:Scrapy_bills - INFO - The work on page724 has finished.
2017-08-22 20:54:35,774 - Task:Scrapy_bills - INFO - The work on page725 has finished.
2017-08-22 20:58:11,054 - Task:Scrapy_bills - INFO - The work on page726 has finished.
2017-08-22 20:58:45,638 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 20:58:45,643 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

2017-08-22 21:02:40,480 - Task:Scrapy_bills - INFO - The work on page727 has finished.
2017-08-22 21:06:03,704 - Task:Scrapy_bills - INFO - The work on page728 has finished.
2017-08-22 21:06:40,482 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 21:06:40,483 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 21:10:31,267 - Task:Scrapy_bills - INFO - The work on page729 has finished.
2017-08-22 21:10:32,169 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation721-730.json
2017-08-22 21:12:15,228 - Task:Scrapy_bills - INFO - The work on page730 has finished.
2017-08-22 21:13:57,439 - Task:Scrapy_bills - INFO - The work on page731 has finished.
2017-08-22 21:17:31,221 - Task:Scrapy_bills - INFO - The work on page732 has finished.
2017-08-22 21:21:22,089 - Task:Scrapy_bills - INFO - The work on page733 has finished.
2017-08-22 21:25:00,606 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 21:25:00,608 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

2017-08-22 21:25:26,302 - Task:Scrapy_bills - INFO - The work on page735 has finished.
2017-08-22 21:28:59,584 - Task:Scrapy_bills - INFO - The work on page736 has finished.
2017-08-22 21:32:34,598 - Task:Scrapy_bills - INFO - The work on page737 has finished.
2017-08-22 21:36:14,438 - Task:Scrapy_bills - INFO - The work on page738 has finished.
2017-08-22 21:39:50,973 - Task:Scrapy_bills - INFO - The work on page739 has finished.
2017-08-22 21:39:51,853 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation731-740.json
2017-08-22 21:40:34,489 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 21:40:34,491 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 539, in _get_chunk_left
    self._safe_read(2)  # toss the CRLF at the end of the chunk
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 21:44:22,687 - Task:Scrapy_bills - INFO - The work on page740 has finished.
2017-08-22 21:48:12,729 - Task:Scrapy_bills - INFO - The work on page741 has finished.
2017-08-22 21:52:13,845 - Task:Scrapy_bills - INFO - The work on page742 has finished.
2017-08-22 21:52:52,481 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 21:52:52,482 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 539, in _get_chunk_left
    self._safe_read(2)  # toss the CRLF at the end of the chunk
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 21:56:37,387 - Task:Scrapy_bills - INFO - The work on page743 has finished.
2017-08-22 22:00:11,055 - Task:Scrapy_bills - INFO - The work on page744 has finished.
2017-08-22 22:03:52,453 - Task:Scrapy_bills - INFO - The work on page745 has finished.
2017-08-22 22:15:27,644 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:15:27,670 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-22 22:15:37,712 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:15:37,722 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:15:47,739 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:15:47,740 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:15:57,745 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:15:57,746 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:07,761 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:07,762 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:17,777 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:17,779 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:27,788 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:27,789 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:37,796 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:37,797 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:47,808 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:47,810 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:16:57,818 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:16:57,820 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:07,836 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:07,836 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:17,859 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:17,862 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:27,878 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:27,879 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:37,905 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:37,909 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:47,930 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:47,932 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:17:57,942 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:17:57,945 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:07,963 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:07,966 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:17,978 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:17,982 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:28,007 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:28,010 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:38,028 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:38,031 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:48,057 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:48,059 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:18:58,076 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:18:58,080 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:08,132 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:08,133 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:18,145 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:18,148 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:28,163 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:28,166 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:38,188 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:38,191 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:48,209 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:48,211 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:19:58,223 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:19:58,226 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:08,251 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:08,255 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:18,279 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:18,282 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:28,310 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:28,313 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:38,327 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:38,331 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:48,356 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:48,360 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:20:58,384 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:20:58,386 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:08,422 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:08,424 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:18,440 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:18,441 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:28,459 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:28,461 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:38,476 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:38,479 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:48,496 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:48,497 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:21:58,511 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:21:58,514 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-22 22:22:49,480 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-22 22:22:49,483 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-7387d8ca93b7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-23 12:51:58,209 - Task:Scrapy_bills - INFO - The number of the search result is:403654
2017-08-23 12:56:40,550 - Task:Scrapy_bills - INFO - The work on page740 has finished.
2017-08-23 13:00:02,459 - Task:Scrapy_bills - INFO - The work on page741 has finished.
2017-08-23 13:03:57,982 - Task:Scrapy_bills - INFO - The work on page742 has finished.
2017-08-23 13:08:09,257 - Task:Scrapy_bills - INFO - The work on page743 has finished.
2017-08-23 13:12:18,977 - Task:Scrapy_bills - INFO - The work on page744 has finished.
2017-08-23 13:16:33,147 - Task:Scrapy_bills - INFO - The work on page745 has finished.
2017-08-23 13:20:51,303 - Task:Scrapy_bills - INFO - The work on page746 has finished.
2017-08-23 13:25:05,137 - Task:Scrapy_bills - INFO - The work on page747 has finished.
2017-08-23 13:29:08,077 - Task:Scrapy_bills - INFO - The work on page748 has finished.
2017-08-23 13:33:10,269 - Task:Scrapy_bills - INFO - The work on page749 has finished.
2017-08-23 13:33:11,046 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation741-750.json
2017-08-23 13:37:13,204 - Task:Scrapy_bills - INFO - The work on page750 has finished.
2017-08-23 13:40:58,296 - Task:Scrapy_bills - INFO - The work on page751 has finished.
2017-08-23 13:44:39,111 - Task:Scrapy_bills - INFO - The work on page752 has finished.
2017-08-23 13:48:28,387 - Task:Scrapy_bills - INFO - The work on page753 has finished.
2017-08-23 13:52:02,929 - Task:Scrapy_bills - INFO - The work on page754 has finished.
2017-08-23 13:55:38,323 - Task:Scrapy_bills - INFO - The work on page755 has finished.
2017-08-23 13:59:28,655 - Task:Scrapy_bills - INFO - The work on page756 has finished.
2017-08-23 14:02:52,929 - Task:Scrapy_bills - INFO - The work on page757 has finished.
2017-08-23 14:06:14,854 - Task:Scrapy_bills - INFO - The work on page758 has finished.
2017-08-23 14:09:56,389 - Task:Scrapy_bills - INFO - The work on page759 has finished.
2017-08-23 14:09:57,166 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation751-760.json
2017-08-23 14:13:24,279 - Task:Scrapy_bills - INFO - The work on page760 has finished.
2017-08-23 14:16:44,965 - Task:Scrapy_bills - INFO - The work on page761 has finished.
2017-08-23 14:20:02,194 - Task:Scrapy_bills - INFO - The work on page762 has finished.
2017-08-23 14:23:22,457 - Task:Scrapy_bills - INFO - The work on page763 has finished.
2017-08-23 14:26:44,768 - Task:Scrapy_bills - INFO - The work on page764 has finished.
2017-08-23 14:30:04,508 - Task:Scrapy_bills - INFO - The work on page765 has finished.
2017-08-23 14:33:26,568 - Task:Scrapy_bills - INFO - The work on page766 has finished.
2017-08-23 14:36:46,913 - Task:Scrapy_bills - INFO - The work on page767 has finished.
2017-08-23 14:40:08,993 - Task:Scrapy_bills - INFO - The work on page768 has finished.
2017-08-23 14:43:28,000 - Task:Scrapy_bills - INFO - The work on page769 has finished.
2017-08-23 14:43:28,814 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation761-770.json
2017-08-23 14:46:47,802 - Task:Scrapy_bills - INFO - The work on page770 has finished.
2017-08-23 14:50:03,401 - Task:Scrapy_bills - INFO - The work on page771 has finished.
2017-08-23 14:53:21,040 - Task:Scrapy_bills - INFO - The work on page772 has finished.
2017-08-23 14:56:40,906 - Task:Scrapy_bills - INFO - The work on page773 has finished.
2017-08-23 14:59:58,565 - Task:Scrapy_bills - INFO - The work on page774 has finished.
2017-08-23 15:03:28,178 - Task:Scrapy_bills - INFO - The work on page775 has finished.
2017-08-23 15:06:46,998 - Task:Scrapy_bills - INFO - The work on page776 has finished.
2017-08-23 15:10:04,567 - Task:Scrapy_bills - INFO - The work on page777 has finished.
2017-08-23 15:13:29,110 - Task:Scrapy_bills - INFO - The work on page778 has finished.
2017-08-23 15:16:48,019 - Task:Scrapy_bills - INFO - The work on page779 has finished.
2017-08-23 15:16:48,831 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation771-780.json
2017-08-23 15:20:05,775 - Task:Scrapy_bills - INFO - The work on page780 has finished.
2017-08-23 15:23:21,197 - Task:Scrapy_bills - INFO - The work on page781 has finished.
2017-08-23 15:26:41,399 - Task:Scrapy_bills - INFO - The work on page782 has finished.
2017-08-23 15:30:03,051 - Task:Scrapy_bills - INFO - The work on page783 has finished.
2017-08-23 15:33:24,365 - Task:Scrapy_bills - INFO - The work on page784 has finished.
2017-08-23 15:36:47,473 - Task:Scrapy_bills - INFO - The work on page785 has finished.
2017-08-23 15:40:12,289 - Task:Scrapy_bills - INFO - The work on page786 has finished.
2017-08-23 15:43:30,897 - Task:Scrapy_bills - INFO - The work on page787 has finished.
2017-08-23 15:46:44,051 - Task:Scrapy_bills - INFO - The work on page788 has finished.
2017-08-23 15:50:06,246 - Task:Scrapy_bills - INFO - The work on page789 has finished.
2017-08-23 15:50:06,993 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation781-790.json
2017-08-23 15:53:31,926 - Task:Scrapy_bills - INFO - The work on page790 has finished.
2017-08-23 15:56:54,157 - Task:Scrapy_bills - INFO - The work on page791 has finished.
2017-08-23 16:00:08,454 - Task:Scrapy_bills - INFO - The work on page792 has finished.
2017-08-23 16:03:23,429 - Task:Scrapy_bills - INFO - The work on page793 has finished.
2017-08-23 16:06:49,337 - Task:Scrapy_bills - INFO - The work on page794 has finished.
2017-08-23 16:09:59,118 - Task:Scrapy_bills - INFO - The work on page795 has finished.
2017-08-23 16:13:13,757 - Task:Scrapy_bills - INFO - The work on page796 has finished.
2017-08-23 16:16:31,663 - Task:Scrapy_bills - INFO - The work on page797 has finished.
2017-08-23 16:19:56,400 - Task:Scrapy_bills - INFO - The work on page798 has finished.
2017-08-23 16:23:09,008 - Task:Scrapy_bills - INFO - The work on page799 has finished.
2017-08-23 16:23:09,952 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation791-800.json
2017-08-23 16:26:30,272 - Task:Scrapy_bills - INFO - The work on page800 has finished.
2017-08-23 16:29:48,271 - Task:Scrapy_bills - INFO - The work on page801 has finished.
2017-08-23 16:33:04,280 - Task:Scrapy_bills - INFO - The work on page802 has finished.
2017-08-23 16:36:22,670 - Task:Scrapy_bills - INFO - The work on page803 has finished.
2017-08-23 16:39:43,680 - Task:Scrapy_bills - INFO - The work on page804 has finished.
2017-08-23 16:43:04,629 - Task:Scrapy_bills - INFO - The work on page805 has finished.
2017-08-23 16:46:20,976 - Task:Scrapy_bills - INFO - The work on page806 has finished.
2017-08-23 16:49:53,938 - Task:Scrapy_bills - INFO - The work on page807 has finished.
2017-08-23 16:53:24,709 - Task:Scrapy_bills - INFO - The work on page808 has finished.
2017-08-23 16:56:53,090 - Task:Scrapy_bills - INFO - The work on page809 has finished.
2017-08-23 16:56:54,007 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation801-810.json
2017-08-23 17:00:28,230 - Task:Scrapy_bills - INFO - The work on page810 has finished.
2017-08-23 17:04:02,193 - Task:Scrapy_bills - INFO - The work on page811 has finished.
2017-08-23 17:07:33,461 - Task:Scrapy_bills - INFO - The work on page812 has finished.
2017-08-23 17:11:15,041 - Task:Scrapy_bills - INFO - The work on page813 has finished.
2017-08-23 17:14:47,939 - Task:Scrapy_bills - INFO - The work on page814 has finished.
2017-08-23 17:18:24,732 - Task:Scrapy_bills - INFO - The work on page815 has finished.
2017-08-23 17:22:01,222 - Task:Scrapy_bills - INFO - The work on page816 has finished.
2017-08-23 17:25:42,595 - Task:Scrapy_bills - INFO - The work on page817 has finished.
2017-08-23 17:29:05,431 - Task:Scrapy_bills - INFO - The work on page818 has finished.
2017-08-23 17:32:22,072 - Task:Scrapy_bills - INFO - The work on page819 has finished.
2017-08-23 17:32:22,919 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation811-820.json
2017-08-23 17:35:48,232 - Task:Scrapy_bills - INFO - The work on page820 has finished.
2017-08-23 17:39:07,552 - Task:Scrapy_bills - INFO - The work on page821 has finished.
2017-08-23 17:42:31,206 - Task:Scrapy_bills - INFO - The work on page822 has finished.
2017-08-23 17:45:49,937 - Task:Scrapy_bills - INFO - The work on page823 has finished.
2017-08-23 17:49:15,034 - Task:Scrapy_bills - INFO - The work on page824 has finished.
2017-08-23 17:52:40,993 - Task:Scrapy_bills - INFO - The work on page825 has finished.
2017-08-23 17:56:05,674 - Task:Scrapy_bills - INFO - The work on page826 has finished.
2017-08-23 17:59:23,016 - Task:Scrapy_bills - INFO - The work on page827 has finished.
2017-08-23 18:02:41,045 - Task:Scrapy_bills - INFO - The work on page828 has finished.
2017-08-23 18:06:01,235 - Task:Scrapy_bills - INFO - The work on page829 has finished.
2017-08-23 18:06:02,039 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation821-830.json
2017-08-23 18:09:23,402 - Task:Scrapy_bills - INFO - The work on page830 has finished.
2017-08-23 18:12:45,124 - Task:Scrapy_bills - INFO - The work on page831 has finished.
2017-08-23 18:16:09,037 - Task:Scrapy_bills - INFO - The work on page832 has finished.
2017-08-23 18:19:26,645 - Task:Scrapy_bills - INFO - The work on page833 has finished.
2017-08-23 18:22:47,855 - Task:Scrapy_bills - INFO - The work on page834 has finished.
2017-08-23 18:26:09,096 - Task:Scrapy_bills - INFO - The work on page835 has finished.
2017-08-23 18:29:32,896 - Task:Scrapy_bills - INFO - The work on page836 has finished.
2017-08-23 18:32:52,023 - Task:Scrapy_bills - INFO - The work on page837 has finished.
2017-08-23 18:36:13,693 - Task:Scrapy_bills - INFO - The work on page838 has finished.
2017-08-23 18:39:32,112 - Task:Scrapy_bills - INFO - The work on page839 has finished.
2017-08-23 18:39:32,932 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation831-840.json
2017-08-23 18:43:00,361 - Task:Scrapy_bills - INFO - The work on page840 has finished.
2017-08-23 18:46:18,364 - Task:Scrapy_bills - INFO - The work on page841 has finished.
2017-08-23 18:49:43,323 - Task:Scrapy_bills - INFO - The work on page842 has finished.
2017-08-23 18:53:01,333 - Task:Scrapy_bills - INFO - The work on page843 has finished.
2017-08-23 18:56:27,131 - Task:Scrapy_bills - INFO - The work on page844 has finished.
2017-08-23 18:59:54,767 - Task:Scrapy_bills - INFO - The work on page845 has finished.
2017-08-23 19:03:18,793 - Task:Scrapy_bills - INFO - The work on page846 has finished.
2017-08-23 19:06:42,302 - Task:Scrapy_bills - INFO - The work on page847 has finished.
2017-08-23 19:10:14,167 - Task:Scrapy_bills - INFO - The work on page848 has finished.
2017-08-23 19:13:39,093 - Task:Scrapy_bills - INFO - The work on page849 has finished.
2017-08-23 19:13:39,937 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation841-850.json
2017-08-23 19:17:03,736 - Task:Scrapy_bills - INFO - The work on page850 has finished.
2017-08-23 19:20:32,826 - Task:Scrapy_bills - INFO - The work on page851 has finished.
2017-08-23 19:23:50,312 - Task:Scrapy_bills - INFO - The work on page852 has finished.
2017-08-23 19:27:13,862 - Task:Scrapy_bills - INFO - The work on page853 has finished.
2017-08-23 19:30:31,420 - Task:Scrapy_bills - INFO - The work on page854 has finished.
2017-08-23 19:33:50,434 - Task:Scrapy_bills - INFO - The work on page855 has finished.
2017-08-23 19:37:08,195 - Task:Scrapy_bills - INFO - The work on page856 has finished.
2017-08-23 19:40:32,318 - Task:Scrapy_bills - INFO - The work on page857 has finished.
2017-08-23 19:43:52,747 - Task:Scrapy_bills - INFO - The work on page858 has finished.
2017-08-23 19:47:15,153 - Task:Scrapy_bills - INFO - The work on page859 has finished.
2017-08-23 19:47:15,955 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation851-860.json
2017-08-23 19:50:44,254 - Task:Scrapy_bills - INFO - The work on page860 has finished.
2017-08-23 19:51:25,509 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 19:51:25,509 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-23 19:51:41,078 - Task:Scrapy_bills - INFO - The work on page862 has finished.
2017-08-23 19:51:45,937 - Task:Scrapy_bills - INFO - The work on page863 has finished.
2017-08-23 19:51:50,693 - Task:Scrapy_bills - INFO - The work on page864 has finished.
2017-08-23 19:51:55,407 - Task:Scrapy_bills - INFO - The work on page865 has finished.
2017-08-23 19:52:57,183 - Task:Scrapy_bills - INFO - The work on page866 has finished.
2017-08-23 19:56:15,064 - Task:Scrapy_bills - INFO - The work on page867 has finished.
2017-08-23 19:59:35,178 - Task:Scrapy_bills - INFO - The work on page868 has finished.
2017-08-23 20:02:53,929 - Task:Scrapy_bills - INFO - The work on page869 has finished.
2017-08-23 20:02:54,581 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation861-870.json
2017-08-23 20:06:19,923 - Task:Scrapy_bills - INFO - The work on page870 has finished.
2017-08-23 20:09:43,903 - Task:Scrapy_bills - INFO - The work on page871 has finished.
2017-08-23 20:13:03,319 - Task:Scrapy_bills - INFO - The work on page872 has finished.
2017-08-23 20:16:21,730 - Task:Scrapy_bills - INFO - The work on page873 has finished.
2017-08-23 20:19:41,973 - Task:Scrapy_bills - INFO - The work on page874 has finished.
2017-08-23 20:23:01,956 - Task:Scrapy_bills - INFO - The work on page875 has finished.
2017-08-23 20:26:20,244 - Task:Scrapy_bills - INFO - The work on page876 has finished.
2017-08-23 20:29:36,368 - Task:Scrapy_bills - INFO - The work on page877 has finished.
2017-08-23 20:32:57,740 - Task:Scrapy_bills - INFO - The work on page878 has finished.
2017-08-23 20:36:17,944 - Task:Scrapy_bills - INFO - The work on page879 has finished.
2017-08-23 20:36:18,756 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation871-880.json
2017-08-23 20:39:45,725 - Task:Scrapy_bills - INFO - The work on page880 has finished.
2017-08-23 20:43:04,146 - Task:Scrapy_bills - INFO - The work on page881 has finished.
2017-08-23 20:46:19,033 - Task:Scrapy_bills - INFO - The work on page882 has finished.
2017-08-23 20:49:33,765 - Task:Scrapy_bills - INFO - The work on page883 has finished.
2017-08-23 20:52:49,414 - Task:Scrapy_bills - INFO - The work on page884 has finished.
2017-08-23 20:56:03,762 - Task:Scrapy_bills - INFO - The work on page885 has finished.
2017-08-23 20:59:16,768 - Task:Scrapy_bills - INFO - The work on page886 has finished.
2017-08-23 21:02:31,862 - Task:Scrapy_bills - INFO - The work on page887 has finished.
2017-08-23 21:05:47,412 - Task:Scrapy_bills - INFO - The work on page888 has finished.
2017-08-23 21:09:01,804 - Task:Scrapy_bills - INFO - The work on page889 has finished.
2017-08-23 21:09:02,570 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation881-890.json
2017-08-23 21:12:22,054 - Task:Scrapy_bills - INFO - The work on page890 has finished.
2017-08-23 21:15:40,211 - Task:Scrapy_bills - INFO - The work on page891 has finished.
2017-08-23 21:18:56,264 - Task:Scrapy_bills - INFO - The work on page892 has finished.
2017-08-23 21:22:15,607 - Task:Scrapy_bills - INFO - The work on page893 has finished.
2017-08-23 21:25:38,583 - Task:Scrapy_bills - INFO - The work on page894 has finished.
2017-08-23 21:28:57,365 - Task:Scrapy_bills - INFO - The work on page895 has finished.
2017-08-23 21:32:19,612 - Task:Scrapy_bills - INFO - The work on page896 has finished.
2017-08-23 21:35:41,204 - Task:Scrapy_bills - INFO - The work on page897 has finished.
2017-08-23 21:39:04,025 - Task:Scrapy_bills - INFO - The work on page898 has finished.
2017-08-23 21:42:24,997 - Task:Scrapy_bills - INFO - The work on page899 has finished.
2017-08-23 21:42:25,800 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation891-900.json
2017-08-23 21:45:51,783 - Task:Scrapy_bills - INFO - The work on page900 has finished.
2017-08-23 21:49:14,133 - Task:Scrapy_bills - INFO - The work on page901 has finished.
2017-08-23 21:52:38,856 - Task:Scrapy_bills - INFO - The work on page902 has finished.
2017-08-23 21:56:03,401 - Task:Scrapy_bills - INFO - The work on page903 has finished.
2017-08-23 21:59:22,187 - Task:Scrapy_bills - INFO - The work on page904 has finished.
2017-08-23 22:02:43,997 - Task:Scrapy_bills - INFO - The work on page905 has finished.
2017-08-23 22:06:03,254 - Task:Scrapy_bills - INFO - The work on page906 has finished.
2017-08-23 22:09:27,787 - Task:Scrapy_bills - INFO - The work on page907 has finished.
2017-08-23 22:12:50,315 - Task:Scrapy_bills - INFO - The work on page908 has finished.
2017-08-23 22:16:16,330 - Task:Scrapy_bills - INFO - The work on page909 has finished.
2017-08-23 22:16:17,154 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation901-910.json
2017-08-23 22:19:42,902 - Task:Scrapy_bills - INFO - The work on page910 has finished.
2017-08-23 22:23:09,067 - Task:Scrapy_bills - INFO - The work on page911 has finished.
2017-08-23 22:26:34,757 - Task:Scrapy_bills - INFO - The work on page912 has finished.
2017-08-23 22:29:53,631 - Task:Scrapy_bills - INFO - The work on page913 has finished.
2017-08-23 22:33:15,459 - Task:Scrapy_bills - INFO - The work on page914 has finished.
2017-08-23 22:36:41,023 - Task:Scrapy_bills - INFO - The work on page915 has finished.
2017-08-23 22:40:02,677 - Task:Scrapy_bills - INFO - The work on page916 has finished.
2017-08-23 22:43:27,489 - Task:Scrapy_bills - INFO - The work on page917 has finished.
2017-08-23 22:46:50,798 - Task:Scrapy_bills - INFO - The work on page918 has finished.
2017-08-23 22:50:21,338 - Task:Scrapy_bills - INFO - The work on page919 has finished.
2017-08-23 22:50:22,152 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation911-920.json
2017-08-23 22:53:48,072 - Task:Scrapy_bills - INFO - The work on page920 has finished.
2017-08-23 22:57:15,602 - Task:Scrapy_bills - INFO - The work on page921 has finished.
2017-08-23 23:00:43,712 - Task:Scrapy_bills - INFO - The work on page922 has finished.
2017-08-23 23:04:04,810 - Task:Scrapy_bills - INFO - The work on page923 has finished.
2017-08-23 23:05:26,480 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:05:26,488 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:05:41,989 - Task:Scrapy_bills - INFO - The work on page925 has finished.
2017-08-23 23:05:43,692 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:05:43,694 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:05:54,884 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:05:54,885 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:06:06,075 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:06:06,077 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:06:17,290 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:06:17,292 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:06:30,677 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:06:30,678 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:07:11,374 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:07:11,382 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-23 23:07:45,301 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:07:45,302 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:07:56,502 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:07:56,503 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:08:12,498 - Task:Scrapy_bills - INFO - The work on page927 has finished.
2017-08-23 23:08:18,582 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:08:18,584 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:08:58,090 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:08:58,092 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:09:09,281 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:09:09,283 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:09:24,844 - Task:Scrapy_bills - INFO - The work on page929 has finished.
2017-08-23 23:09:25,495 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation921-930.json
2017-08-23 23:09:28,019 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:09:28,021 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:13:03,606 - Task:Scrapy_bills - INFO - The work on page930 has finished.
2017-08-23 23:14:26,588 - Task:Scrapy_bills - INFO - The work on page931 has finished.
2017-08-23 23:15:01,323 - Task:Scrapy_bills - INFO - The work on page932 has finished.
2017-08-23 23:17:27,341 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:17:27,343 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:17:43,022 - Task:Scrapy_bills - INFO - The work on page934 has finished.
2017-08-23 23:19:36,249 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:19:36,251 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:19:52,486 - Task:Scrapy_bills - INFO - The work on page936 has finished.
2017-08-23 23:21:48,039 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:21:48,041 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:22:04,116 - Task:Scrapy_bills - INFO - The work on page938 has finished.
2017-08-23 23:22:29,046 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:22:29,047 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:22:45,470 - Task:Scrapy_bills - INFO - The work on page940 has finished.
2017-08-23 23:22:46,097 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation931-940.json
2017-08-23 23:26:12,961 - Task:Scrapy_bills - INFO - The work on page940 has finished.
2017-08-23 23:26:14,458 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:26:14,459 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:29:44,942 - Task:Scrapy_bills - INFO - The work on page941 has finished.
2017-08-23 23:32:46,045 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:32:46,046 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:33:04,294 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:33:04,295 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:33:20,699 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:33:20,700 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:33:31,696 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:33:31,697 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:33:43,222 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:33:43,224 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:33:54,467 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:33:54,468 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:34:06,228 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:34:06,230 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:34:17,419 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:34:17,420 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:34:29,024 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:34:29,026 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:34:42,336 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:34:42,338 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:34:53,543 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:34:53,544 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:35:04,563 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:35:04,565 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:35:42,003 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:35:42,004 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:35:53,203 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:35:53,204 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:36:18,215 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:36:18,217 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:36:35,080 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:36:35,081 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:36:49,852 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:36:49,854 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:37:07,502 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:37:07,503 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:37:22,525 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:37:22,527 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:37:58,166 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:37:58,167 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:38:15,866 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:38:15,868 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:38:32,839 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:38:32,841 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:38:44,057 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:38:44,058 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:39:11,000 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:39:11,001 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:39:36,129 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:39:36,131 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:40:02,632 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:40:02,633 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:40:17,622 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:40:17,623 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:40:32,324 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:40:32,325 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:43:39,882 - Task:Scrapy_bills - INFO - The work on page942 has finished.
2017-08-23 23:47:06,375 - Task:Scrapy_bills - INFO - The work on page943 has finished.
2017-08-23 23:47:45,825 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:47:45,826 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:50:39,277 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-23 23:50:39,278 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-23 23:53:51,842 - Task:Scrapy_bills - INFO - The work on page944 has finished.
2017-08-23 23:57:21,210 - Task:Scrapy_bills - INFO - The work on page945 has finished.
2017-08-24 00:00:47,777 - Task:Scrapy_bills - INFO - The work on page946 has finished.
2017-08-24 00:04:23,648 - Task:Scrapy_bills - INFO - The work on page947 has finished.
2017-08-24 00:07:02,114 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 00:07:02,115 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 00:09:01,487 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 00:09:01,489 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 00:12:16,018 - Task:Scrapy_bills - INFO - The work on page948 has finished.
2017-08-24 00:15:38,676 - Task:Scrapy_bills - INFO - The work on page949 has finished.
2017-08-24 00:15:39,505 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation941-950.json
2017-08-24 00:19:00,029 - Task:Scrapy_bills - INFO - The work on page950 has finished.
2017-08-24 00:22:23,611 - Task:Scrapy_bills - INFO - The work on page951 has finished.
2017-08-24 00:25:52,024 - Task:Scrapy_bills - INFO - The work on page952 has finished.
2017-08-24 00:29:15,035 - Task:Scrapy_bills - INFO - The work on page953 has finished.
2017-08-24 00:32:36,181 - Task:Scrapy_bills - INFO - The work on page954 has finished.
2017-08-24 00:36:01,651 - Task:Scrapy_bills - INFO - The work on page955 has finished.
2017-08-24 00:39:27,861 - Task:Scrapy_bills - INFO - The work on page956 has finished.
2017-08-24 00:41:14,319 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 00:41:14,320 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 00:42:02,689 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 00:42:02,690 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 00:45:20,312 - Task:Scrapy_bills - INFO - The work on page957 has finished.
2017-08-24 00:48:45,815 - Task:Scrapy_bills - INFO - The work on page958 has finished.
2017-08-24 00:52:14,598 - Task:Scrapy_bills - INFO - The work on page959 has finished.
2017-08-24 00:52:15,365 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation951-960.json
2017-08-24 00:55:44,915 - Task:Scrapy_bills - INFO - The work on page960 has finished.
2017-08-24 00:59:10,693 - Task:Scrapy_bills - INFO - The work on page961 has finished.
2017-08-24 01:02:34,001 - Task:Scrapy_bills - INFO - The work on page962 has finished.
2017-08-24 01:05:59,944 - Task:Scrapy_bills - INFO - The work on page963 has finished.
2017-08-24 01:09:28,925 - Task:Scrapy_bills - INFO - The work on page964 has finished.
2017-08-24 01:12:52,995 - Task:Scrapy_bills - INFO - The work on page965 has finished.
2017-08-24 01:16:19,434 - Task:Scrapy_bills - INFO - The work on page966 has finished.
2017-08-24 01:19:45,136 - Task:Scrapy_bills - INFO - The work on page967 has finished.
2017-08-24 01:23:10,471 - Task:Scrapy_bills - INFO - The work on page968 has finished.
2017-08-24 01:26:32,975 - Task:Scrapy_bills - INFO - The work on page969 has finished.
2017-08-24 01:26:33,736 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation961-970.json
2017-08-24 01:30:02,120 - Task:Scrapy_bills - INFO - The work on page970 has finished.
2017-08-24 01:33:30,362 - Task:Scrapy_bills - INFO - The work on page971 has finished.
2017-08-24 01:36:58,673 - Task:Scrapy_bills - INFO - The work on page972 has finished.
2017-08-24 01:40:23,556 - Task:Scrapy_bills - INFO - The work on page973 has finished.
2017-08-24 01:43:47,742 - Task:Scrapy_bills - INFO - The work on page974 has finished.
2017-08-24 01:47:09,431 - Task:Scrapy_bills - INFO - The work on page975 has finished.
2017-08-24 01:50:36,424 - Task:Scrapy_bills - INFO - The work on page976 has finished.
2017-08-24 01:53:58,562 - Task:Scrapy_bills - INFO - The work on page977 has finished.
2017-08-24 01:57:25,401 - Task:Scrapy_bills - INFO - The work on page978 has finished.
2017-08-24 02:01:00,078 - Task:Scrapy_bills - INFO - The work on page979 has finished.
2017-08-24 02:01:00,830 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation971-980.json
2017-08-24 02:04:47,967 - Task:Scrapy_bills - INFO - The work on page980 has finished.
2017-08-24 02:08:21,074 - Task:Scrapy_bills - INFO - The work on page981 has finished.
2017-08-24 02:11:50,551 - Task:Scrapy_bills - INFO - The work on page982 has finished.
2017-08-24 02:15:26,014 - Task:Scrapy_bills - INFO - The work on page983 has finished.
2017-08-24 02:16:59,548 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 02:16:59,549 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 02:17:10,977 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 02:17:10,979 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 02:17:26,023 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 02:17:26,024 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 02:20:48,722 - Task:Scrapy_bills - INFO - The work on page984 has finished.
2017-08-24 02:24:18,404 - Task:Scrapy_bills - INFO - The work on page985 has finished.
2017-08-24 02:26:19,718 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 02:26:19,719 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 02:29:33,521 - Task:Scrapy_bills - INFO - The work on page986 has finished.
2017-08-24 02:31:21,942 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 02:31:21,943 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 02:34:35,642 - Task:Scrapy_bills - INFO - The work on page987 has finished.
2017-08-24 02:38:01,970 - Task:Scrapy_bills - INFO - The work on page988 has finished.
2017-08-24 02:41:32,011 - Task:Scrapy_bills - INFO - The work on page989 has finished.
2017-08-24 02:41:32,813 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation981-990.json
2017-08-24 02:45:01,923 - Task:Scrapy_bills - INFO - The work on page990 has finished.
2017-08-24 02:48:21,677 - Task:Scrapy_bills - INFO - The work on page991 has finished.
2017-08-24 02:51:48,314 - Task:Scrapy_bills - INFO - The work on page992 has finished.
2017-08-24 02:55:11,523 - Task:Scrapy_bills - INFO - The work on page993 has finished.
2017-08-24 02:58:30,638 - Task:Scrapy_bills - INFO - The work on page994 has finished.
2017-08-24 03:01:53,352 - Task:Scrapy_bills - INFO - The work on page995 has finished.
2017-08-24 03:05:16,619 - Task:Scrapy_bills - INFO - The work on page996 has finished.
2017-08-24 03:08:26,796 - Task:Scrapy_bills - INFO - The work on page997 has finished.
2017-08-24 03:11:49,009 - Task:Scrapy_bills - INFO - The work on page998 has finished.
2017-08-24 03:15:11,503 - Task:Scrapy_bills - INFO - The work on page999 has finished.
2017-08-24 03:15:12,264 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation991-1000.json
2017-08-24 03:18:36,185 - Task:Scrapy_bills - INFO - The work on page1000 has finished.
2017-08-24 03:22:00,275 - Task:Scrapy_bills - INFO - The work on page1001 has finished.
2017-08-24 03:25:21,715 - Task:Scrapy_bills - INFO - The work on page1002 has finished.
2017-08-24 03:28:41,674 - Task:Scrapy_bills - INFO - The work on page1003 has finished.
2017-08-24 03:32:04,873 - Task:Scrapy_bills - INFO - The work on page1004 has finished.
2017-08-24 03:35:29,188 - Task:Scrapy_bills - INFO - The work on page1005 has finished.
2017-08-24 03:38:44,864 - Task:Scrapy_bills - INFO - The work on page1006 has finished.
2017-08-24 03:42:07,143 - Task:Scrapy_bills - INFO - The work on page1007 has finished.
2017-08-24 03:45:34,355 - Task:Scrapy_bills - INFO - The work on page1008 has finished.
2017-08-24 03:48:57,606 - Task:Scrapy_bills - INFO - The work on page1009 has finished.
2017-08-24 03:48:58,412 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1001-1010.json
2017-08-24 03:52:21,717 - Task:Scrapy_bills - INFO - The work on page1010 has finished.
2017-08-24 03:55:39,305 - Task:Scrapy_bills - INFO - The work on page1011 has finished.
2017-08-24 03:59:00,159 - Task:Scrapy_bills - INFO - The work on page1012 has finished.
2017-08-24 04:02:20,226 - Task:Scrapy_bills - INFO - The work on page1013 has finished.
2017-08-24 04:05:44,675 - Task:Scrapy_bills - INFO - The work on page1014 has finished.
2017-08-24 04:09:13,365 - Task:Scrapy_bills - INFO - The work on page1015 has finished.
2017-08-24 04:12:29,971 - Task:Scrapy_bills - INFO - The work on page1016 has finished.
2017-08-24 04:15:48,427 - Task:Scrapy_bills - INFO - The work on page1017 has finished.
2017-08-24 04:19:12,538 - Task:Scrapy_bills - INFO - The work on page1018 has finished.
2017-08-24 04:22:34,353 - Task:Scrapy_bills - INFO - The work on page1019 has finished.
2017-08-24 04:22:35,161 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1011-1020.json
2017-08-24 04:25:56,206 - Task:Scrapy_bills - INFO - The work on page1020 has finished.
2017-08-24 04:29:17,210 - Task:Scrapy_bills - INFO - The work on page1021 has finished.
2017-08-24 04:32:40,792 - Task:Scrapy_bills - INFO - The work on page1022 has finished.
2017-08-24 04:36:08,273 - Task:Scrapy_bills - INFO - The work on page1023 has finished.
2017-08-24 04:39:33,947 - Task:Scrapy_bills - INFO - The work on page1024 has finished.
2017-08-24 04:43:01,177 - Task:Scrapy_bills - INFO - The work on page1025 has finished.
2017-08-24 04:46:26,602 - Task:Scrapy_bills - INFO - The work on page1026 has finished.
2017-08-24 04:49:53,477 - Task:Scrapy_bills - INFO - The work on page1027 has finished.
2017-08-24 04:53:22,267 - Task:Scrapy_bills - INFO - The work on page1028 has finished.
2017-08-24 04:56:52,717 - Task:Scrapy_bills - INFO - The work on page1029 has finished.
2017-08-24 04:56:53,517 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1021-1030.json
2017-08-24 05:00:20,414 - Task:Scrapy_bills - INFO - The work on page1030 has finished.
2017-08-24 05:03:26,062 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 05:03:26,064 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 05:03:41,976 - Task:Scrapy_bills - INFO - The work on page1032 has finished.
2017-08-24 05:07:14,764 - Task:Scrapy_bills - INFO - The work on page1033 has finished.
2017-08-24 05:10:46,121 - Task:Scrapy_bills - INFO - The work on page1034 has finished.
2017-08-24 05:14:20,096 - Task:Scrapy_bills - INFO - The work on page1035 has finished.
2017-08-24 05:17:51,727 - Task:Scrapy_bills - INFO - The work on page1036 has finished.
2017-08-24 05:21:09,335 - Task:Scrapy_bills - INFO - The work on page1037 has finished.
2017-08-24 05:24:36,335 - Task:Scrapy_bills - INFO - The work on page1038 has finished.
2017-08-24 05:28:09,008 - Task:Scrapy_bills - INFO - The work on page1039 has finished.
2017-08-24 05:28:09,783 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1031-1040.json
2017-08-24 05:31:40,326 - Task:Scrapy_bills - INFO - The work on page1040 has finished.
2017-08-24 05:35:11,094 - Task:Scrapy_bills - INFO - The work on page1041 has finished.
2017-08-24 05:38:49,041 - Task:Scrapy_bills - INFO - The work on page1042 has finished.
2017-08-24 05:42:20,987 - Task:Scrapy_bills - INFO - The work on page1043 has finished.
2017-08-24 05:45:47,230 - Task:Scrapy_bills - INFO - The work on page1044 has finished.
2017-08-24 05:49:11,753 - Task:Scrapy_bills - INFO - The work on page1045 has finished.
2017-08-24 05:52:35,676 - Task:Scrapy_bills - INFO - The work on page1046 has finished.
2017-08-24 05:55:54,525 - Task:Scrapy_bills - INFO - The work on page1047 has finished.
2017-08-24 05:59:13,717 - Task:Scrapy_bills - INFO - The work on page1048 has finished.
2017-08-24 06:02:34,479 - Task:Scrapy_bills - INFO - The work on page1049 has finished.
2017-08-24 06:02:35,288 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1041-1050.json
2017-08-24 06:05:59,708 - Task:Scrapy_bills - INFO - The work on page1050 has finished.
2017-08-24 06:09:22,819 - Task:Scrapy_bills - INFO - The work on page1051 has finished.
2017-08-24 06:12:46,408 - Task:Scrapy_bills - INFO - The work on page1052 has finished.
2017-08-24 06:16:06,511 - Task:Scrapy_bills - INFO - The work on page1053 has finished.
2017-08-24 06:19:25,784 - Task:Scrapy_bills - INFO - The work on page1054 has finished.
2017-08-24 06:22:53,565 - Task:Scrapy_bills - INFO - The work on page1055 has finished.
2017-08-24 06:26:17,944 - Task:Scrapy_bills - INFO - The work on page1056 has finished.
2017-08-24 06:29:42,648 - Task:Scrapy_bills - INFO - The work on page1057 has finished.
2017-08-24 06:33:11,977 - Task:Scrapy_bills - INFO - The work on page1058 has finished.
2017-08-24 06:36:33,222 - Task:Scrapy_bills - INFO - The work on page1059 has finished.
2017-08-24 06:36:34,028 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1051-1060.json
2017-08-24 06:40:02,833 - Task:Scrapy_bills - INFO - The work on page1060 has finished.
2017-08-24 06:41:38,133 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 06:41:38,133 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-24 06:41:53,958 - Task:Scrapy_bills - INFO - The work on page1062 has finished.
2017-08-24 06:41:58,752 - Task:Scrapy_bills - INFO - The work on page1063 has finished.
2017-08-24 06:42:03,420 - Task:Scrapy_bills - INFO - The work on page1064 has finished.
2017-08-24 06:42:08,491 - Task:Scrapy_bills - INFO - The work on page1065 has finished.
2017-08-24 06:42:13,307 - Task:Scrapy_bills - INFO - The work on page1066 has finished.
2017-08-24 06:43:35,524 - Task:Scrapy_bills - INFO - The work on page1067 has finished.
2017-08-24 06:46:52,990 - Task:Scrapy_bills - INFO - The work on page1068 has finished.
2017-08-24 06:50:08,441 - Task:Scrapy_bills - INFO - The work on page1069 has finished.
2017-08-24 06:50:09,076 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1061-1070.json
2017-08-24 06:53:33,515 - Task:Scrapy_bills - INFO - The work on page1070 has finished.
2017-08-24 06:56:55,745 - Task:Scrapy_bills - INFO - The work on page1071 has finished.
2017-08-24 07:00:13,376 - Task:Scrapy_bills - INFO - The work on page1072 has finished.
2017-08-24 07:03:40,719 - Task:Scrapy_bills - INFO - The work on page1073 has finished.
2017-08-24 07:07:05,787 - Task:Scrapy_bills - INFO - The work on page1074 has finished.
2017-08-24 07:08:13,827 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 07:08:13,829 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-24 07:08:29,667 - Task:Scrapy_bills - INFO - The work on page1076 has finished.
2017-08-24 07:11:57,913 - Task:Scrapy_bills - INFO - The work on page1077 has finished.
2017-08-24 07:15:18,340 - Task:Scrapy_bills - INFO - The work on page1078 has finished.
2017-08-24 07:18:35,568 - Task:Scrapy_bills - INFO - The work on page1079 has finished.
2017-08-24 07:18:36,333 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1071-1080.json
2017-08-24 07:21:55,201 - Task:Scrapy_bills - INFO - The work on page1080 has finished.
2017-08-24 07:25:18,093 - Task:Scrapy_bills - INFO - The work on page1081 has finished.
2017-08-24 07:28:32,652 - Task:Scrapy_bills - INFO - The work on page1082 has finished.
2017-08-24 07:31:50,911 - Task:Scrapy_bills - INFO - The work on page1083 has finished.
2017-08-24 07:35:12,311 - Task:Scrapy_bills - INFO - The work on page1084 has finished.
2017-08-24 07:38:35,706 - Task:Scrapy_bills - INFO - The work on page1085 has finished.
2017-08-24 07:41:57,431 - Task:Scrapy_bills - INFO - The work on page1086 has finished.
2017-08-24 07:45:18,905 - Task:Scrapy_bills - INFO - The work on page1087 has finished.
2017-08-24 07:48:44,673 - Task:Scrapy_bills - INFO - The work on page1088 has finished.
2017-08-24 07:52:03,510 - Task:Scrapy_bills - INFO - The work on page1089 has finished.
2017-08-24 07:52:04,262 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1081-1090.json
2017-08-24 07:55:27,515 - Task:Scrapy_bills - INFO - The work on page1090 has finished.
2017-08-24 07:58:53,315 - Task:Scrapy_bills - INFO - The work on page1091 has finished.
2017-08-24 08:02:17,215 - Task:Scrapy_bills - INFO - The work on page1092 has finished.
2017-08-24 08:05:44,166 - Task:Scrapy_bills - INFO - The work on page1093 has finished.
2017-08-24 08:09:09,487 - Task:Scrapy_bills - INFO - The work on page1094 has finished.
2017-08-24 08:12:28,634 - Task:Scrapy_bills - INFO - The work on page1095 has finished.
2017-08-24 08:16:00,733 - Task:Scrapy_bills - INFO - The work on page1096 has finished.
2017-08-24 08:19:31,575 - Task:Scrapy_bills - INFO - The work on page1097 has finished.
2017-08-24 08:23:24,738 - Task:Scrapy_bills - INFO - The work on page1098 has finished.
2017-08-24 08:27:04,212 - Task:Scrapy_bills - INFO - The work on page1099 has finished.
2017-08-24 08:27:05,025 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1091-1100.json
2017-08-24 08:30:52,331 - Task:Scrapy_bills - INFO - The work on page1100 has finished.
2017-08-24 08:34:26,383 - Task:Scrapy_bills - INFO - The work on page1101 has finished.
2017-08-24 08:38:00,494 - Task:Scrapy_bills - INFO - The work on page1102 has finished.
2017-08-24 08:41:39,757 - Task:Scrapy_bills - INFO - The work on page1103 has finished.
2017-08-24 08:45:09,458 - Task:Scrapy_bills - INFO - The work on page1104 has finished.
2017-08-24 08:48:41,645 - Task:Scrapy_bills - INFO - The work on page1105 has finished.
2017-08-24 08:52:11,172 - Task:Scrapy_bills - INFO - The work on page1106 has finished.
2017-08-24 08:55:33,159 - Task:Scrapy_bills - INFO - The work on page1107 has finished.
2017-08-24 08:58:57,216 - Task:Scrapy_bills - INFO - The work on page1108 has finished.
2017-08-24 09:02:30,901 - Task:Scrapy_bills - INFO - The work on page1109 has finished.
2017-08-24 09:02:31,716 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1101-1110.json
2017-08-24 09:06:18,967 - Task:Scrapy_bills - INFO - The work on page1110 has finished.
2017-08-24 09:09:49,386 - Task:Scrapy_bills - INFO - The work on page1111 has finished.
2017-08-24 09:13:18,016 - Task:Scrapy_bills - INFO - The work on page1112 has finished.
2017-08-24 09:16:43,954 - Task:Scrapy_bills - INFO - The work on page1113 has finished.
2017-08-24 09:20:09,306 - Task:Scrapy_bills - INFO - The work on page1114 has finished.
2017-08-24 09:23:42,181 - Task:Scrapy_bills - INFO - The work on page1115 has finished.
2017-08-24 09:27:21,971 - Task:Scrapy_bills - INFO - The work on page1116 has finished.
2017-08-24 09:31:33,007 - Task:Scrapy_bills - INFO - The work on page1117 has finished.
2017-08-24 09:35:12,705 - Task:Scrapy_bills - INFO - The work on page1118 has finished.
2017-08-24 09:38:55,239 - Task:Scrapy_bills - INFO - The work on page1119 has finished.
2017-08-24 09:38:56,055 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1111-1120.json
2017-08-24 09:42:42,844 - Task:Scrapy_bills - INFO - The work on page1120 has finished.
2017-08-24 09:46:30,975 - Task:Scrapy_bills - INFO - The work on page1121 has finished.
2017-08-24 09:50:08,563 - Task:Scrapy_bills - INFO - The work on page1122 has finished.
2017-08-24 09:53:34,690 - Task:Scrapy_bills - INFO - The work on page1123 has finished.
2017-08-24 09:57:04,176 - Task:Scrapy_bills - INFO - The work on page1124 has finished.
2017-08-24 10:00:33,747 - Task:Scrapy_bills - INFO - The work on page1125 has finished.
2017-08-24 10:04:10,184 - Task:Scrapy_bills - INFO - The work on page1126 has finished.
2017-08-24 10:07:48,247 - Task:Scrapy_bills - INFO - The work on page1127 has finished.
2017-08-24 10:11:19,332 - Task:Scrapy_bills - INFO - The work on page1128 has finished.
2017-08-24 10:14:45,704 - Task:Scrapy_bills - INFO - The work on page1129 has finished.
2017-08-24 10:14:46,522 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1121-1130.json
2017-08-24 10:18:18,848 - Task:Scrapy_bills - INFO - The work on page1130 has finished.
2017-08-24 10:21:47,656 - Task:Scrapy_bills - INFO - The work on page1131 has finished.
2017-08-24 10:22:25,187 - Task:Scrapy_bills - INFO - The work on page1132 has finished.
2017-08-24 10:23:10,602 - Task:Scrapy_bills - INFO - The work on page1133 has finished.
2017-08-24 10:26:37,628 - Task:Scrapy_bills - INFO - The work on page1134 has finished.
2017-08-24 10:30:07,715 - Task:Scrapy_bills - INFO - The work on page1135 has finished.
2017-08-24 10:33:41,402 - Task:Scrapy_bills - INFO - The work on page1136 has finished.
2017-08-24 10:37:16,445 - Task:Scrapy_bills - INFO - The work on page1137 has finished.
2017-08-24 10:40:50,381 - Task:Scrapy_bills - INFO - The work on page1138 has finished.
2017-08-24 10:44:20,051 - Task:Scrapy_bills - INFO - The work on page1139 has finished.
2017-08-24 10:44:20,807 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1131-1140.json
2017-08-24 10:47:43,411 - Task:Scrapy_bills - INFO - The work on page1140 has finished.
2017-08-24 10:51:01,927 - Task:Scrapy_bills - INFO - The work on page1141 has finished.
2017-08-24 10:54:21,333 - Task:Scrapy_bills - INFO - The work on page1142 has finished.
2017-08-24 10:57:38,401 - Task:Scrapy_bills - INFO - The work on page1143 has finished.
2017-08-24 11:00:53,798 - Task:Scrapy_bills - INFO - The work on page1144 has finished.
2017-08-24 11:04:10,772 - Task:Scrapy_bills - INFO - The work on page1145 has finished.
2017-08-24 11:07:26,673 - Task:Scrapy_bills - INFO - The work on page1146 has finished.
2017-08-24 11:10:42,819 - Task:Scrapy_bills - INFO - The work on page1147 has finished.
2017-08-24 11:14:11,628 - Task:Scrapy_bills - INFO - The work on page1148 has finished.
2017-08-24 11:17:31,322 - Task:Scrapy_bills - INFO - The work on page1149 has finished.
2017-08-24 11:17:32,071 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1141-1150.json
2017-08-24 11:20:51,553 - Task:Scrapy_bills - INFO - The work on page1150 has finished.
2017-08-24 11:24:12,123 - Task:Scrapy_bills - INFO - The work on page1151 has finished.
2017-08-24 11:27:30,698 - Task:Scrapy_bills - INFO - The work on page1152 has finished.
2017-08-24 11:30:49,171 - Task:Scrapy_bills - INFO - The work on page1153 has finished.
2017-08-24 11:34:11,368 - Task:Scrapy_bills - INFO - The work on page1154 has finished.
2017-08-24 11:37:31,962 - Task:Scrapy_bills - INFO - The work on page1155 has finished.
2017-08-24 11:40:57,995 - Task:Scrapy_bills - INFO - The work on page1156 has finished.
2017-08-24 11:44:23,014 - Task:Scrapy_bills - INFO - The work on page1157 has finished.
2017-08-24 11:47:52,179 - Task:Scrapy_bills - INFO - The work on page1158 has finished.
2017-08-24 11:51:19,442 - Task:Scrapy_bills - INFO - The work on page1159 has finished.
2017-08-24 11:51:20,202 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1151-1160.json
2017-08-24 11:54:46,719 - Task:Scrapy_bills - INFO - The work on page1160 has finished.
2017-08-24 11:58:12,187 - Task:Scrapy_bills - INFO - The work on page1161 has finished.
2017-08-24 12:01:33,708 - Task:Scrapy_bills - INFO - The work on page1162 has finished.
2017-08-24 12:04:58,042 - Task:Scrapy_bills - INFO - The work on page1163 has finished.
2017-08-24 12:08:51,308 - Task:Scrapy_bills - INFO - The work on page1164 has finished.
2017-08-24 12:12:17,091 - Task:Scrapy_bills - INFO - The work on page1165 has finished.
2017-08-24 12:15:43,570 - Task:Scrapy_bills - INFO - The work on page1166 has finished.
2017-08-24 12:19:01,626 - Task:Scrapy_bills - INFO - The work on page1167 has finished.
2017-08-24 12:22:22,477 - Task:Scrapy_bills - INFO - The work on page1168 has finished.
2017-08-24 12:25:49,716 - Task:Scrapy_bills - INFO - The work on page1169 has finished.
2017-08-24 12:25:50,605 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1161-1170.json
2017-08-24 12:29:12,631 - Task:Scrapy_bills - INFO - The work on page1170 has finished.
2017-08-24 12:31:19,030 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 12:31:19,032 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 12:31:59,709 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 12:31:59,709 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 12:32:40,643 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 12:32:40,645 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 12:33:21,536 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 12:33:21,537 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 12:34:02,222 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 12:34:02,224 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 12:37:23,820 - Task:Scrapy_bills - INFO - The work on page1171 has finished.
2017-08-24 12:40:58,512 - Task:Scrapy_bills - INFO - The work on page1172 has finished.
2017-08-24 12:44:20,724 - Task:Scrapy_bills - INFO - The work on page1173 has finished.
2017-08-24 12:47:41,572 - Task:Scrapy_bills - INFO - The work on page1174 has finished.
2017-08-24 12:51:03,688 - Task:Scrapy_bills - INFO - The work on page1175 has finished.
2017-08-24 12:54:23,253 - Task:Scrapy_bills - INFO - The work on page1176 has finished.
2017-08-24 12:57:45,751 - Task:Scrapy_bills - INFO - The work on page1177 has finished.
2017-08-24 13:01:01,498 - Task:Scrapy_bills - INFO - The work on page1178 has finished.
2017-08-24 13:04:27,745 - Task:Scrapy_bills - INFO - The work on page1179 has finished.
2017-08-24 13:04:28,489 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1171-1180.json
2017-08-24 13:08:16,799 - Task:Scrapy_bills - INFO - The work on page1180 has finished.
2017-08-24 13:12:35,761 - Task:Scrapy_bills - INFO - The work on page1181 has finished.
2017-08-24 13:16:58,631 - Task:Scrapy_bills - INFO - The work on page1182 has finished.
2017-08-24 13:21:11,878 - Task:Scrapy_bills - INFO - The work on page1183 has finished.
2017-08-24 13:25:22,200 - Task:Scrapy_bills - INFO - The work on page1184 has finished.
2017-08-24 13:29:33,959 - Task:Scrapy_bills - INFO - The work on page1185 has finished.
2017-08-24 13:33:31,537 - Task:Scrapy_bills - INFO - The work on page1186 has finished.
2017-08-24 13:37:26,711 - Task:Scrapy_bills - INFO - The work on page1187 has finished.
2017-08-24 13:41:15,229 - Task:Scrapy_bills - INFO - The work on page1188 has finished.
2017-08-24 13:44:59,584 - Task:Scrapy_bills - INFO - The work on page1189 has finished.
2017-08-24 13:45:00,333 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1181-1190.json
2017-08-24 13:48:49,633 - Task:Scrapy_bills - INFO - The work on page1190 has finished.
2017-08-24 13:52:26,819 - Task:Scrapy_bills - INFO - The work on page1191 has finished.
2017-08-24 13:55:43,719 - Task:Scrapy_bills - INFO - The work on page1192 has finished.
2017-08-24 13:58:51,127 - Task:Scrapy_bills - INFO - The work on page1193 has finished.
2017-08-24 14:01:58,297 - Task:Scrapy_bills - INFO - The work on page1194 has finished.
2017-08-24 14:05:15,323 - Task:Scrapy_bills - INFO - The work on page1195 has finished.
2017-08-24 14:08:30,320 - Task:Scrapy_bills - INFO - The work on page1196 has finished.
2017-08-24 14:11:36,055 - Task:Scrapy_bills - INFO - The work on page1197 has finished.
2017-08-24 14:14:48,894 - Task:Scrapy_bills - INFO - The work on page1198 has finished.
2017-08-24 14:17:57,566 - Task:Scrapy_bills - INFO - The work on page1199 has finished.
2017-08-24 14:17:58,372 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1191-1200.json
2017-08-24 14:21:09,396 - Task:Scrapy_bills - INFO - The work on page1200 has finished.
2017-08-24 14:24:18,793 - Task:Scrapy_bills - INFO - The work on page1201 has finished.
2017-08-24 14:27:23,885 - Task:Scrapy_bills - INFO - The work on page1202 has finished.
2017-08-24 14:30:29,492 - Task:Scrapy_bills - INFO - The work on page1203 has finished.
2017-08-24 14:33:38,378 - Task:Scrapy_bills - INFO - The work on page1204 has finished.
2017-08-24 14:36:42,805 - Task:Scrapy_bills - INFO - The work on page1205 has finished.
2017-08-24 14:39:49,272 - Task:Scrapy_bills - INFO - The work on page1206 has finished.
2017-08-24 14:42:55,928 - Task:Scrapy_bills - INFO - The work on page1207 has finished.
2017-08-24 14:46:05,950 - Task:Scrapy_bills - INFO - The work on page1208 has finished.
2017-08-24 14:49:13,909 - Task:Scrapy_bills - INFO - The work on page1209 has finished.
2017-08-24 14:49:14,751 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1201-1210.json
2017-08-24 14:52:22,831 - Task:Scrapy_bills - INFO - The work on page1210 has finished.
2017-08-24 14:52:57,631 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 14:52:57,633 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 14:56:15,347 - Task:Scrapy_bills - INFO - The work on page1211 has finished.
2017-08-24 14:59:21,279 - Task:Scrapy_bills - INFO - The work on page1212 has finished.
2017-08-24 15:02:28,414 - Task:Scrapy_bills - INFO - The work on page1213 has finished.
2017-08-24 15:05:43,132 - Task:Scrapy_bills - INFO - The work on page1214 has finished.
2017-08-24 15:08:51,839 - Task:Scrapy_bills - INFO - The work on page1215 has finished.
2017-08-24 15:12:00,338 - Task:Scrapy_bills - INFO - The work on page1216 has finished.
2017-08-24 15:15:06,866 - Task:Scrapy_bills - INFO - The work on page1217 has finished.
2017-08-24 15:18:15,181 - Task:Scrapy_bills - INFO - The work on page1218 has finished.
2017-08-24 15:21:25,935 - Task:Scrapy_bills - INFO - The work on page1219 has finished.
2017-08-24 15:21:26,777 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1211-1220.json
2017-08-24 15:24:40,596 - Task:Scrapy_bills - INFO - The work on page1220 has finished.
2017-08-24 15:27:46,994 - Task:Scrapy_bills - INFO - The work on page1221 has finished.
2017-08-24 15:30:55,413 - Task:Scrapy_bills - INFO - The work on page1222 has finished.
2017-08-24 15:35:47,973 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:35:47,976 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 15:35:57,977 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:35:57,978 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:07,979 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:07,979 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:17,979 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:17,980 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:27,981 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:27,982 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:37,982 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:37,983 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:47,985 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:47,985 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:36:58,030 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:36:58,032 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:08,034 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:08,036 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:18,038 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:18,041 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:28,043 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:28,045 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:38,047 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:38,049 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:48,052 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:48,054 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:37:58,056 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:37:58,058 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:08,060 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:08,062 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:18,065 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:18,068 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:28,069 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:28,072 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:38,074 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:38,076 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:48,077 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:48,080 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:38:58,081 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:38:58,083 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:39:08,086 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:39:08,088 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:39:18,090 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:39:18,093 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:39:32,078 - Task:Scrapy_bills - INFO - The work on page1223 has finished.
2017-08-24 15:39:32,584 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 15:39:32,585 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-08-24 15:42:55,381 - Task:Scrapy_bills - INFO - The work on page1224 has finished.
2017-08-24 15:46:19,399 - Task:Scrapy_bills - INFO - The work on page1225 has finished.
2017-08-24 15:49:39,551 - Task:Scrapy_bills - INFO - The work on page1226 has finished.
2017-08-24 15:53:10,947 - Task:Scrapy_bills - INFO - The work on page1227 has finished.
2017-08-24 15:56:33,777 - Task:Scrapy_bills - INFO - The work on page1228 has finished.
2017-08-24 15:59:58,408 - Task:Scrapy_bills - INFO - The work on page1229 has finished.
2017-08-24 15:59:59,237 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1221-1230.json
2017-08-24 16:03:26,602 - Task:Scrapy_bills - INFO - The work on page1230 has finished.
2017-08-24 16:06:48,070 - Task:Scrapy_bills - INFO - The work on page1231 has finished.
2017-08-24 16:10:09,454 - Task:Scrapy_bills - INFO - The work on page1232 has finished.
2017-08-24 16:13:18,317 - Task:Scrapy_bills - INFO - The work on page1233 has finished.
2017-08-24 16:16:45,229 - Task:Scrapy_bills - INFO - The work on page1234 has finished.
2017-08-24 16:20:07,781 - Task:Scrapy_bills - INFO - The work on page1235 has finished.
2017-08-24 16:23:31,149 - Task:Scrapy_bills - INFO - The work on page1236 has finished.
2017-08-24 16:26:54,410 - Task:Scrapy_bills - INFO - The work on page1237 has finished.
2017-08-24 16:30:16,196 - Task:Scrapy_bills - INFO - The work on page1238 has finished.
2017-08-24 16:33:34,916 - Task:Scrapy_bills - INFO - The work on page1239 has finished.
2017-08-24 16:33:35,774 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1231-1240.json
2017-08-24 16:36:56,964 - Task:Scrapy_bills - INFO - The work on page1240 has finished.
2017-08-24 16:39:49,379 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 16:39:49,382 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 16:40:09,122 - Task:Scrapy_bills - INFO - The work on page1242 has finished.
2017-08-24 16:43:35,391 - Task:Scrapy_bills - INFO - The work on page1243 has finished.
2017-08-24 16:46:58,061 - Task:Scrapy_bills - INFO - The work on page1244 has finished.
2017-08-24 16:48:15,431 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 16:48:15,432 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 16:48:34,213 - Task:Scrapy_bills - INFO - The work on page1246 has finished.
2017-08-24 16:49:17,096 - Task:Scrapy_bills - INFO - The work on page1247 has finished.
2017-08-24 16:49:21,993 - Task:Scrapy_bills - INFO - The work on page1248 has finished.
2017-08-24 16:49:27,207 - Task:Scrapy_bills - INFO - The work on page1249 has finished.
2017-08-24 16:49:27,872 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1241-1250.json
2017-08-24 16:49:38,210 - Task:Scrapy_bills - INFO - The work on page1250 has finished.
2017-08-24 16:49:46,257 - Task:Scrapy_bills - INFO - The work on page1251 has finished.
2017-08-24 16:49:53,809 - Task:Scrapy_bills - INFO - The work on page1252 has finished.
2017-08-24 16:52:22,057 - Task:Scrapy_bills - INFO - The work on page1253 has finished.
2017-08-24 16:55:43,195 - Task:Scrapy_bills - INFO - The work on page1254 has finished.
2017-08-24 16:58:59,675 - Task:Scrapy_bills - INFO - The work on page1255 has finished.
2017-08-24 17:02:08,608 - Task:Scrapy_bills - INFO - The work on page1256 has finished.
2017-08-24 17:05:24,790 - Task:Scrapy_bills - INFO - The work on page1257 has finished.
2017-08-24 17:07:06,974 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 17:07:06,975 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

2017-08-24 17:07:25,832 - Task:Scrapy_bills - INFO - The work on page1259 has finished.
2017-08-24 17:07:26,529 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1251-1260.json
2017-08-24 17:10:42,601 - Task:Scrapy_bills - INFO - The work on page1260 has finished.
2017-08-24 17:13:07,400 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 17:13:07,402 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

2017-08-24 17:13:23,276 - Task:Scrapy_bills - INFO - The work on page1262 has finished.
2017-08-24 17:17:21,498 - Task:Scrapy_bills - INFO - The work on page1263 has finished.
2017-08-24 17:19:00,225 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 17:19:00,227 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 17:22:37,354 - Task:Scrapy_bills - INFO - The work on page1264 has finished.
2017-08-24 17:26:28,187 - Task:Scrapy_bills - INFO - The work on page1265 has finished.
2017-08-24 17:30:09,979 - Task:Scrapy_bills - INFO - The work on page1266 has finished.
2017-08-24 17:34:00,055 - Task:Scrapy_bills - INFO - The work on page1267 has finished.
2017-08-24 17:37:41,141 - Task:Scrapy_bills - INFO - The work on page1268 has finished.
2017-08-24 17:41:24,406 - Task:Scrapy_bills - INFO - The work on page1269 has finished.
2017-08-24 17:41:25,153 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1261-1270.json
2017-08-24 17:44:43,668 - Task:Scrapy_bills - INFO - The work on page1270 has finished.
2017-08-24 17:47:52,997 - Task:Scrapy_bills - INFO - The work on page1271 has finished.
2017-08-24 17:51:12,492 - Task:Scrapy_bills - INFO - The work on page1272 has finished.
2017-08-24 17:54:30,252 - Task:Scrapy_bills - INFO - The work on page1273 has finished.
2017-08-24 17:57:41,651 - Task:Scrapy_bills - INFO - The work on page1274 has finished.
2017-08-24 18:01:02,685 - Task:Scrapy_bills - INFO - The work on page1275 has finished.
2017-08-24 18:04:21,683 - Task:Scrapy_bills - INFO - The work on page1276 has finished.
2017-08-24 18:07:40,040 - Task:Scrapy_bills - INFO - The work on page1277 has finished.
2017-08-24 18:10:56,604 - Task:Scrapy_bills - INFO - The work on page1278 has finished.
2017-08-24 18:11:33,571 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 18:11:33,573 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 18:15:00,165 - Task:Scrapy_bills - INFO - The work on page1279 has finished.
2017-08-24 18:15:00,989 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1271-1280.json
2017-08-24 18:18:35,420 - Task:Scrapy_bills - INFO - The work on page1280 has finished.
2017-08-24 18:21:54,648 - Task:Scrapy_bills - INFO - The work on page1281 has finished.
2017-08-24 18:25:12,345 - Task:Scrapy_bills - INFO - The work on page1282 has finished.
2017-08-24 18:28:27,896 - Task:Scrapy_bills - INFO - The work on page1283 has finished.
2017-08-24 18:31:45,017 - Task:Scrapy_bills - INFO - The work on page1284 has finished.
2017-08-24 18:34:57,190 - Task:Scrapy_bills - INFO - The work on page1285 has finished.
2017-08-24 18:38:12,162 - Task:Scrapy_bills - INFO - The work on page1286 has finished.
2017-08-24 18:41:25,555 - Task:Scrapy_bills - INFO - The work on page1287 has finished.
2017-08-24 18:44:41,205 - Task:Scrapy_bills - INFO - The work on page1288 has finished.
2017-08-24 18:47:56,597 - Task:Scrapy_bills - INFO - The work on page1289 has finished.
2017-08-24 18:47:57,423 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1281-1290.json
2017-08-24 18:51:18,195 - Task:Scrapy_bills - INFO - The work on page1290 has finished.
2017-08-24 18:54:33,049 - Task:Scrapy_bills - INFO - The work on page1291 has finished.
2017-08-24 18:57:47,808 - Task:Scrapy_bills - INFO - The work on page1292 has finished.
2017-08-24 19:01:07,275 - Task:Scrapy_bills - INFO - The work on page1293 has finished.
2017-08-24 19:04:27,014 - Task:Scrapy_bills - INFO - The work on page1294 has finished.
2017-08-24 19:07:43,100 - Task:Scrapy_bills - INFO - The work on page1295 has finished.
2017-08-24 19:11:00,253 - Task:Scrapy_bills - INFO - The work on page1296 has finished.
2017-08-24 19:14:16,711 - Task:Scrapy_bills - INFO - The work on page1297 has finished.
2017-08-24 19:17:30,780 - Task:Scrapy_bills - INFO - The work on page1298 has finished.
2017-08-24 19:20:42,017 - Task:Scrapy_bills - INFO - The work on page1299 has finished.
2017-08-24 19:20:42,838 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1291-1300.json
2017-08-24 19:22:42,000 - Task:Scrapy_bills - INFO - The work on page1300 has finished.
2017-08-24 19:22:46,632 - Task:Scrapy_bills - INFO - The work on page1301 has finished.
2017-08-24 19:24:28,878 - Task:Scrapy_bills - INFO - The work on page1302 has finished.
2017-08-24 19:27:42,112 - Task:Scrapy_bills - INFO - The work on page1303 has finished.
2017-08-24 19:30:53,640 - Task:Scrapy_bills - INFO - The work on page1304 has finished.
2017-08-24 19:34:07,829 - Task:Scrapy_bills - INFO - The work on page1305 has finished.
2017-08-24 19:37:19,335 - Task:Scrapy_bills - INFO - The work on page1306 has finished.
2017-08-24 19:40:34,690 - Task:Scrapy_bills - INFO - The work on page1307 has finished.
2017-08-24 19:43:52,367 - Task:Scrapy_bills - INFO - The work on page1308 has finished.
2017-08-24 19:47:12,760 - Task:Scrapy_bills - INFO - The work on page1309 has finished.
2017-08-24 19:47:13,504 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1301-1310.json
2017-08-24 19:50:33,884 - Task:Scrapy_bills - INFO - The work on page1310 has finished.
2017-08-24 19:53:49,206 - Task:Scrapy_bills - INFO - The work on page1311 has finished.
2017-08-24 19:57:02,663 - Task:Scrapy_bills - INFO - The work on page1312 has finished.
2017-08-24 20:00:17,012 - Task:Scrapy_bills - INFO - The work on page1313 has finished.
2017-08-24 20:03:35,729 - Task:Scrapy_bills - INFO - The work on page1314 has finished.
2017-08-24 20:06:53,232 - Task:Scrapy_bills - INFO - The work on page1315 has finished.
2017-08-24 20:10:11,325 - Task:Scrapy_bills - INFO - The work on page1316 has finished.
2017-08-24 20:13:30,466 - Task:Scrapy_bills - INFO - The work on page1317 has finished.
2017-08-24 20:16:48,745 - Task:Scrapy_bills - INFO - The work on page1318 has finished.
2017-08-24 20:20:07,032 - Task:Scrapy_bills - INFO - The work on page1319 has finished.
2017-08-24 20:20:07,785 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1311-1320.json
2017-08-24 20:23:28,432 - Task:Scrapy_bills - INFO - The work on page1320 has finished.
2017-08-24 20:26:46,357 - Task:Scrapy_bills - INFO - The work on page1321 has finished.
2017-08-24 20:30:09,047 - Task:Scrapy_bills - INFO - The work on page1322 has finished.
2017-08-24 20:33:34,872 - Task:Scrapy_bills - INFO - The work on page1323 has finished.
2017-08-24 20:37:02,266 - Task:Scrapy_bills - INFO - The work on page1324 has finished.
2017-08-24 20:40:22,269 - Task:Scrapy_bills - INFO - The work on page1325 has finished.
2017-08-24 20:43:39,974 - Task:Scrapy_bills - INFO - The work on page1326 has finished.
2017-08-24 20:46:55,689 - Task:Scrapy_bills - INFO - The work on page1327 has finished.
2017-08-24 20:50:11,832 - Task:Scrapy_bills - INFO - The work on page1328 has finished.
2017-08-24 20:53:27,012 - Task:Scrapy_bills - INFO - The work on page1329 has finished.
2017-08-24 20:53:27,756 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1321-1330.json
2017-08-24 20:56:46,016 - Task:Scrapy_bills - INFO - The work on page1330 has finished.
2017-08-24 21:00:00,914 - Task:Scrapy_bills - INFO - The work on page1331 has finished.
2017-08-24 21:03:45,643 - Task:Scrapy_bills - INFO - The work on page1332 has finished.
2017-08-24 21:09:48,532 - Task:Scrapy_bills - INFO - The work on page1333 has finished.
2017-08-24 21:13:14,993 - Task:Scrapy_bills - INFO - The work on page1334 has finished.
2017-08-24 21:16:36,443 - Task:Scrapy_bills - INFO - The work on page1335 has finished.
2017-08-24 21:20:26,477 - Task:Scrapy_bills - INFO - The work on page1336 has finished.
2017-08-24 21:23:44,513 - Task:Scrapy_bills - INFO - The work on page1337 has finished.
2017-08-24 21:27:06,525 - Task:Scrapy_bills - INFO - The work on page1338 has finished.
2017-08-24 21:30:39,010 - Task:Scrapy_bills - INFO - The work on page1339 has finished.
2017-08-24 21:30:39,761 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1331-1340.json
2017-08-24 21:33:58,907 - Task:Scrapy_bills - INFO - The work on page1340 has finished.
2017-08-24 21:37:17,095 - Task:Scrapy_bills - INFO - The work on page1341 has finished.
2017-08-24 21:40:36,223 - Task:Scrapy_bills - INFO - The work on page1342 has finished.
2017-08-24 21:43:53,359 - Task:Scrapy_bills - INFO - The work on page1343 has finished.
2017-08-24 21:47:15,074 - Task:Scrapy_bills - INFO - The work on page1344 has finished.
2017-08-24 21:50:33,222 - Task:Scrapy_bills - INFO - The work on page1345 has finished.
2017-08-24 21:53:52,152 - Task:Scrapy_bills - INFO - The work on page1346 has finished.
2017-08-24 21:57:11,874 - Task:Scrapy_bills - INFO - The work on page1347 has finished.
2017-08-24 22:00:26,590 - Task:Scrapy_bills - INFO - The work on page1348 has finished.
2017-08-24 22:03:36,077 - Task:Scrapy_bills - INFO - The work on page1349 has finished.
2017-08-24 22:03:36,829 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1341-1350.json
2017-08-24 22:06:50,602 - Task:Scrapy_bills - INFO - The work on page1350 has finished.
2017-08-24 22:10:02,885 - Task:Scrapy_bills - INFO - The work on page1351 has finished.
2017-08-24 22:13:12,946 - Task:Scrapy_bills - INFO - The work on page1352 has finished.
2017-08-24 22:16:21,948 - Task:Scrapy_bills - INFO - The work on page1353 has finished.
2017-08-24 22:19:31,972 - Task:Scrapy_bills - INFO - The work on page1354 has finished.
2017-08-24 22:22:44,821 - Task:Scrapy_bills - INFO - The work on page1355 has finished.
2017-08-24 22:25:54,384 - Task:Scrapy_bills - INFO - The work on page1356 has finished.
2017-08-24 22:29:06,205 - Task:Scrapy_bills - INFO - The work on page1357 has finished.
2017-08-24 22:32:17,692 - Task:Scrapy_bills - INFO - The work on page1358 has finished.
2017-08-24 22:35:31,738 - Task:Scrapy_bills - INFO - The work on page1359 has finished.
2017-08-24 22:35:32,555 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1351-1360.json
2017-08-24 22:38:42,889 - Task:Scrapy_bills - INFO - The work on page1360 has finished.
2017-08-24 22:41:52,966 - Task:Scrapy_bills - INFO - The work on page1361 has finished.
2017-08-24 22:45:04,696 - Task:Scrapy_bills - INFO - The work on page1362 has finished.
2017-08-24 22:48:12,542 - Task:Scrapy_bills - INFO - The work on page1363 has finished.
2017-08-24 22:51:22,695 - Task:Scrapy_bills - INFO - The work on page1364 has finished.
2017-08-24 22:51:57,565 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 22:51:57,567 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 22:55:16,881 - Task:Scrapy_bills - INFO - The work on page1365 has finished.
2017-08-24 22:58:32,666 - Task:Scrapy_bills - INFO - The work on page1366 has finished.
2017-08-24 22:59:07,802 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-24 22:59:07,804 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-24 23:02:27,745 - Task:Scrapy_bills - INFO - The work on page1367 has finished.
2017-08-24 23:05:36,619 - Task:Scrapy_bills - INFO - The work on page1368 has finished.
2017-08-24 23:08:43,883 - Task:Scrapy_bills - INFO - The work on page1369 has finished.
2017-08-24 23:08:44,704 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1361-1370.json
2017-08-24 23:11:56,468 - Task:Scrapy_bills - INFO - The work on page1370 has finished.
2017-08-24 23:15:13,545 - Task:Scrapy_bills - INFO - The work on page1371 has finished.
2017-08-24 23:18:23,684 - Task:Scrapy_bills - INFO - The work on page1372 has finished.
2017-08-24 23:21:37,068 - Task:Scrapy_bills - INFO - The work on page1373 has finished.
2017-08-24 23:24:47,937 - Task:Scrapy_bills - INFO - The work on page1374 has finished.
2017-08-24 23:27:59,266 - Task:Scrapy_bills - INFO - The work on page1375 has finished.
2017-08-24 23:31:10,905 - Task:Scrapy_bills - INFO - The work on page1376 has finished.
2017-08-24 23:34:19,636 - Task:Scrapy_bills - INFO - The work on page1377 has finished.
2017-08-24 23:37:31,128 - Task:Scrapy_bills - INFO - The work on page1378 has finished.
2017-08-24 23:40:42,851 - Task:Scrapy_bills - INFO - The work on page1379 has finished.
2017-08-24 23:40:43,671 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1371-1380.json
2017-08-24 23:43:57,353 - Task:Scrapy_bills - INFO - The work on page1380 has finished.
2017-08-24 23:47:16,705 - Task:Scrapy_bills - INFO - The work on page1381 has finished.
2017-08-24 23:50:28,749 - Task:Scrapy_bills - INFO - The work on page1382 has finished.
2017-08-24 23:53:40,396 - Task:Scrapy_bills - INFO - The work on page1383 has finished.
2017-08-24 23:56:51,827 - Task:Scrapy_bills - INFO - The work on page1384 has finished.
2017-08-25 00:00:04,068 - Task:Scrapy_bills - INFO - The work on page1385 has finished.
2017-08-25 00:03:16,816 - Task:Scrapy_bills - INFO - The work on page1386 has finished.
2017-08-25 00:06:33,861 - Task:Scrapy_bills - INFO - The work on page1387 has finished.
2017-08-25 00:09:45,915 - Task:Scrapy_bills - INFO - The work on page1388 has finished.
2017-08-25 00:12:55,907 - Task:Scrapy_bills - INFO - The work on page1389 has finished.
2017-08-25 00:12:56,730 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1381-1390.json
2017-08-25 00:16:05,700 - Task:Scrapy_bills - INFO - The work on page1390 has finished.
2017-08-25 00:19:17,752 - Task:Scrapy_bills - INFO - The work on page1391 has finished.
2017-08-25 00:22:31,425 - Task:Scrapy_bills - INFO - The work on page1392 has finished.
2017-08-25 00:25:40,911 - Task:Scrapy_bills - INFO - The work on page1393 has finished.
2017-08-25 00:29:01,093 - Task:Scrapy_bills - INFO - The work on page1394 has finished.
2017-08-25 00:32:09,884 - Task:Scrapy_bills - INFO - The work on page1395 has finished.
2017-08-25 00:35:26,551 - Task:Scrapy_bills - INFO - The work on page1396 has finished.
2017-08-25 00:38:36,291 - Task:Scrapy_bills - INFO - The work on page1397 has finished.
2017-08-25 00:41:52,035 - Task:Scrapy_bills - INFO - The work on page1398 has finished.
2017-08-25 00:45:02,836 - Task:Scrapy_bills - INFO - The work on page1399 has finished.
2017-08-25 00:45:03,638 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1391-1400.json
2017-08-25 00:48:13,396 - Task:Scrapy_bills - INFO - The work on page1400 has finished.
2017-08-25 00:51:21,920 - Task:Scrapy_bills - INFO - The work on page1401 has finished.
2017-08-25 00:54:37,307 - Task:Scrapy_bills - INFO - The work on page1402 has finished.
2017-08-25 00:57:47,955 - Task:Scrapy_bills - INFO - The work on page1403 has finished.
2017-08-25 01:00:57,487 - Task:Scrapy_bills - INFO - The work on page1404 has finished.
2017-08-25 01:03:31,962 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-25 01:03:31,962 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-25 01:03:48,016 - Task:Scrapy_bills - INFO - The work on page1406 has finished.
2017-08-25 01:03:55,254 - Task:Scrapy_bills - INFO - The work on page1407 has finished.
2017-08-25 01:04:00,144 - Task:Scrapy_bills - INFO - The work on page1408 has finished.
2017-08-25 01:04:04,995 - Task:Scrapy_bills - INFO - The work on page1409 has finished.
2017-08-25 01:04:05,689 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1401-1410.json
2017-08-25 01:04:12,195 - Task:Scrapy_bills - INFO - The work on page1410 has finished.
2017-08-25 01:04:16,939 - Task:Scrapy_bills - INFO - The work on page1411 has finished.
2017-08-25 01:06:21,378 - Task:Scrapy_bills - INFO - The work on page1412 has finished.
2017-08-25 01:09:31,044 - Task:Scrapy_bills - INFO - The work on page1413 has finished.
2017-08-25 01:12:37,488 - Task:Scrapy_bills - INFO - The work on page1414 has finished.
2017-08-25 01:15:44,956 - Task:Scrapy_bills - INFO - The work on page1415 has finished.
2017-08-25 01:18:51,566 - Task:Scrapy_bills - INFO - The work on page1416 has finished.
2017-08-25 01:21:57,157 - Task:Scrapy_bills - INFO - The work on page1417 has finished.
2017-08-25 01:25:05,845 - Task:Scrapy_bills - INFO - The work on page1418 has finished.
2017-08-25 01:28:21,921 - Task:Scrapy_bills - INFO - The work on page1419 has finished.
2017-08-25 01:28:22,663 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1411-1420.json
2017-08-25 01:31:42,434 - Task:Scrapy_bills - INFO - The work on page1420 has finished.
2017-08-25 01:34:58,067 - Task:Scrapy_bills - INFO - The work on page1421 has finished.
2017-08-25 01:38:11,594 - Task:Scrapy_bills - INFO - The work on page1422 has finished.
2017-08-25 01:41:25,078 - Task:Scrapy_bills - INFO - The work on page1423 has finished.
2017-08-25 01:44:42,798 - Task:Scrapy_bills - INFO - The work on page1424 has finished.
2017-08-25 01:47:48,406 - Task:Scrapy_bills - INFO - The work on page1425 has finished.
2017-08-25 01:50:56,174 - Task:Scrapy_bills - INFO - The work on page1426 has finished.
2017-08-25 01:54:05,342 - Task:Scrapy_bills - INFO - The work on page1427 has finished.
2017-08-25 01:57:12,285 - Task:Scrapy_bills - INFO - The work on page1428 has finished.
2017-08-25 02:00:19,514 - Task:Scrapy_bills - INFO - The work on page1429 has finished.
2017-08-25 02:00:20,303 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1421-1430.json
2017-08-25 02:03:28,743 - Task:Scrapy_bills - INFO - The work on page1430 has finished.
2017-08-25 02:06:37,755 - Task:Scrapy_bills - INFO - The work on page1431 has finished.
2017-08-25 02:09:43,425 - Task:Scrapy_bills - INFO - The work on page1432 has finished.
2017-08-25 02:12:48,045 - Task:Scrapy_bills - INFO - The work on page1433 has finished.
2017-08-25 02:15:57,353 - Task:Scrapy_bills - INFO - The work on page1434 has finished.
2017-08-25 02:19:02,150 - Task:Scrapy_bills - INFO - The work on page1435 has finished.
2017-08-25 02:22:09,723 - Task:Scrapy_bills - INFO - The work on page1436 has finished.
2017-08-25 02:25:19,915 - Task:Scrapy_bills - INFO - The work on page1437 has finished.
2017-08-25 02:28:28,281 - Task:Scrapy_bills - INFO - The work on page1438 has finished.
2017-08-25 02:31:35,508 - Task:Scrapy_bills - INFO - The work on page1439 has finished.
2017-08-25 02:31:36,316 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1431-1440.json
2017-08-25 02:34:44,955 - Task:Scrapy_bills - INFO - The work on page1440 has finished.
2017-08-25 02:37:56,696 - Task:Scrapy_bills - INFO - The work on page1441 has finished.
2017-08-25 02:41:12,272 - Task:Scrapy_bills - INFO - The work on page1442 has finished.
2017-08-25 02:44:19,786 - Task:Scrapy_bills - INFO - The work on page1443 has finished.
2017-08-25 02:47:29,479 - Task:Scrapy_bills - INFO - The work on page1444 has finished.
2017-08-25 02:50:37,010 - Task:Scrapy_bills - INFO - The work on page1445 has finished.
2017-08-25 02:53:48,787 - Task:Scrapy_bills - INFO - The work on page1446 has finished.
2017-08-25 02:56:59,962 - Task:Scrapy_bills - INFO - The work on page1447 has finished.
2017-08-25 03:00:08,057 - Task:Scrapy_bills - INFO - The work on page1448 has finished.
2017-08-25 03:03:18,675 - Task:Scrapy_bills - INFO - The work on page1449 has finished.
2017-08-25 03:03:19,484 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1441-1450.json
2017-08-25 03:06:30,738 - Task:Scrapy_bills - INFO - The work on page1450 has finished.
2017-08-25 03:09:42,435 - Task:Scrapy_bills - INFO - The work on page1451 has finished.
2017-08-25 03:12:47,969 - Task:Scrapy_bills - INFO - The work on page1452 has finished.
2017-08-25 03:15:57,225 - Task:Scrapy_bills - INFO - The work on page1453 has finished.
2017-08-25 03:19:06,294 - Task:Scrapy_bills - INFO - The work on page1454 has finished.
2017-08-25 03:22:16,204 - Task:Scrapy_bills - INFO - The work on page1455 has finished.
2017-08-25 03:24:34,403 - Task:Scrapy_bills - INFO - The work on page1456 has finished.
2017-08-25 03:24:43,541 - Task:Scrapy_bills - INFO - The work on page1457 has finished.
2017-08-25 03:25:29,971 - Task:Scrapy_bills - INFO - The work on page1458 has finished.
2017-08-25 03:28:39,605 - Task:Scrapy_bills - INFO - The work on page1459 has finished.
2017-08-25 03:28:40,360 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1451-1460.json
2017-08-25 03:31:51,488 - Task:Scrapy_bills - INFO - The work on page1460 has finished.
2017-08-25 03:35:02,238 - Task:Scrapy_bills - INFO - The work on page1461 has finished.
2017-08-25 03:38:17,502 - Task:Scrapy_bills - INFO - The work on page1462 has finished.
2017-08-25 03:41:35,111 - Task:Scrapy_bills - INFO - The work on page1463 has finished.
2017-08-25 03:45:05,022 - Task:Scrapy_bills - INFO - The work on page1464 has finished.
2017-08-25 03:48:29,090 - Task:Scrapy_bills - INFO - The work on page1465 has finished.
2017-08-25 03:51:49,544 - Task:Scrapy_bills - INFO - The work on page1466 has finished.
2017-08-25 03:55:07,428 - Task:Scrapy_bills - INFO - The work on page1467 has finished.
2017-08-25 03:58:24,969 - Task:Scrapy_bills - INFO - The work on page1468 has finished.
2017-08-25 04:01:45,282 - Task:Scrapy_bills - INFO - The work on page1469 has finished.
2017-08-25 04:01:46,040 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1461-1470.json
2017-08-25 04:05:02,474 - Task:Scrapy_bills - INFO - The work on page1470 has finished.
2017-08-25 04:08:20,471 - Task:Scrapy_bills - INFO - The work on page1471 has finished.
2017-08-25 04:11:38,910 - Task:Scrapy_bills - INFO - The work on page1472 has finished.
2017-08-25 04:15:01,782 - Task:Scrapy_bills - INFO - The work on page1473 has finished.
2017-08-25 04:18:19,842 - Task:Scrapy_bills - INFO - The work on page1474 has finished.
2017-08-25 04:21:41,894 - Task:Scrapy_bills - INFO - The work on page1475 has finished.
2017-08-25 04:25:04,605 - Task:Scrapy_bills - INFO - The work on page1476 has finished.
2017-08-25 04:28:22,992 - Task:Scrapy_bills - INFO - The work on page1477 has finished.
2017-08-25 04:31:37,443 - Task:Scrapy_bills - INFO - The work on page1478 has finished.
2017-08-25 04:35:05,238 - Task:Scrapy_bills - INFO - The work on page1479 has finished.
2017-08-25 04:35:05,978 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1471-1480.json
2017-08-25 04:38:28,634 - Task:Scrapy_bills - INFO - The work on page1480 has finished.
2017-08-25 04:41:45,313 - Task:Scrapy_bills - INFO - The work on page1481 has finished.
2017-08-25 04:45:02,588 - Task:Scrapy_bills - INFO - The work on page1482 has finished.
2017-08-25 04:48:18,491 - Task:Scrapy_bills - INFO - The work on page1483 has finished.
2017-08-25 04:51:48,772 - Task:Scrapy_bills - INFO - The work on page1484 has finished.
2017-08-25 04:55:10,005 - Task:Scrapy_bills - INFO - The work on page1485 has finished.
2017-08-25 04:58:31,486 - Task:Scrapy_bills - INFO - The work on page1486 has finished.
2017-08-25 05:01:48,193 - Task:Scrapy_bills - INFO - The work on page1487 has finished.
2017-08-25 05:05:02,963 - Task:Scrapy_bills - INFO - The work on page1488 has finished.
2017-08-25 05:08:21,855 - Task:Scrapy_bills - INFO - The work on page1489 has finished.
2017-08-25 05:08:22,599 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1481-1490.json
2017-08-25 05:11:44,571 - Task:Scrapy_bills - INFO - The work on page1490 has finished.
2017-08-25 05:15:02,351 - Task:Scrapy_bills - INFO - The work on page1491 has finished.
2017-08-25 05:18:17,362 - Task:Scrapy_bills - INFO - The work on page1492 has finished.
2017-08-25 05:21:31,736 - Task:Scrapy_bills - INFO - The work on page1493 has finished.
2017-08-25 05:24:49,774 - Task:Scrapy_bills - INFO - The work on page1494 has finished.
2017-08-25 05:28:03,802 - Task:Scrapy_bills - INFO - The work on page1495 has finished.
2017-08-25 05:31:19,818 - Task:Scrapy_bills - INFO - The work on page1496 has finished.
2017-08-25 05:34:37,962 - Task:Scrapy_bills - INFO - The work on page1497 has finished.
2017-08-25 05:37:58,521 - Task:Scrapy_bills - INFO - The work on page1498 has finished.
2017-08-25 05:41:19,491 - Task:Scrapy_bills - INFO - The work on page1499 has finished.
2017-08-25 05:41:20,237 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1491-1500.json
2017-08-25 05:44:40,554 - Task:Scrapy_bills - INFO - The work on page1500 has finished.
2017-08-25 05:47:58,219 - Task:Scrapy_bills - INFO - The work on page1501 has finished.
2017-08-25 05:51:17,958 - Task:Scrapy_bills - INFO - The work on page1502 has finished.
2017-08-25 05:54:34,540 - Task:Scrapy_bills - INFO - The work on page1503 has finished.
2017-08-25 05:57:54,942 - Task:Scrapy_bills - INFO - The work on page1504 has finished.
2017-08-25 06:01:13,944 - Task:Scrapy_bills - INFO - The work on page1505 has finished.
2017-08-25 06:04:35,122 - Task:Scrapy_bills - INFO - The work on page1506 has finished.
2017-08-25 06:07:52,619 - Task:Scrapy_bills - INFO - The work on page1507 has finished.
2017-08-25 06:11:12,736 - Task:Scrapy_bills - INFO - The work on page1508 has finished.
2017-08-25 06:14:31,547 - Task:Scrapy_bills - INFO - The work on page1509 has finished.
2017-08-25 06:14:32,296 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1501-1510.json
2017-08-25 06:17:51,861 - Task:Scrapy_bills - INFO - The work on page1510 has finished.
2017-08-25 06:21:07,601 - Task:Scrapy_bills - INFO - The work on page1511 has finished.
2017-08-25 06:24:20,895 - Task:Scrapy_bills - INFO - The work on page1512 has finished.
2017-08-25 06:27:29,586 - Task:Scrapy_bills - INFO - The work on page1513 has finished.
2017-08-25 06:30:35,869 - Task:Scrapy_bills - INFO - The work on page1514 has finished.
2017-08-25 06:33:45,903 - Task:Scrapy_bills - INFO - The work on page1515 has finished.
2017-08-25 06:36:50,618 - Task:Scrapy_bills - INFO - The work on page1516 has finished.
2017-08-25 06:39:56,416 - Task:Scrapy_bills - INFO - The work on page1517 has finished.
2017-08-25 06:43:01,615 - Task:Scrapy_bills - INFO - The work on page1518 has finished.
2017-08-25 06:46:08,837 - Task:Scrapy_bills - INFO - The work on page1519 has finished.
2017-08-25 06:46:09,645 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1511-1520.json
2017-08-25 06:49:22,489 - Task:Scrapy_bills - INFO - The work on page1520 has finished.
2017-08-25 06:52:31,753 - Task:Scrapy_bills - INFO - The work on page1521 has finished.
2017-08-25 06:55:39,474 - Task:Scrapy_bills - INFO - The work on page1522 has finished.
2017-08-25 06:58:48,724 - Task:Scrapy_bills - INFO - The work on page1523 has finished.
2017-08-25 07:01:58,315 - Task:Scrapy_bills - INFO - The work on page1524 has finished.
2017-08-25 07:05:04,754 - Task:Scrapy_bills - INFO - The work on page1525 has finished.
2017-08-25 07:08:16,469 - Task:Scrapy_bills - INFO - The work on page1526 has finished.
2017-08-25 07:11:27,800 - Task:Scrapy_bills - INFO - The work on page1527 has finished.
2017-08-25 07:14:34,693 - Task:Scrapy_bills - INFO - The work on page1528 has finished.
2017-08-25 07:17:39,976 - Task:Scrapy_bills - INFO - The work on page1529 has finished.
2017-08-25 07:17:40,795 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1521-1530.json
2017-08-25 07:20:52,483 - Task:Scrapy_bills - INFO - The work on page1530 has finished.
2017-08-25 07:23:56,123 - Task:Scrapy_bills - INFO - The work on page1531 has finished.
2017-08-25 07:27:07,801 - Task:Scrapy_bills - INFO - The work on page1532 has finished.
2017-08-25 07:30:12,840 - Task:Scrapy_bills - INFO - The work on page1533 has finished.
2017-08-25 07:33:26,489 - Task:Scrapy_bills - INFO - The work on page1534 has finished.
2017-08-25 07:36:33,498 - Task:Scrapy_bills - INFO - The work on page1535 has finished.
2017-08-25 07:39:45,559 - Task:Scrapy_bills - INFO - The work on page1536 has finished.
2017-08-25 07:42:54,405 - Task:Scrapy_bills - INFO - The work on page1537 has finished.
2017-08-25 07:46:05,657 - Task:Scrapy_bills - INFO - The work on page1538 has finished.
2017-08-25 07:49:16,517 - Task:Scrapy_bills - INFO - The work on page1539 has finished.
2017-08-25 07:49:17,335 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1531-1540.json
2017-08-25 07:52:25,468 - Task:Scrapy_bills - INFO - The work on page1540 has finished.
2017-08-25 07:55:33,053 - Task:Scrapy_bills - INFO - The work on page1541 has finished.
2017-08-25 07:58:42,613 - Task:Scrapy_bills - INFO - The work on page1542 has finished.
2017-08-25 08:01:50,774 - Task:Scrapy_bills - INFO - The work on page1543 has finished.
2017-08-25 08:05:00,135 - Task:Scrapy_bills - INFO - The work on page1544 has finished.
2017-08-25 08:08:04,968 - Task:Scrapy_bills - INFO - The work on page1545 has finished.
2017-08-25 08:11:11,476 - Task:Scrapy_bills - INFO - The work on page1546 has finished.
2017-08-25 08:14:20,877 - Task:Scrapy_bills - INFO - The work on page1547 has finished.
2017-08-25 08:17:27,445 - Task:Scrapy_bills - INFO - The work on page1548 has finished.
2017-08-25 08:20:35,567 - Task:Scrapy_bills - INFO - The work on page1549 has finished.
2017-08-25 08:20:36,389 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1541-1550.json
2017-08-25 08:23:47,554 - Task:Scrapy_bills - INFO - The work on page1550 has finished.
2017-08-25 08:26:56,084 - Task:Scrapy_bills - INFO - The work on page1551 has finished.
2017-08-25 08:30:03,934 - Task:Scrapy_bills - INFO - The work on page1552 has finished.
2017-08-25 08:33:11,295 - Task:Scrapy_bills - INFO - The work on page1553 has finished.
2017-08-25 08:36:20,658 - Task:Scrapy_bills - INFO - The work on page1554 has finished.
2017-08-25 08:39:30,883 - Task:Scrapy_bills - INFO - The work on page1555 has finished.
2017-08-25 08:42:40,112 - Task:Scrapy_bills - INFO - The work on page1556 has finished.
2017-08-25 08:45:50,167 - Task:Scrapy_bills - INFO - The work on page1557 has finished.
2017-08-25 08:48:58,424 - Task:Scrapy_bills - INFO - The work on page1558 has finished.
2017-08-25 08:52:05,866 - Task:Scrapy_bills - INFO - The work on page1559 has finished.
2017-08-25 08:52:06,685 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1551-1560.json
2017-08-25 08:55:22,645 - Task:Scrapy_bills - INFO - The work on page1560 has finished.
2017-08-25 08:58:32,205 - Task:Scrapy_bills - INFO - The work on page1561 has finished.
2017-08-25 09:01:49,395 - Task:Scrapy_bills - INFO - The work on page1562 has finished.
2017-08-25 09:04:57,539 - Task:Scrapy_bills - INFO - The work on page1563 has finished.
2017-08-25 09:08:06,484 - Task:Scrapy_bills - INFO - The work on page1564 has finished.
2017-08-25 09:11:16,430 - Task:Scrapy_bills - INFO - The work on page1565 has finished.
2017-08-25 09:14:27,205 - Task:Scrapy_bills - INFO - The work on page1566 has finished.
2017-08-25 09:17:36,505 - Task:Scrapy_bills - INFO - The work on page1567 has finished.
2017-08-25 09:20:43,517 - Task:Scrapy_bills - INFO - The work on page1568 has finished.
2017-08-25 09:22:21,508 - Task:Scrapy_bills - INFO - The work on page1569 has finished.
2017-08-25 09:22:22,311 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1561-1570.json
2017-08-25 09:22:39,289 - Task:Scrapy_bills - INFO - The work on page1570 has finished.
2017-08-25 09:22:44,088 - Task:Scrapy_bills - INFO - The work on page1571 has finished.
2017-08-25 09:22:49,018 - Task:Scrapy_bills - INFO - The work on page1572 has finished.
2017-08-25 09:22:53,652 - Task:Scrapy_bills - INFO - The work on page1573 has finished.
2017-08-25 09:23:14,756 - Task:Scrapy_bills - INFO - The work on page1574 has finished.
2017-08-25 09:26:21,361 - Task:Scrapy_bills - INFO - The work on page1575 has finished.
2017-08-25 09:29:29,697 - Task:Scrapy_bills - INFO - The work on page1576 has finished.
2017-08-25 09:32:37,397 - Task:Scrapy_bills - INFO - The work on page1577 has finished.
2017-08-25 09:35:45,915 - Task:Scrapy_bills - INFO - The work on page1578 has finished.
2017-08-25 09:38:55,665 - Task:Scrapy_bills - INFO - The work on page1579 has finished.
2017-08-25 09:38:56,338 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1571-1580.json
2017-08-25 09:42:06,833 - Task:Scrapy_bills - INFO - The work on page1580 has finished.
2017-08-25 09:45:15,414 - Task:Scrapy_bills - INFO - The work on page1581 has finished.
2017-08-25 09:48:31,638 - Task:Scrapy_bills - INFO - The work on page1582 has finished.
2017-08-25 09:51:44,411 - Task:Scrapy_bills - INFO - The work on page1583 has finished.
2017-08-25 09:54:56,157 - Task:Scrapy_bills - INFO - The work on page1584 has finished.
2017-08-25 09:58:07,665 - Task:Scrapy_bills - INFO - The work on page1585 has finished.
2017-08-25 10:01:20,515 - Task:Scrapy_bills - INFO - The work on page1586 has finished.
2017-08-25 10:04:41,754 - Task:Scrapy_bills - INFO - The work on page1587 has finished.
2017-08-25 10:07:58,545 - Task:Scrapy_bills - INFO - The work on page1588 has finished.
2017-08-25 10:11:14,474 - Task:Scrapy_bills - INFO - The work on page1589 has finished.
2017-08-25 10:11:15,230 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1581-1590.json
2017-08-25 10:14:30,643 - Task:Scrapy_bills - INFO - The work on page1590 has finished.
2017-08-25 10:17:40,784 - Task:Scrapy_bills - INFO - The work on page1591 has finished.
2017-08-25 10:20:49,563 - Task:Scrapy_bills - INFO - The work on page1592 has finished.
2017-08-25 10:23:56,164 - Task:Scrapy_bills - INFO - The work on page1593 has finished.
2017-08-25 10:27:04,284 - Task:Scrapy_bills - INFO - The work on page1594 has finished.
2017-08-25 10:30:11,033 - Task:Scrapy_bills - INFO - The work on page1595 has finished.
2017-08-25 10:33:20,311 - Task:Scrapy_bills - INFO - The work on page1596 has finished.
2017-08-25 10:36:28,912 - Task:Scrapy_bills - INFO - The work on page1597 has finished.
2017-08-25 10:39:35,682 - Task:Scrapy_bills - INFO - The work on page1598 has finished.
2017-08-25 10:42:50,540 - Task:Scrapy_bills - INFO - The work on page1599 has finished.
2017-08-25 10:42:51,352 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1591-1600.json
2017-08-25 10:46:02,233 - Task:Scrapy_bills - INFO - The work on page1600 has finished.
2017-08-25 10:49:11,143 - Task:Scrapy_bills - INFO - The work on page1601 has finished.
2017-08-25 10:52:20,794 - Task:Scrapy_bills - INFO - The work on page1602 has finished.
2017-08-25 10:55:25,665 - Task:Scrapy_bills - INFO - The work on page1603 has finished.
2017-08-25 10:58:32,836 - Task:Scrapy_bills - INFO - The work on page1604 has finished.
2017-08-25 11:01:40,544 - Task:Scrapy_bills - INFO - The work on page1605 has finished.
2017-08-25 11:04:48,268 - Task:Scrapy_bills - INFO - The work on page1606 has finished.
2017-08-25 11:07:55,987 - Task:Scrapy_bills - INFO - The work on page1607 has finished.
2017-08-25 11:11:03,856 - Task:Scrapy_bills - INFO - The work on page1608 has finished.
2017-08-25 11:14:14,931 - Task:Scrapy_bills - INFO - The work on page1609 has finished.
2017-08-25 11:14:15,756 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1601-1610.json
2017-08-25 11:17:28,457 - Task:Scrapy_bills - INFO - The work on page1610 has finished.
2017-08-25 11:20:38,145 - Task:Scrapy_bills - INFO - The work on page1611 has finished.
2017-08-25 11:23:49,641 - Task:Scrapy_bills - INFO - The work on page1612 has finished.
2017-08-25 11:27:00,908 - Task:Scrapy_bills - INFO - The work on page1613 has finished.
2017-08-25 11:30:13,789 - Task:Scrapy_bills - INFO - The work on page1614 has finished.
2017-08-25 11:33:25,278 - Task:Scrapy_bills - INFO - The work on page1615 has finished.
2017-08-25 11:36:36,359 - Task:Scrapy_bills - INFO - The work on page1616 has finished.
2017-08-25 11:39:46,726 - Task:Scrapy_bills - INFO - The work on page1617 has finished.
2017-08-25 11:42:57,428 - Task:Scrapy_bills - INFO - The work on page1618 has finished.
2017-08-25 11:46:07,366 - Task:Scrapy_bills - INFO - The work on page1619 has finished.
2017-08-25 11:46:08,206 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1611-1620.json
2017-08-25 11:49:23,421 - Task:Scrapy_bills - INFO - The work on page1620 has finished.
2017-08-25 11:52:35,149 - Task:Scrapy_bills - INFO - The work on page1621 has finished.
2017-08-25 11:55:44,475 - Task:Scrapy_bills - INFO - The work on page1622 has finished.
2017-08-25 11:58:48,051 - Task:Scrapy_bills - INFO - The work on page1623 has finished.
2017-08-25 12:01:56,935 - Task:Scrapy_bills - INFO - The work on page1624 has finished.
2017-08-25 12:02:59,607 - Task:Scrapy_bills - INFO - The work on page1625 has finished.
2017-08-25 12:03:04,525 - Task:Scrapy_bills - INFO - The work on page1626 has finished.
2017-08-25 12:04:55,365 - Task:Scrapy_bills - INFO - The work on page1627 has finished.
2017-08-25 12:08:08,836 - Task:Scrapy_bills - INFO - The work on page1628 has finished.
2017-08-25 12:11:21,077 - Task:Scrapy_bills - INFO - The work on page1629 has finished.
2017-08-25 12:11:21,837 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1621-1630.json
2017-08-25 12:14:41,537 - Task:Scrapy_bills - INFO - The work on page1630 has finished.
2017-08-25 12:17:55,343 - Task:Scrapy_bills - INFO - The work on page1631 has finished.
2017-08-25 12:21:13,301 - Task:Scrapy_bills - INFO - The work on page1632 has finished.
2017-08-25 12:24:32,209 - Task:Scrapy_bills - INFO - The work on page1633 has finished.
2017-08-25 12:27:47,395 - Task:Scrapy_bills - INFO - The work on page1634 has finished.
2017-08-25 12:31:02,892 - Task:Scrapy_bills - INFO - The work on page1635 has finished.
2017-08-25 12:34:17,634 - Task:Scrapy_bills - INFO - The work on page1636 has finished.
2017-08-25 12:37:32,600 - Task:Scrapy_bills - INFO - The work on page1637 has finished.
2017-08-25 12:40:53,246 - Task:Scrapy_bills - INFO - The work on page1638 has finished.
2017-08-25 12:44:08,532 - Task:Scrapy_bills - INFO - The work on page1639 has finished.
2017-08-25 12:44:09,287 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1631-1640.json
2017-08-25 12:47:26,113 - Task:Scrapy_bills - INFO - The work on page1640 has finished.
2017-08-25 12:50:53,059 - Task:Scrapy_bills - INFO - The work on page1641 has finished.
2017-08-25 12:54:14,673 - Task:Scrapy_bills - INFO - The work on page1642 has finished.
2017-08-25 12:57:56,892 - Task:Scrapy_bills - INFO - The work on page1643 has finished.
2017-08-25 13:01:17,231 - Task:Scrapy_bills - INFO - The work on page1644 has finished.
2017-08-25 13:04:35,993 - Task:Scrapy_bills - INFO - The work on page1645 has finished.
2017-08-25 13:08:03,974 - Task:Scrapy_bills - INFO - The work on page1646 has finished.
2017-08-25 13:11:26,655 - Task:Scrapy_bills - INFO - The work on page1647 has finished.
2017-08-25 13:14:45,552 - Task:Scrapy_bills - INFO - The work on page1648 has finished.
2017-08-25 13:17:58,452 - Task:Scrapy_bills - INFO - The work on page1649 has finished.
2017-08-25 13:17:59,195 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1641-1650.json
2017-08-25 13:21:15,671 - Task:Scrapy_bills - INFO - The work on page1650 has finished.
2017-08-25 13:24:29,110 - Task:Scrapy_bills - INFO - The work on page1651 has finished.
2017-08-25 13:27:40,496 - Task:Scrapy_bills - INFO - The work on page1652 has finished.
2017-08-25 13:30:50,207 - Task:Scrapy_bills - INFO - The work on page1653 has finished.
2017-08-25 13:33:58,574 - Task:Scrapy_bills - INFO - The work on page1654 has finished.
2017-08-25 13:37:10,820 - Task:Scrapy_bills - INFO - The work on page1655 has finished.
2017-08-25 13:40:24,276 - Task:Scrapy_bills - INFO - The work on page1656 has finished.
2017-08-25 13:43:35,161 - Task:Scrapy_bills - INFO - The work on page1657 has finished.
2017-08-25 13:46:47,291 - Task:Scrapy_bills - INFO - The work on page1658 has finished.
2017-08-25 13:49:57,266 - Task:Scrapy_bills - INFO - The work on page1659 has finished.
2017-08-25 13:49:58,019 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1651-1660.json
2017-08-25 13:53:14,067 - Task:Scrapy_bills - INFO - The work on page1660 has finished.
2017-08-25 13:56:26,144 - Task:Scrapy_bills - INFO - The work on page1661 has finished.
2017-08-25 13:59:37,151 - Task:Scrapy_bills - INFO - The work on page1662 has finished.
2017-08-25 14:02:47,906 - Task:Scrapy_bills - INFO - The work on page1663 has finished.
2017-08-25 14:06:01,650 - Task:Scrapy_bills - INFO - The work on page1664 has finished.
2017-08-25 14:09:14,447 - Task:Scrapy_bills - INFO - The work on page1665 has finished.
2017-08-25 14:12:25,571 - Task:Scrapy_bills - INFO - The work on page1666 has finished.
2017-08-25 14:15:35,059 - Task:Scrapy_bills - INFO - The work on page1667 has finished.
2017-08-25 14:18:49,805 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-25 14:18:49,807 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-25 14:21:45,585 - Task:Scrapy_bills - INFO - The work on page1668 has finished.
2017-08-25 14:25:51,543 - Task:Scrapy_bills - INFO - The work on page1669 has finished.
2017-08-25 14:25:52,442 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1661-1670.json
2017-08-25 14:29:08,723 - Task:Scrapy_bills - INFO - The work on page1670 has finished.
2017-08-25 14:32:20,121 - Task:Scrapy_bills - INFO - The work on page1671 has finished.
2017-08-25 14:35:32,448 - Task:Scrapy_bills - INFO - The work on page1672 has finished.
2017-08-25 14:38:43,028 - Task:Scrapy_bills - INFO - The work on page1673 has finished.
2017-08-25 14:42:00,585 - Task:Scrapy_bills - INFO - The work on page1674 has finished.
2017-08-25 14:45:09,374 - Task:Scrapy_bills - INFO - The work on page1675 has finished.
2017-08-25 14:48:27,263 - Task:Scrapy_bills - INFO - The work on page1676 has finished.
2017-08-25 14:51:52,995 - Task:Scrapy_bills - INFO - The work on page1677 has finished.
2017-08-25 14:55:22,637 - Task:Scrapy_bills - INFO - The work on page1678 has finished.
2017-08-25 14:58:55,806 - Task:Scrapy_bills - INFO - The work on page1679 has finished.
2017-08-25 14:58:56,618 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1671-1680.json
2017-08-25 15:02:31,256 - Task:Scrapy_bills - INFO - The work on page1680 has finished.
2017-08-25 15:05:58,707 - Task:Scrapy_bills - INFO - The work on page1681 has finished.
2017-08-25 15:09:28,314 - Task:Scrapy_bills - INFO - The work on page1682 has finished.
2017-08-25 15:10:03,042 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-25 15:10:03,043 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-25 15:13:41,509 - Task:Scrapy_bills - INFO - The work on page1683 has finished.
2017-08-25 15:17:04,937 - Task:Scrapy_bills - INFO - The work on page1684 has finished.
2017-08-25 15:20:34,602 - Task:Scrapy_bills - INFO - The work on page1685 has finished.
2017-08-25 15:24:06,342 - Task:Scrapy_bills - INFO - The work on page1686 has finished.
2017-08-25 15:27:40,980 - Task:Scrapy_bills - INFO - The work on page1687 has finished.
2017-08-25 15:31:08,990 - Task:Scrapy_bills - INFO - The work on page1688 has finished.
2017-08-25 15:34:37,584 - Task:Scrapy_bills - INFO - The work on page1689 has finished.
2017-08-25 15:34:38,532 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1681-1690.json
2017-08-25 15:38:09,153 - Task:Scrapy_bills - INFO - The work on page1690 has finished.
2017-08-25 15:41:41,590 - Task:Scrapy_bills - INFO - The work on page1691 has finished.
2017-08-25 15:45:08,221 - Task:Scrapy_bills - INFO - The work on page1692 has finished.
2017-08-25 15:48:36,696 - Task:Scrapy_bills - INFO - The work on page1693 has finished.
2017-08-25 15:52:02,919 - Task:Scrapy_bills - INFO - The work on page1694 has finished.
2017-08-25 15:55:30,312 - Task:Scrapy_bills - INFO - The work on page1695 has finished.
2017-08-25 15:58:58,606 - Task:Scrapy_bills - INFO - The work on page1696 has finished.
2017-08-25 16:02:25,698 - Task:Scrapy_bills - INFO - The work on page1697 has finished.
2017-08-25 16:05:56,386 - Task:Scrapy_bills - INFO - The work on page1698 has finished.
2017-08-25 16:09:34,791 - Task:Scrapy_bills - INFO - The work on page1699 has finished.
2017-08-25 16:09:35,799 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1691-1700.json
2017-08-25 16:13:11,096 - Task:Scrapy_bills - INFO - The work on page1700 has finished.
2017-08-25 16:16:46,779 - Task:Scrapy_bills - INFO - The work on page1701 has finished.
2017-08-25 16:20:17,493 - Task:Scrapy_bills - INFO - The work on page1702 has finished.
2017-08-25 16:23:49,923 - Task:Scrapy_bills - INFO - The work on page1703 has finished.
2017-08-25 16:27:24,635 - Task:Scrapy_bills - INFO - The work on page1704 has finished.
2017-08-25 16:30:55,743 - Task:Scrapy_bills - INFO - The work on page1705 has finished.
2017-08-25 16:34:33,795 - Task:Scrapy_bills - INFO - The work on page1706 has finished.
2017-08-25 16:38:02,206 - Task:Scrapy_bills - INFO - The work on page1707 has finished.
2017-08-25 16:41:32,377 - Task:Scrapy_bills - INFO - The work on page1708 has finished.
2017-08-25 16:45:05,919 - Task:Scrapy_bills - INFO - The work on page1709 has finished.
2017-08-25 16:45:06,786 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1701-1710.json
2017-08-25 16:48:36,908 - Task:Scrapy_bills - INFO - The work on page1710 has finished.
2017-08-25 16:52:14,298 - Task:Scrapy_bills - INFO - The work on page1711 has finished.
2017-08-25 16:55:49,068 - Task:Scrapy_bills - INFO - The work on page1712 has finished.
2017-08-25 16:59:27,492 - Task:Scrapy_bills - INFO - The work on page1713 has finished.
2017-08-25 17:03:04,768 - Task:Scrapy_bills - INFO - The work on page1714 has finished.
2017-08-25 17:06:52,850 - Task:Scrapy_bills - INFO - The work on page1715 has finished.
2017-08-25 17:10:39,015 - Task:Scrapy_bills - INFO - The work on page1716 has finished.
2017-08-25 17:14:13,099 - Task:Scrapy_bills - INFO - The work on page1717 has finished.
2017-08-25 17:17:50,895 - Task:Scrapy_bills - INFO - The work on page1718 has finished.
2017-08-25 17:21:27,828 - Task:Scrapy_bills - INFO - The work on page1719 has finished.
2017-08-25 17:21:28,808 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1711-1720.json
2017-08-25 17:25:06,426 - Task:Scrapy_bills - INFO - The work on page1720 has finished.
2017-08-25 17:28:42,378 - Task:Scrapy_bills - INFO - The work on page1721 has finished.
2017-08-25 17:32:23,689 - Task:Scrapy_bills - INFO - The work on page1722 has finished.
2017-08-25 17:35:35,989 - Task:Scrapy_bills - INFO - The work on page1723 has finished.
2017-08-25 17:36:16,844 - Task:Scrapy_bills - INFO - The work on page1724 has finished.
2017-08-25 17:36:21,832 - Task:Scrapy_bills - INFO - The work on page1725 has finished.
2017-08-25 17:36:27,460 - Task:Scrapy_bills - INFO - The work on page1726 has finished.
2017-08-25 17:36:32,106 - Task:Scrapy_bills - INFO - The work on page1727 has finished.
2017-08-25 17:37:35,213 - Task:Scrapy_bills - INFO - The work on page1728 has finished.
2017-08-25 17:41:08,717 - Task:Scrapy_bills - INFO - The work on page1729 has finished.
2017-08-25 17:41:09,412 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1721-1730.json
2017-08-25 17:44:47,752 - Task:Scrapy_bills - INFO - The work on page1730 has finished.
2017-08-25 17:48:29,943 - Task:Scrapy_bills - INFO - The work on page1731 has finished.
2017-08-25 17:52:07,466 - Task:Scrapy_bills - INFO - The work on page1732 has finished.
2017-08-25 17:55:50,495 - Task:Scrapy_bills - INFO - The work on page1733 has finished.
2017-08-25 17:59:24,379 - Task:Scrapy_bills - INFO - The work on page1734 has finished.
2017-08-25 18:02:36,455 - Task:Scrapy_bills - INFO - The work on page1735 has finished.
2017-08-25 18:05:49,863 - Task:Scrapy_bills - INFO - The work on page1736 has finished.
2017-08-25 18:09:03,911 - Task:Scrapy_bills - INFO - The work on page1737 has finished.
2017-08-25 18:12:16,819 - Task:Scrapy_bills - INFO - The work on page1738 has finished.
2017-08-25 18:15:28,180 - Task:Scrapy_bills - INFO - The work on page1739 has finished.
2017-08-25 18:15:28,966 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1731-1740.json
2017-08-25 18:18:44,543 - Task:Scrapy_bills - INFO - The work on page1740 has finished.
2017-08-25 18:21:59,833 - Task:Scrapy_bills - INFO - The work on page1741 has finished.
2017-08-25 18:25:16,949 - Task:Scrapy_bills - INFO - The work on page1742 has finished.
2017-08-25 18:28:55,584 - Task:Scrapy_bills - INFO - The work on page1743 has finished.
2017-08-25 18:33:14,556 - Task:Scrapy_bills - INFO - The work on page1744 has finished.
2017-08-25 18:36:45,091 - Task:Scrapy_bills - INFO - The work on page1745 has finished.
2017-08-25 18:40:20,028 - Task:Scrapy_bills - INFO - The work on page1746 has finished.
2017-08-25 18:43:57,777 - Task:Scrapy_bills - INFO - The work on page1747 has finished.
2017-08-25 18:47:23,145 - Task:Scrapy_bills - INFO - The work on page1748 has finished.
2017-08-25 18:50:52,433 - Task:Scrapy_bills - INFO - The work on page1749 has finished.
2017-08-25 18:50:53,215 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1741-1750.json
2017-08-25 18:54:26,390 - Task:Scrapy_bills - INFO - The work on page1750 has finished.
2017-08-25 18:58:03,707 - Task:Scrapy_bills - INFO - The work on page1751 has finished.
2017-08-25 19:01:52,905 - Task:Scrapy_bills - INFO - The work on page1752 has finished.
2017-08-25 19:05:33,841 - Task:Scrapy_bills - INFO - The work on page1753 has finished.
2017-08-25 19:09:25,261 - Task:Scrapy_bills - INFO - The work on page1754 has finished.
2017-08-25 19:13:10,684 - Task:Scrapy_bills - INFO - The work on page1755 has finished.
2017-08-25 19:16:59,205 - Task:Scrapy_bills - INFO - The work on page1756 has finished.
2017-08-25 19:20:33,744 - Task:Scrapy_bills - INFO - The work on page1757 has finished.
2017-08-25 19:24:03,346 - Task:Scrapy_bills - INFO - The work on page1758 has finished.
2017-08-25 19:27:34,448 - Task:Scrapy_bills - INFO - The work on page1759 has finished.
2017-08-25 19:27:35,273 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1751-1760.json
2017-08-25 19:31:07,622 - Task:Scrapy_bills - INFO - The work on page1760 has finished.
2017-08-25 19:34:41,356 - Task:Scrapy_bills - INFO - The work on page1761 has finished.
2017-08-25 19:38:15,107 - Task:Scrapy_bills - INFO - The work on page1762 has finished.
2017-08-25 19:41:46,396 - Task:Scrapy_bills - INFO - The work on page1763 has finished.
2017-08-25 19:45:14,038 - Task:Scrapy_bills - INFO - The work on page1764 has finished.
2017-08-25 19:48:47,524 - Task:Scrapy_bills - INFO - The work on page1765 has finished.
2017-08-25 19:52:21,947 - Task:Scrapy_bills - INFO - The work on page1766 has finished.
2017-08-25 19:55:50,973 - Task:Scrapy_bills - INFO - The work on page1767 has finished.
2017-08-25 19:59:21,679 - Task:Scrapy_bills - INFO - The work on page1768 has finished.
2017-08-25 19:59:57,718 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-25 19:59:57,720 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-25 20:03:36,725 - Task:Scrapy_bills - INFO - The work on page1769 has finished.
2017-08-25 20:03:37,549 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1761-1770.json
2017-08-25 20:06:22,709 - Task:Scrapy_bills - INFO - The work on page1770 has finished.
2017-08-25 20:06:32,083 - Task:Scrapy_bills - INFO - The work on page1771 has finished.
2017-08-25 20:07:57,424 - Task:Scrapy_bills - INFO - The work on page1772 has finished.
2017-08-25 20:11:36,241 - Task:Scrapy_bills - INFO - The work on page1773 has finished.
2017-08-25 20:15:15,016 - Task:Scrapy_bills - INFO - The work on page1774 has finished.
2017-08-25 20:18:47,247 - Task:Scrapy_bills - INFO - The work on page1775 has finished.
2017-08-25 20:22:02,698 - Task:Scrapy_bills - INFO - The work on page1776 has finished.
2017-08-25 20:25:19,827 - Task:Scrapy_bills - INFO - The work on page1777 has finished.
2017-08-25 20:28:34,764 - Task:Scrapy_bills - INFO - The work on page1778 has finished.
2017-08-25 20:31:48,910 - Task:Scrapy_bills - INFO - The work on page1779 has finished.
2017-08-25 20:31:49,641 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1771-1780.json
2017-08-25 20:35:11,800 - Task:Scrapy_bills - INFO - The work on page1780 has finished.
2017-08-25 20:38:26,414 - Task:Scrapy_bills - INFO - The work on page1781 has finished.
2017-08-25 20:41:44,412 - Task:Scrapy_bills - INFO - The work on page1782 has finished.
2017-08-25 20:45:00,830 - Task:Scrapy_bills - INFO - The work on page1783 has finished.
2017-08-25 20:48:18,853 - Task:Scrapy_bills - INFO - The work on page1784 has finished.
2017-08-25 20:51:49,667 - Task:Scrapy_bills - INFO - The work on page1785 has finished.
2017-08-25 20:55:06,868 - Task:Scrapy_bills - INFO - The work on page1786 has finished.
2017-08-25 20:58:24,795 - Task:Scrapy_bills - INFO - The work on page1787 has finished.
2017-08-25 21:01:44,490 - Task:Scrapy_bills - INFO - The work on page1788 has finished.
2017-08-25 21:05:07,602 - Task:Scrapy_bills - INFO - The work on page1789 has finished.
2017-08-25 21:05:08,343 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1781-1790.json
2017-08-25 21:08:32,335 - Task:Scrapy_bills - INFO - The work on page1790 has finished.
2017-08-25 21:11:53,906 - Task:Scrapy_bills - INFO - The work on page1791 has finished.
2017-08-25 21:15:09,824 - Task:Scrapy_bills - INFO - The work on page1792 has finished.
2017-08-25 21:18:49,645 - Task:Scrapy_bills - INFO - The work on page1793 has finished.
2017-08-25 21:22:18,882 - Task:Scrapy_bills - INFO - The work on page1794 has finished.
2017-08-25 21:26:12,214 - Task:Scrapy_bills - INFO - The work on page1795 has finished.
2017-08-25 21:29:46,322 - Task:Scrapy_bills - INFO - The work on page1796 has finished.
2017-08-25 21:33:07,272 - Task:Scrapy_bills - INFO - The work on page1797 has finished.
2017-08-25 21:36:44,503 - Task:Scrapy_bills - INFO - The work on page1798 has finished.
2017-08-25 21:40:22,765 - Task:Scrapy_bills - INFO - The work on page1799 has finished.
2017-08-25 21:40:23,525 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1791-1800.json
2017-08-25 21:43:56,961 - Task:Scrapy_bills - INFO - The work on page1800 has finished.
2017-08-25 21:47:24,676 - Task:Scrapy_bills - INFO - The work on page1801 has finished.
2017-08-25 21:50:50,454 - Task:Scrapy_bills - INFO - The work on page1802 has finished.
2017-08-25 21:54:09,677 - Task:Scrapy_bills - INFO - The work on page1803 has finished.
2017-08-25 21:57:29,395 - Task:Scrapy_bills - INFO - The work on page1804 has finished.
2017-08-25 22:00:45,583 - Task:Scrapy_bills - INFO - The work on page1805 has finished.
2017-08-25 22:04:09,053 - Task:Scrapy_bills - INFO - The work on page1806 has finished.
2017-08-25 22:07:35,265 - Task:Scrapy_bills - INFO - The work on page1807 has finished.
2017-08-25 22:10:56,849 - Task:Scrapy_bills - INFO - The work on page1808 has finished.
2017-08-25 22:14:14,263 - Task:Scrapy_bills - INFO - The work on page1809 has finished.
2017-08-25 22:14:15,022 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1801-1810.json
2017-08-25 22:17:34,915 - Task:Scrapy_bills - INFO - The work on page1810 has finished.
2017-08-25 22:20:53,653 - Task:Scrapy_bills - INFO - The work on page1811 has finished.
2017-08-25 22:24:12,315 - Task:Scrapy_bills - INFO - The work on page1812 has finished.
2017-08-25 22:27:31,963 - Task:Scrapy_bills - INFO - The work on page1813 has finished.
2017-08-25 22:30:51,225 - Task:Scrapy_bills - INFO - The work on page1814 has finished.
2017-08-25 22:34:14,036 - Task:Scrapy_bills - INFO - The work on page1815 has finished.
2017-08-25 22:37:37,245 - Task:Scrapy_bills - INFO - The work on page1816 has finished.
2017-08-25 22:40:57,431 - Task:Scrapy_bills - INFO - The work on page1817 has finished.
2017-08-25 22:44:18,692 - Task:Scrapy_bills - INFO - The work on page1818 has finished.
2017-08-25 22:47:41,069 - Task:Scrapy_bills - INFO - The work on page1819 has finished.
2017-08-25 22:47:41,863 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1811-1820.json
2017-08-25 22:51:12,022 - Task:Scrapy_bills - INFO - The work on page1820 has finished.
2017-08-25 22:54:37,607 - Task:Scrapy_bills - INFO - The work on page1821 has finished.
2017-08-25 22:57:57,757 - Task:Scrapy_bills - INFO - The work on page1822 has finished.
2017-08-25 23:01:19,396 - Task:Scrapy_bills - INFO - The work on page1823 has finished.
2017-08-25 23:04:44,444 - Task:Scrapy_bills - INFO - The work on page1824 has finished.
2017-08-25 23:08:06,980 - Task:Scrapy_bills - INFO - The work on page1825 has finished.
2017-08-25 23:11:30,332 - Task:Scrapy_bills - INFO - The work on page1826 has finished.
2017-08-25 23:14:55,366 - Task:Scrapy_bills - INFO - The work on page1827 has finished.
2017-08-25 23:18:23,472 - Task:Scrapy_bills - INFO - The work on page1828 has finished.
2017-08-25 23:21:49,135 - Task:Scrapy_bills - INFO - The work on page1829 has finished.
2017-08-25 23:21:49,964 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1821-1830.json
2017-08-25 23:25:18,078 - Task:Scrapy_bills - INFO - The work on page1830 has finished.
2017-08-25 23:28:48,983 - Task:Scrapy_bills - INFO - The work on page1831 has finished.
2017-08-25 23:32:21,558 - Task:Scrapy_bills - INFO - The work on page1832 has finished.
2017-08-25 23:35:47,559 - Task:Scrapy_bills - INFO - The work on page1833 has finished.
2017-08-25 23:39:24,621 - Task:Scrapy_bills - INFO - The work on page1834 has finished.
2017-08-25 23:42:51,207 - Task:Scrapy_bills - INFO - The work on page1835 has finished.
2017-08-25 23:46:12,382 - Task:Scrapy_bills - INFO - The work on page1836 has finished.
2017-08-25 23:49:37,457 - Task:Scrapy_bills - INFO - The work on page1837 has finished.
2017-08-25 23:53:00,278 - Task:Scrapy_bills - INFO - The work on page1838 has finished.
2017-08-25 23:56:27,758 - Task:Scrapy_bills - INFO - The work on page1839 has finished.
2017-08-25 23:56:28,592 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1831-1840.json
2017-08-25 23:59:55,956 - Task:Scrapy_bills - INFO - The work on page1840 has finished.
2017-08-26 00:03:20,991 - Task:Scrapy_bills - INFO - The work on page1841 has finished.
2017-08-26 00:06:46,080 - Task:Scrapy_bills - INFO - The work on page1842 has finished.
2017-08-26 00:10:04,647 - Task:Scrapy_bills - INFO - The work on page1843 has finished.
2017-08-26 00:13:36,691 - Task:Scrapy_bills - INFO - The work on page1844 has finished.
2017-08-26 00:16:58,923 - Task:Scrapy_bills - INFO - The work on page1845 has finished.
2017-08-26 00:20:23,832 - Task:Scrapy_bills - INFO - The work on page1846 has finished.
2017-08-26 00:23:44,634 - Task:Scrapy_bills - INFO - The work on page1847 has finished.
2017-08-26 00:27:01,130 - Task:Scrapy_bills - INFO - The work on page1848 has finished.
2017-08-26 00:30:21,474 - Task:Scrapy_bills - INFO - The work on page1849 has finished.
2017-08-26 00:30:22,314 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1841-1850.json
2017-08-26 00:33:46,555 - Task:Scrapy_bills - INFO - The work on page1850 has finished.
2017-08-26 00:37:08,635 - Task:Scrapy_bills - INFO - The work on page1851 has finished.
2017-08-26 00:40:36,855 - Task:Scrapy_bills - INFO - The work on page1852 has finished.
2017-08-26 00:44:03,222 - Task:Scrapy_bills - INFO - The work on page1853 has finished.
2017-08-26 00:47:27,333 - Task:Scrapy_bills - INFO - The work on page1854 has finished.
2017-08-26 00:51:00,442 - Task:Scrapy_bills - INFO - The work on page1855 has finished.
2017-08-26 00:54:27,074 - Task:Scrapy_bills - INFO - The work on page1856 has finished.
2017-08-26 00:56:55,305 - Task:Scrapy_bills - INFO - The work on page1857 has finished.
2017-08-26 00:57:20,694 - Task:Scrapy_bills - INFO - The work on page1858 has finished.
2017-08-26 00:57:25,613 - Task:Scrapy_bills - INFO - The work on page1859 has finished.
2017-08-26 00:57:26,375 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1851-1860.json
2017-08-26 00:57:32,051 - Task:Scrapy_bills - INFO - The work on page1860 has finished.
2017-08-26 00:57:56,309 - Task:Scrapy_bills - INFO - The work on page1861 has finished.
2017-08-26 01:01:16,422 - Task:Scrapy_bills - INFO - The work on page1862 has finished.
2017-08-26 01:04:40,287 - Task:Scrapy_bills - INFO - The work on page1863 has finished.
2017-08-26 01:08:02,577 - Task:Scrapy_bills - INFO - The work on page1864 has finished.
2017-08-26 01:11:22,903 - Task:Scrapy_bills - INFO - The work on page1865 has finished.
2017-08-26 01:14:46,794 - Task:Scrapy_bills - INFO - The work on page1866 has finished.
2017-08-26 01:18:11,358 - Task:Scrapy_bills - INFO - The work on page1867 has finished.
2017-08-26 01:21:22,937 - Task:Scrapy_bills - INFO - The work on page1868 has finished.
2017-08-26 01:24:36,440 - Task:Scrapy_bills - INFO - The work on page1869 has finished.
2017-08-26 01:24:37,197 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1861-1870.json
2017-08-26 01:27:52,287 - Task:Scrapy_bills - INFO - The work on page1870 has finished.
2017-08-26 01:31:05,563 - Task:Scrapy_bills - INFO - The work on page1871 has finished.
2017-08-26 01:34:18,403 - Task:Scrapy_bills - INFO - The work on page1872 has finished.
2017-08-26 01:37:30,537 - Task:Scrapy_bills - INFO - The work on page1873 has finished.
2017-08-26 01:40:43,309 - Task:Scrapy_bills - INFO - The work on page1874 has finished.
2017-08-26 01:43:54,890 - Task:Scrapy_bills - INFO - The work on page1875 has finished.
2017-08-26 01:47:07,494 - Task:Scrapy_bills - INFO - The work on page1876 has finished.
2017-08-26 01:50:20,687 - Task:Scrapy_bills - INFO - The work on page1877 has finished.
2017-08-26 01:53:32,094 - Task:Scrapy_bills - INFO - The work on page1878 has finished.
2017-08-26 01:56:43,080 - Task:Scrapy_bills - INFO - The work on page1879 has finished.
2017-08-26 01:56:43,840 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1871-1880.json
2017-08-26 01:59:59,895 - Task:Scrapy_bills - INFO - The work on page1880 has finished.
2017-08-26 02:03:03,434 - Task:Scrapy_bills - INFO - The work on page1881 has finished.
2017-08-26 02:06:18,353 - Task:Scrapy_bills - INFO - The work on page1882 has finished.
2017-08-26 02:09:35,975 - Task:Scrapy_bills - INFO - The work on page1883 has finished.
2017-08-26 02:12:58,618 - Task:Scrapy_bills - INFO - The work on page1884 has finished.
2017-08-26 02:16:27,016 - Task:Scrapy_bills - INFO - The work on page1885 has finished.
2017-08-26 02:19:49,878 - Task:Scrapy_bills - INFO - The work on page1886 has finished.
2017-08-26 02:23:13,843 - Task:Scrapy_bills - INFO - The work on page1887 has finished.
2017-08-26 02:26:43,307 - Task:Scrapy_bills - INFO - The work on page1888 has finished.
2017-08-26 02:30:00,522 - Task:Scrapy_bills - INFO - The work on page1889 has finished.
2017-08-26 02:30:01,346 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1881-1890.json
2017-08-26 02:33:20,406 - Task:Scrapy_bills - INFO - The work on page1890 has finished.
2017-08-26 02:36:33,408 - Task:Scrapy_bills - INFO - The work on page1891 has finished.
2017-08-26 02:39:55,666 - Task:Scrapy_bills - INFO - The work on page1892 has finished.
2017-08-26 02:43:20,505 - Task:Scrapy_bills - INFO - The work on page1893 has finished.
2017-08-26 02:46:47,853 - Task:Scrapy_bills - INFO - The work on page1894 has finished.
2017-08-26 02:50:16,843 - Task:Scrapy_bills - INFO - The work on page1895 has finished.
2017-08-26 02:53:35,806 - Task:Scrapy_bills - INFO - The work on page1896 has finished.
2017-08-26 02:56:57,526 - Task:Scrapy_bills - INFO - The work on page1897 has finished.
2017-08-26 03:00:21,107 - Task:Scrapy_bills - INFO - The work on page1898 has finished.
2017-08-26 03:03:50,095 - Task:Scrapy_bills - INFO - The work on page1899 has finished.
2017-08-26 03:03:50,932 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1891-1900.json
2017-08-26 03:07:19,397 - Task:Scrapy_bills - INFO - The work on page1900 has finished.
2017-08-26 03:10:36,617 - Task:Scrapy_bills - INFO - The work on page1901 has finished.
2017-08-26 03:14:04,098 - Task:Scrapy_bills - INFO - The work on page1902 has finished.
2017-08-26 03:14:53,405 - Task:Scrapy_bills - INFO - The work on page1903 has finished.
2017-08-26 03:16:27,355 - Task:Scrapy_bills - INFO - The work on page1904 has finished.
2017-08-26 03:19:45,884 - Task:Scrapy_bills - INFO - The work on page1905 has finished.
2017-08-26 03:23:04,103 - Task:Scrapy_bills - INFO - The work on page1906 has finished.
2017-08-26 03:26:33,184 - Task:Scrapy_bills - INFO - The work on page1907 has finished.
2017-08-26 03:29:47,892 - Task:Scrapy_bills - INFO - The work on page1908 has finished.
2017-08-26 03:33:06,645 - Task:Scrapy_bills - INFO - The work on page1909 has finished.
2017-08-26 03:33:07,414 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1901-1910.json
2017-08-26 03:36:30,104 - Task:Scrapy_bills - INFO - The work on page1910 has finished.
2017-08-26 03:39:48,879 - Task:Scrapy_bills - INFO - The work on page1911 has finished.
2017-08-26 03:43:08,698 - Task:Scrapy_bills - INFO - The work on page1912 has finished.
2017-08-26 03:46:28,135 - Task:Scrapy_bills - INFO - The work on page1913 has finished.
2017-08-26 03:49:49,532 - Task:Scrapy_bills - INFO - The work on page1914 has finished.
2017-08-26 03:53:07,911 - Task:Scrapy_bills - INFO - The work on page1915 has finished.
2017-08-26 03:56:25,737 - Task:Scrapy_bills - INFO - The work on page1916 has finished.
2017-08-26 03:59:43,584 - Task:Scrapy_bills - INFO - The work on page1917 has finished.
2017-08-26 04:03:00,224 - Task:Scrapy_bills - INFO - The work on page1918 has finished.
2017-08-26 04:06:12,073 - Task:Scrapy_bills - INFO - The work on page1919 has finished.
2017-08-26 04:06:12,834 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1911-1920.json
2017-08-26 04:09:28,565 - Task:Scrapy_bills - INFO - The work on page1920 has finished.
2017-08-26 04:12:46,360 - Task:Scrapy_bills - INFO - The work on page1921 has finished.
2017-08-26 04:16:06,388 - Task:Scrapy_bills - INFO - The work on page1922 has finished.
2017-08-26 04:19:27,220 - Task:Scrapy_bills - INFO - The work on page1923 has finished.
2017-08-26 04:22:46,059 - Task:Scrapy_bills - INFO - The work on page1924 has finished.
2017-08-26 04:26:06,174 - Task:Scrapy_bills - INFO - The work on page1925 has finished.
2017-08-26 04:29:32,261 - Task:Scrapy_bills - INFO - The work on page1926 has finished.
2017-08-26 04:32:49,281 - Task:Scrapy_bills - INFO - The work on page1927 has finished.
2017-08-26 04:36:19,122 - Task:Scrapy_bills - INFO - The work on page1928 has finished.
2017-08-26 04:39:43,012 - Task:Scrapy_bills - INFO - The work on page1929 has finished.
2017-08-26 04:39:43,762 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1921-1930.json
2017-08-26 04:43:10,392 - Task:Scrapy_bills - INFO - The work on page1930 has finished.
2017-08-26 04:46:29,292 - Task:Scrapy_bills - INFO - The work on page1931 has finished.
2017-08-26 04:49:47,714 - Task:Scrapy_bills - INFO - The work on page1932 has finished.
2017-08-26 04:53:05,357 - Task:Scrapy_bills - INFO - The work on page1933 has finished.
2017-08-26 04:56:18,373 - Task:Scrapy_bills - INFO - The work on page1934 has finished.
2017-08-26 04:59:32,215 - Task:Scrapy_bills - INFO - The work on page1935 has finished.
2017-08-26 05:02:53,558 - Task:Scrapy_bills - INFO - The work on page1936 has finished.
2017-08-26 05:06:13,818 - Task:Scrapy_bills - INFO - The work on page1937 has finished.
2017-08-26 05:09:30,412 - Task:Scrapy_bills - INFO - The work on page1938 has finished.
2017-08-26 05:12:42,329 - Task:Scrapy_bills - INFO - The work on page1939 has finished.
2017-08-26 05:12:43,089 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1931-1940.json
2017-08-26 05:16:03,949 - Task:Scrapy_bills - INFO - The work on page1940 has finished.
2017-08-26 05:19:20,384 - Task:Scrapy_bills - INFO - The work on page1941 has finished.
2017-08-26 05:22:42,497 - Task:Scrapy_bills - INFO - The work on page1942 has finished.
2017-08-26 05:25:59,447 - Task:Scrapy_bills - INFO - The work on page1943 has finished.
2017-08-26 05:29:16,605 - Task:Scrapy_bills - INFO - The work on page1944 has finished.
2017-08-26 05:32:36,861 - Task:Scrapy_bills - INFO - The work on page1945 has finished.
2017-08-26 05:35:56,234 - Task:Scrapy_bills - INFO - The work on page1946 has finished.
2017-08-26 05:39:11,905 - Task:Scrapy_bills - INFO - The work on page1947 has finished.
2017-08-26 05:42:25,239 - Task:Scrapy_bills - INFO - The work on page1948 has finished.
2017-08-26 05:45:43,122 - Task:Scrapy_bills - INFO - The work on page1949 has finished.
2017-08-26 05:45:43,875 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1941-1950.json
2017-08-26 05:49:01,697 - Task:Scrapy_bills - INFO - The work on page1950 has finished.
2017-08-26 05:52:17,386 - Task:Scrapy_bills - INFO - The work on page1951 has finished.
2017-08-26 05:55:36,504 - Task:Scrapy_bills - INFO - The work on page1952 has finished.
2017-08-26 05:58:52,303 - Task:Scrapy_bills - INFO - The work on page1953 has finished.
2017-08-26 06:02:07,949 - Task:Scrapy_bills - INFO - The work on page1954 has finished.
2017-08-26 06:05:26,128 - Task:Scrapy_bills - INFO - The work on page1955 has finished.
2017-08-26 06:08:43,041 - Task:Scrapy_bills - INFO - The work on page1956 has finished.
2017-08-26 06:12:00,832 - Task:Scrapy_bills - INFO - The work on page1957 has finished.
2017-08-26 06:15:19,302 - Task:Scrapy_bills - INFO - The work on page1958 has finished.
2017-08-26 06:17:34,030 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 06:17:34,031 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

2017-08-26 06:20:41,804 - Task:Scrapy_bills - INFO - The work on page1959 has finished.
2017-08-26 06:20:42,578 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1951-1960.json
2017-08-26 06:24:02,668 - Task:Scrapy_bills - INFO - The work on page1960 has finished.
2017-08-26 06:27:22,654 - Task:Scrapy_bills - INFO - The work on page1961 has finished.
2017-08-26 06:30:33,768 - Task:Scrapy_bills - INFO - The work on page1962 has finished.
2017-08-26 06:33:54,649 - Task:Scrapy_bills - INFO - The work on page1963 has finished.
2017-08-26 06:37:19,108 - Task:Scrapy_bills - INFO - The work on page1964 has finished.
2017-08-26 06:40:43,511 - Task:Scrapy_bills - INFO - The work on page1965 has finished.
2017-08-26 06:44:06,225 - Task:Scrapy_bills - INFO - The work on page1966 has finished.
2017-08-26 06:47:27,380 - Task:Scrapy_bills - INFO - The work on page1967 has finished.
2017-08-26 06:50:50,988 - Task:Scrapy_bills - INFO - The work on page1968 has finished.
2017-08-26 06:54:14,183 - Task:Scrapy_bills - INFO - The work on page1969 has finished.
2017-08-26 06:54:14,997 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1961-1970.json
2017-08-26 06:57:41,129 - Task:Scrapy_bills - INFO - The work on page1970 has finished.
2017-08-26 07:01:08,513 - Task:Scrapy_bills - INFO - The work on page1971 has finished.
2017-08-26 07:04:35,874 - Task:Scrapy_bills - INFO - The work on page1972 has finished.
2017-08-26 07:08:01,409 - Task:Scrapy_bills - INFO - The work on page1973 has finished.
2017-08-26 07:11:26,478 - Task:Scrapy_bills - INFO - The work on page1974 has finished.
2017-08-26 07:14:52,816 - Task:Scrapy_bills - INFO - The work on page1975 has finished.
2017-08-26 07:18:18,922 - Task:Scrapy_bills - INFO - The work on page1976 has finished.
2017-08-26 07:21:46,106 - Task:Scrapy_bills - INFO - The work on page1977 has finished.
2017-08-26 07:25:15,035 - Task:Scrapy_bills - INFO - The work on page1978 has finished.
2017-08-26 07:28:39,977 - Task:Scrapy_bills - INFO - The work on page1979 has finished.
2017-08-26 07:28:40,809 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1971-1980.json
2017-08-26 07:32:09,682 - Task:Scrapy_bills - INFO - The work on page1980 has finished.
2017-08-26 07:35:38,887 - Task:Scrapy_bills - INFO - The work on page1981 has finished.
2017-08-26 07:39:09,553 - Task:Scrapy_bills - INFO - The work on page1982 has finished.
2017-08-26 07:42:47,868 - Task:Scrapy_bills - INFO - The work on page1983 has finished.
2017-08-26 07:46:14,576 - Task:Scrapy_bills - INFO - The work on page1984 has finished.
2017-08-26 07:49:38,634 - Task:Scrapy_bills - INFO - The work on page1985 has finished.
2017-08-26 07:53:07,471 - Task:Scrapy_bills - INFO - The work on page1986 has finished.
2017-08-26 07:56:41,386 - Task:Scrapy_bills - INFO - The work on page1987 has finished.
2017-08-26 08:00:08,217 - Task:Scrapy_bills - INFO - The work on page1988 has finished.
2017-08-26 08:03:34,245 - Task:Scrapy_bills - INFO - The work on page1989 has finished.
2017-08-26 08:03:35,074 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1981-1990.json
2017-08-26 08:07:06,433 - Task:Scrapy_bills - INFO - The work on page1990 has finished.
2017-08-26 08:10:34,920 - Task:Scrapy_bills - INFO - The work on page1991 has finished.
2017-08-26 08:14:02,867 - Task:Scrapy_bills - INFO - The work on page1992 has finished.
2017-08-26 08:17:29,009 - Task:Scrapy_bills - INFO - The work on page1993 has finished.
2017-08-26 08:20:57,282 - Task:Scrapy_bills - INFO - The work on page1994 has finished.
2017-08-26 08:24:26,277 - Task:Scrapy_bills - INFO - The work on page1995 has finished.
2017-08-26 08:27:54,866 - Task:Scrapy_bills - INFO - The work on page1996 has finished.
2017-08-26 08:31:21,705 - Task:Scrapy_bills - INFO - The work on page1997 has finished.
2017-08-26 08:34:49,974 - Task:Scrapy_bills - INFO - The work on page1998 has finished.
2017-08-26 08:38:13,799 - Task:Scrapy_bills - INFO - The work on page1999 has finished.
2017-08-26 08:38:14,629 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation1991-2000.json
2017-08-26 08:41:39,714 - Task:Scrapy_bills - INFO - The work on page2000 has finished.
2017-08-26 08:45:04,913 - Task:Scrapy_bills - INFO - The work on page2001 has finished.
2017-08-26 08:48:33,528 - Task:Scrapy_bills - INFO - The work on page2002 has finished.
2017-08-26 08:51:54,876 - Task:Scrapy_bills - INFO - The work on page2003 has finished.
2017-08-26 08:55:18,526 - Task:Scrapy_bills - INFO - The work on page2004 has finished.
2017-08-26 08:58:39,871 - Task:Scrapy_bills - INFO - The work on page2005 has finished.
2017-08-26 09:02:06,102 - Task:Scrapy_bills - INFO - The work on page2006 has finished.
2017-08-26 09:05:41,308 - Task:Scrapy_bills - INFO - The work on page2007 has finished.
2017-08-26 09:09:12,476 - Task:Scrapy_bills - INFO - The work on page2008 has finished.
2017-08-26 09:12:44,284 - Task:Scrapy_bills - INFO - The work on page2009 has finished.
2017-08-26 09:12:45,114 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2001-2010.json
2017-08-26 09:16:17,757 - Task:Scrapy_bills - INFO - The work on page2010 has finished.
2017-08-26 09:19:41,851 - Task:Scrapy_bills - INFO - The work on page2011 has finished.
2017-08-26 09:23:15,177 - Task:Scrapy_bills - INFO - The work on page2012 has finished.
2017-08-26 09:26:48,568 - Task:Scrapy_bills - INFO - The work on page2013 has finished.
2017-08-26 09:30:14,148 - Task:Scrapy_bills - INFO - The work on page2014 has finished.
2017-08-26 09:31:38,628 - Task:Scrapy_bills - INFO - The work on page2015 has finished.
2017-08-26 09:32:05,444 - Task:Scrapy_bills - INFO - The work on page2016 has finished.
2017-08-26 09:32:26,582 - Task:Scrapy_bills - INFO - The work on page2017 has finished.
2017-08-26 09:32:57,561 - Task:Scrapy_bills - INFO - The work on page2018 has finished.
2017-08-26 09:33:02,506 - Task:Scrapy_bills - INFO - The work on page2019 has finished.
2017-08-26 09:33:03,204 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2011-2020.json
2017-08-26 09:33:08,781 - Task:Scrapy_bills - INFO - The work on page2020 has finished.
2017-08-26 09:33:15,026 - Task:Scrapy_bills - INFO - The work on page2021 has finished.
2017-08-26 09:34:01,544 - Task:Scrapy_bills - INFO - The work on page2022 has finished.
2017-08-26 09:37:32,836 - Task:Scrapy_bills - INFO - The work on page2023 has finished.
2017-08-26 09:41:11,787 - Task:Scrapy_bills - INFO - The work on page2024 has finished.
2017-08-26 09:44:41,140 - Task:Scrapy_bills - INFO - The work on page2025 has finished.
2017-08-26 09:48:13,583 - Task:Scrapy_bills - INFO - The work on page2026 has finished.
2017-08-26 09:51:48,067 - Task:Scrapy_bills - INFO - The work on page2027 has finished.
2017-08-26 09:55:17,089 - Task:Scrapy_bills - INFO - The work on page2028 has finished.
2017-08-26 09:58:28,012 - Task:Scrapy_bills - INFO - The work on page2029 has finished.
2017-08-26 09:58:28,740 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2021-2030.json
2017-08-26 10:01:45,225 - Task:Scrapy_bills - INFO - The work on page2030 has finished.
2017-08-26 10:05:06,974 - Task:Scrapy_bills - INFO - The work on page2031 has finished.
2017-08-26 10:08:23,653 - Task:Scrapy_bills - INFO - The work on page2032 has finished.
2017-08-26 10:11:38,398 - Task:Scrapy_bills - INFO - The work on page2033 has finished.
2017-08-26 10:14:50,715 - Task:Scrapy_bills - INFO - The work on page2034 has finished.
2017-08-26 10:18:01,645 - Task:Scrapy_bills - INFO - The work on page2035 has finished.
2017-08-26 10:21:10,062 - Task:Scrapy_bills - INFO - The work on page2036 has finished.
2017-08-26 10:24:19,164 - Task:Scrapy_bills - INFO - The work on page2037 has finished.
2017-08-26 10:27:48,658 - Task:Scrapy_bills - INFO - The work on page2038 has finished.
2017-08-26 10:28:07,143 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:28:07,144 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:28:18,233 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:28:18,234 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:28:34,280 - Task:Scrapy_bills - INFO - The work on page2040 has finished.
2017-08-26 10:28:35,023 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2031-2040.json
2017-08-26 10:29:13,705 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:29:13,706 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:29:24,727 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:29:24,728 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:29:41,208 - Task:Scrapy_bills - INFO - The work on page2041 has finished.
2017-08-26 10:29:53,549 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:29:53,551 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:30:08,998 - Task:Scrapy_bills - INFO - The work on page2043 has finished.
2017-08-26 10:30:10,972 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:30:10,974 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:30:22,163 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:30:22,165 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:30:33,159 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:30:33,160 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:31:25,539 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:31:25,541 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:31:41,322 - Task:Scrapy_bills - INFO - The work on page2045 has finished.
2017-08-26 10:31:42,810 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:31:42,812 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:32:05,162 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:32:05,163 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:32:21,716 - Task:Scrapy_bills - INFO - The work on page2047 has finished.
2017-08-26 10:32:30,120 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:32:30,121 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:32:46,511 - Task:Scrapy_bills - INFO - The work on page2049 has finished.
2017-08-26 10:32:47,050 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2041-2050.json
2017-08-26 10:33:24,336 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:33:24,337 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:33:40,218 - Task:Scrapy_bills - INFO - The work on page2051 has finished.
2017-08-26 10:33:41,705 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:33:41,708 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:33:58,642 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:33:58,643 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:34:27,577 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:34:27,578 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:34:38,559 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:34:38,559 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:34:54,720 - Task:Scrapy_bills - INFO - The work on page2053 has finished.
2017-08-26 10:35:10,364 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:35:10,366 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:35:26,087 - Task:Scrapy_bills - INFO - The work on page2055 has finished.
2017-08-26 10:35:35,555 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:35:35,556 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:35:51,381 - Task:Scrapy_bills - INFO - The work on page2057 has finished.
2017-08-26 10:36:46,764 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:36:46,766 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:37:02,863 - Task:Scrapy_bills - INFO - The work on page2059 has finished.
2017-08-26 10:37:03,405 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2051-2060.json
2017-08-26 10:37:11,787 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:37:11,788 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:40:54,344 - Task:Scrapy_bills - INFO - The work on page2060 has finished.
2017-08-26 10:44:28,276 - Task:Scrapy_bills - INFO - The work on page2061 has finished.
2017-08-26 10:46:04,931 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 10:46:04,933 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-26 10:46:21,644 - Task:Scrapy_bills - INFO - The work on page2063 has finished.
2017-08-26 10:47:19,363 - Task:Scrapy_bills - INFO - The work on page2064 has finished.
2017-08-26 10:48:13,714 - Task:Scrapy_bills - INFO - The work on page2065 has finished.
2017-08-26 10:48:40,094 - Task:Scrapy_bills - INFO - The work on page2066 has finished.
2017-08-26 10:52:06,761 - Task:Scrapy_bills - INFO - The work on page2067 has finished.
2017-08-26 10:55:41,639 - Task:Scrapy_bills - INFO - The work on page2068 has finished.
2017-08-26 10:59:17,655 - Task:Scrapy_bills - INFO - The work on page2069 has finished.
2017-08-26 10:59:18,359 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2061-2070.json
2017-08-26 11:02:42,014 - Task:Scrapy_bills - INFO - The work on page2070 has finished.
2017-08-26 11:05:54,791 - Task:Scrapy_bills - INFO - The work on page2071 has finished.
2017-08-26 11:09:05,750 - Task:Scrapy_bills - INFO - The work on page2072 has finished.
2017-08-26 11:12:18,907 - Task:Scrapy_bills - INFO - The work on page2073 has finished.
2017-08-26 11:15:32,651 - Task:Scrapy_bills - INFO - The work on page2074 has finished.
2017-08-26 11:18:45,762 - Task:Scrapy_bills - INFO - The work on page2075 has finished.
2017-08-26 11:22:02,594 - Task:Scrapy_bills - INFO - The work on page2076 has finished.
2017-08-26 11:25:15,985 - Task:Scrapy_bills - INFO - The work on page2077 has finished.
2017-08-26 11:28:32,756 - Task:Scrapy_bills - INFO - The work on page2078 has finished.
2017-08-26 11:31:49,991 - Task:Scrapy_bills - INFO - The work on page2079 has finished.
2017-08-26 11:31:50,747 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2071-2080.json
2017-08-26 11:35:07,032 - Task:Scrapy_bills - INFO - The work on page2080 has finished.
2017-08-26 11:38:18,496 - Task:Scrapy_bills - INFO - The work on page2081 has finished.
2017-08-26 11:41:33,840 - Task:Scrapy_bills - INFO - The work on page2082 has finished.
2017-08-26 11:44:48,344 - Task:Scrapy_bills - INFO - The work on page2083 has finished.
2017-08-26 11:48:01,218 - Task:Scrapy_bills - INFO - The work on page2084 has finished.
2017-08-26 11:51:17,419 - Task:Scrapy_bills - INFO - The work on page2085 has finished.
2017-08-26 11:54:33,300 - Task:Scrapy_bills - INFO - The work on page2086 has finished.
2017-08-26 11:57:47,393 - Task:Scrapy_bills - INFO - The work on page2087 has finished.
2017-08-26 12:01:01,529 - Task:Scrapy_bills - INFO - The work on page2088 has finished.
2017-08-26 12:04:19,802 - Task:Scrapy_bills - INFO - The work on page2089 has finished.
2017-08-26 12:04:20,568 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2081-2090.json
2017-08-26 12:07:46,111 - Task:Scrapy_bills - INFO - The work on page2090 has finished.
2017-08-26 12:11:08,086 - Task:Scrapy_bills - INFO - The work on page2091 has finished.
2017-08-26 12:14:28,396 - Task:Scrapy_bills - INFO - The work on page2092 has finished.
2017-08-26 12:17:41,564 - Task:Scrapy_bills - INFO - The work on page2093 has finished.
2017-08-26 12:20:55,698 - Task:Scrapy_bills - INFO - The work on page2094 has finished.
2017-08-26 12:24:14,195 - Task:Scrapy_bills - INFO - The work on page2095 has finished.
2017-08-26 12:27:34,007 - Task:Scrapy_bills - INFO - The work on page2096 has finished.
2017-08-26 12:30:57,226 - Task:Scrapy_bills - INFO - The work on page2097 has finished.
2017-08-26 12:34:24,262 - Task:Scrapy_bills - INFO - The work on page2098 has finished.
2017-08-26 12:37:51,757 - Task:Scrapy_bills - INFO - The work on page2099 has finished.
2017-08-26 12:37:52,536 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2091-2100.json
2017-08-26 12:41:26,929 - Task:Scrapy_bills - INFO - The work on page2100 has finished.
2017-08-26 12:44:53,478 - Task:Scrapy_bills - INFO - The work on page2101 has finished.
2017-08-26 12:48:15,197 - Task:Scrapy_bills - INFO - The work on page2102 has finished.
2017-08-26 12:51:41,099 - Task:Scrapy_bills - INFO - The work on page2103 has finished.
2017-08-26 12:55:06,441 - Task:Scrapy_bills - INFO - The work on page2104 has finished.
2017-08-26 12:58:32,631 - Task:Scrapy_bills - INFO - The work on page2105 has finished.
2017-08-26 13:02:00,980 - Task:Scrapy_bills - INFO - The work on page2106 has finished.
2017-08-26 13:05:33,542 - Task:Scrapy_bills - INFO - The work on page2107 has finished.
2017-08-26 13:09:12,835 - Task:Scrapy_bills - INFO - The work on page2108 has finished.
2017-08-26 13:12:49,220 - Task:Scrapy_bills - INFO - The work on page2109 has finished.
2017-08-26 13:12:50,053 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2101-2110.json
2017-08-26 13:16:25,142 - Task:Scrapy_bills - INFO - The work on page2110 has finished.
2017-08-26 13:19:52,154 - Task:Scrapy_bills - INFO - The work on page2111 has finished.
2017-08-26 13:23:23,093 - Task:Scrapy_bills - INFO - The work on page2112 has finished.
2017-08-26 13:26:56,429 - Task:Scrapy_bills - INFO - The work on page2113 has finished.
2017-08-26 13:30:19,792 - Task:Scrapy_bills - INFO - The work on page2114 has finished.
2017-08-26 13:33:49,247 - Task:Scrapy_bills - INFO - The work on page2115 has finished.
2017-08-26 13:37:15,966 - Task:Scrapy_bills - INFO - The work on page2116 has finished.
2017-08-26 13:40:49,593 - Task:Scrapy_bills - INFO - The work on page2117 has finished.
2017-08-26 13:44:17,651 - Task:Scrapy_bills - INFO - The work on page2118 has finished.
2017-08-26 13:47:49,754 - Task:Scrapy_bills - INFO - The work on page2119 has finished.
2017-08-26 13:47:50,588 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2111-2120.json
2017-08-26 13:51:17,594 - Task:Scrapy_bills - INFO - The work on page2120 has finished.
2017-08-26 13:54:47,605 - Task:Scrapy_bills - INFO - The work on page2121 has finished.
2017-08-26 13:58:16,037 - Task:Scrapy_bills - INFO - The work on page2122 has finished.
2017-08-26 14:01:41,634 - Task:Scrapy_bills - INFO - The work on page2123 has finished.
2017-08-26 14:05:11,662 - Task:Scrapy_bills - INFO - The work on page2124 has finished.
2017-08-26 14:08:42,616 - Task:Scrapy_bills - INFO - The work on page2125 has finished.
2017-08-26 14:12:07,131 - Task:Scrapy_bills - INFO - The work on page2126 has finished.
2017-08-26 14:15:41,213 - Task:Scrapy_bills - INFO - The work on page2127 has finished.
2017-08-26 14:19:07,069 - Task:Scrapy_bills - INFO - The work on page2128 has finished.
2017-08-26 14:22:32,186 - Task:Scrapy_bills - INFO - The work on page2129 has finished.
2017-08-26 14:22:33,015 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2121-2130.json
2017-08-26 14:25:59,788 - Task:Scrapy_bills - INFO - The work on page2130 has finished.
2017-08-26 14:29:33,416 - Task:Scrapy_bills - INFO - The work on page2131 has finished.
2017-08-26 14:33:04,685 - Task:Scrapy_bills - INFO - The work on page2132 has finished.
2017-08-26 14:36:38,024 - Task:Scrapy_bills - INFO - The work on page2133 has finished.
2017-08-26 14:40:11,022 - Task:Scrapy_bills - INFO - The work on page2134 has finished.
2017-08-26 14:43:41,957 - Task:Scrapy_bills - INFO - The work on page2135 has finished.
2017-08-26 14:47:11,429 - Task:Scrapy_bills - INFO - The work on page2136 has finished.
2017-08-26 14:50:46,553 - Task:Scrapy_bills - INFO - The work on page2137 has finished.
2017-08-26 14:54:24,556 - Task:Scrapy_bills - INFO - The work on page2138 has finished.
2017-08-26 14:58:02,297 - Task:Scrapy_bills - INFO - The work on page2139 has finished.
2017-08-26 14:58:03,133 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2131-2140.json
2017-08-26 15:01:45,854 - Task:Scrapy_bills - INFO - The work on page2140 has finished.
2017-08-26 15:05:22,774 - Task:Scrapy_bills - INFO - The work on page2141 has finished.
2017-08-26 15:08:54,791 - Task:Scrapy_bills - INFO - The work on page2142 has finished.
2017-08-26 15:12:23,736 - Task:Scrapy_bills - INFO - The work on page2143 has finished.
2017-08-26 15:12:57,895 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 15:12:57,898 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-26 15:16:33,053 - Task:Scrapy_bills - INFO - The work on page2144 has finished.
2017-08-26 15:20:00,013 - Task:Scrapy_bills - INFO - The work on page2145 has finished.
2017-08-26 15:23:26,639 - Task:Scrapy_bills - INFO - The work on page2146 has finished.
2017-08-26 15:27:00,104 - Task:Scrapy_bills - INFO - The work on page2147 has finished.
2017-08-26 15:30:34,131 - Task:Scrapy_bills - INFO - The work on page2148 has finished.
2017-08-26 15:34:12,727 - Task:Scrapy_bills - INFO - The work on page2149 has finished.
2017-08-26 15:34:13,561 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2141-2150.json
2017-08-26 15:37:52,092 - Task:Scrapy_bills - INFO - The work on page2150 has finished.
2017-08-26 15:41:21,380 - Task:Scrapy_bills - INFO - The work on page2151 has finished.
2017-08-26 15:44:56,545 - Task:Scrapy_bills - INFO - The work on page2152 has finished.
2017-08-26 15:48:31,137 - Task:Scrapy_bills - INFO - The work on page2153 has finished.
2017-08-26 15:52:03,103 - Task:Scrapy_bills - INFO - The work on page2154 has finished.
2017-08-26 15:55:39,886 - Task:Scrapy_bills - INFO - The work on page2155 has finished.
2017-08-26 15:59:11,219 - Task:Scrapy_bills - INFO - The work on page2156 has finished.
2017-08-26 16:02:46,492 - Task:Scrapy_bills - INFO - The work on page2157 has finished.
2017-08-26 16:04:57,281 - Task:Scrapy_bills - INFO - The work on page2158 has finished.
2017-08-26 16:05:43,885 - Task:Scrapy_bills - INFO - The work on page2159 has finished.
2017-08-26 16:05:44,678 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2151-2160.json
2017-08-26 16:06:29,168 - Task:Scrapy_bills - INFO - The work on page2160 has finished.
2017-08-26 16:07:11,725 - Task:Scrapy_bills - INFO - The work on page2161 has finished.
2017-08-26 16:07:57,467 - Task:Scrapy_bills - INFO - The work on page2162 has finished.
2017-08-26 16:08:17,541 - Task:Scrapy_bills - INFO - The work on page2163 has finished.
2017-08-26 16:08:22,206 - Task:Scrapy_bills - INFO - The work on page2164 has finished.
2017-08-26 16:08:27,256 - Task:Scrapy_bills - INFO - The work on page2165 has finished.
2017-08-26 16:08:31,973 - Task:Scrapy_bills - INFO - The work on page2166 has finished.
2017-08-26 16:08:44,187 - Task:Scrapy_bills - INFO - The work on page2167 has finished.
2017-08-26 16:12:23,753 - Task:Scrapy_bills - INFO - The work on page2168 has finished.
2017-08-26 16:16:00,725 - Task:Scrapy_bills - INFO - The work on page2169 has finished.
2017-08-26 16:16:01,343 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2161-2170.json
2017-08-26 16:19:38,476 - Task:Scrapy_bills - INFO - The work on page2170 has finished.
2017-08-26 16:23:14,945 - Task:Scrapy_bills - INFO - The work on page2171 has finished.
2017-08-26 16:26:49,338 - Task:Scrapy_bills - INFO - The work on page2172 has finished.
2017-08-26 16:30:25,545 - Task:Scrapy_bills - INFO - The work on page2173 has finished.
2017-08-26 16:33:40,140 - Task:Scrapy_bills - INFO - The work on page2174 has finished.
2017-08-26 16:36:50,137 - Task:Scrapy_bills - INFO - The work on page2175 has finished.
2017-08-26 16:40:02,566 - Task:Scrapy_bills - INFO - The work on page2176 has finished.
2017-08-26 16:43:13,285 - Task:Scrapy_bills - INFO - The work on page2177 has finished.
2017-08-26 16:46:24,375 - Task:Scrapy_bills - INFO - The work on page2178 has finished.
2017-08-26 16:49:35,815 - Task:Scrapy_bills - INFO - The work on page2179 has finished.
2017-08-26 16:49:36,593 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2171-2180.json
2017-08-26 16:52:51,104 - Task:Scrapy_bills - INFO - The work on page2180 has finished.
2017-08-26 16:56:10,228 - Task:Scrapy_bills - INFO - The work on page2181 has finished.
2017-08-26 16:59:21,332 - Task:Scrapy_bills - INFO - The work on page2182 has finished.
2017-08-26 17:02:53,656 - Task:Scrapy_bills - INFO - The work on page2183 has finished.
2017-08-26 17:06:26,984 - Task:Scrapy_bills - INFO - The work on page2184 has finished.
2017-08-26 17:10:01,306 - Task:Scrapy_bills - INFO - The work on page2185 has finished.
2017-08-26 17:13:37,304 - Task:Scrapy_bills - INFO - The work on page2186 has finished.
2017-08-26 17:17:04,937 - Task:Scrapy_bills - INFO - The work on page2187 has finished.
2017-08-26 17:20:35,668 - Task:Scrapy_bills - INFO - The work on page2188 has finished.
2017-08-26 17:24:09,917 - Task:Scrapy_bills - INFO - The work on page2189 has finished.
2017-08-26 17:24:10,729 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2181-2190.json
2017-08-26 17:27:39,866 - Task:Scrapy_bills - INFO - The work on page2190 has finished.
2017-08-26 17:31:08,180 - Task:Scrapy_bills - INFO - The work on page2191 has finished.
2017-08-26 17:34:35,746 - Task:Scrapy_bills - INFO - The work on page2192 has finished.
2017-08-26 17:38:04,969 - Task:Scrapy_bills - INFO - The work on page2193 has finished.
2017-08-26 17:41:40,406 - Task:Scrapy_bills - INFO - The work on page2194 has finished.
2017-08-26 17:45:21,410 - Task:Scrapy_bills - INFO - The work on page2195 has finished.
2017-08-26 17:48:55,487 - Task:Scrapy_bills - INFO - The work on page2196 has finished.
2017-08-26 17:52:31,163 - Task:Scrapy_bills - INFO - The work on page2197 has finished.
2017-08-26 17:56:06,088 - Task:Scrapy_bills - INFO - The work on page2198 has finished.
2017-08-26 17:59:43,395 - Task:Scrapy_bills - INFO - The work on page2199 has finished.
2017-08-26 17:59:44,231 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2191-2200.json
2017-08-26 18:03:27,462 - Task:Scrapy_bills - INFO - The work on page2200 has finished.
2017-08-26 18:06:59,580 - Task:Scrapy_bills - INFO - The work on page2201 has finished.
2017-08-26 18:10:33,778 - Task:Scrapy_bills - INFO - The work on page2202 has finished.
2017-08-26 18:14:13,972 - Task:Scrapy_bills - INFO - The work on page2203 has finished.
2017-08-26 18:17:48,465 - Task:Scrapy_bills - INFO - The work on page2204 has finished.
2017-08-26 18:21:30,824 - Task:Scrapy_bills - INFO - The work on page2205 has finished.
2017-08-26 18:25:05,774 - Task:Scrapy_bills - INFO - The work on page2206 has finished.
2017-08-26 18:28:39,509 - Task:Scrapy_bills - INFO - The work on page2207 has finished.
2017-08-26 18:32:16,518 - Task:Scrapy_bills - INFO - The work on page2208 has finished.
2017-08-26 18:35:48,852 - Task:Scrapy_bills - INFO - The work on page2209 has finished.
2017-08-26 18:35:49,690 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2201-2210.json
2017-08-26 18:39:28,222 - Task:Scrapy_bills - INFO - The work on page2210 has finished.
2017-08-26 18:43:07,345 - Task:Scrapy_bills - INFO - The work on page2211 has finished.
2017-08-26 18:46:39,307 - Task:Scrapy_bills - INFO - The work on page2212 has finished.
2017-08-26 18:50:09,828 - Task:Scrapy_bills - INFO - The work on page2213 has finished.
2017-08-26 18:53:37,514 - Task:Scrapy_bills - INFO - The work on page2214 has finished.
2017-08-26 18:57:15,542 - Task:Scrapy_bills - INFO - The work on page2215 has finished.
2017-08-26 19:00:40,125 - Task:Scrapy_bills - INFO - The work on page2216 has finished.
2017-08-26 19:01:16,735 - Task:Scrapy_bills - INFO - The work on page2217 has finished.
2017-08-26 19:01:58,146 - Task:Scrapy_bills - INFO - The work on page2218 has finished.
2017-08-26 19:02:53,119 - Task:Scrapy_bills - INFO - The work on page2219 has finished.
2017-08-26 19:02:53,866 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2211-2220.json
2017-08-26 19:03:05,367 - Task:Scrapy_bills - INFO - The work on page2220 has finished.
2017-08-26 19:03:55,934 - Task:Scrapy_bills - INFO - The work on page2221 has finished.
2017-08-26 19:07:47,583 - Task:Scrapy_bills - INFO - The work on page2222 has finished.
2017-08-26 19:11:39,595 - Task:Scrapy_bills - INFO - The work on page2223 has finished.
2017-08-26 19:15:39,793 - Task:Scrapy_bills - INFO - The work on page2224 has finished.
2017-08-26 19:19:11,471 - Task:Scrapy_bills - INFO - The work on page2225 has finished.
2017-08-26 19:22:24,680 - Task:Scrapy_bills - INFO - The work on page2226 has finished.
2017-08-26 19:25:39,258 - Task:Scrapy_bills - INFO - The work on page2227 has finished.
2017-08-26 19:28:51,435 - Task:Scrapy_bills - INFO - The work on page2228 has finished.
2017-08-26 19:32:04,058 - Task:Scrapy_bills - INFO - The work on page2229 has finished.
2017-08-26 19:32:04,790 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2221-2230.json
2017-08-26 19:35:21,475 - Task:Scrapy_bills - INFO - The work on page2230 has finished.
2017-08-26 19:38:32,206 - Task:Scrapy_bills - INFO - The work on page2231 has finished.
2017-08-26 19:41:45,702 - Task:Scrapy_bills - INFO - The work on page2232 has finished.
2017-08-26 19:44:56,502 - Task:Scrapy_bills - INFO - The work on page2233 has finished.
2017-08-26 19:48:09,411 - Task:Scrapy_bills - INFO - The work on page2234 has finished.
2017-08-26 19:51:20,868 - Task:Scrapy_bills - INFO - The work on page2235 has finished.
2017-08-26 19:54:40,581 - Task:Scrapy_bills - INFO - The work on page2236 has finished.
2017-08-26 19:57:50,218 - Task:Scrapy_bills - INFO - The work on page2237 has finished.
2017-08-26 20:01:02,509 - Task:Scrapy_bills - INFO - The work on page2238 has finished.
2017-08-26 20:04:15,955 - Task:Scrapy_bills - INFO - The work on page2239 has finished.
2017-08-26 20:04:16,688 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2231-2240.json
2017-08-26 20:07:28,566 - Task:Scrapy_bills - INFO - The work on page2240 has finished.
2017-08-26 20:10:39,712 - Task:Scrapy_bills - INFO - The work on page2241 has finished.
2017-08-26 20:13:50,781 - Task:Scrapy_bills - INFO - The work on page2242 has finished.
2017-08-26 20:17:04,735 - Task:Scrapy_bills - INFO - The work on page2243 has finished.
2017-08-26 20:20:18,948 - Task:Scrapy_bills - INFO - The work on page2244 has finished.
2017-08-26 20:23:33,858 - Task:Scrapy_bills - INFO - The work on page2245 has finished.
2017-08-26 20:26:47,293 - Task:Scrapy_bills - INFO - The work on page2246 has finished.
2017-08-26 20:29:59,557 - Task:Scrapy_bills - INFO - The work on page2247 has finished.
2017-08-26 20:33:11,973 - Task:Scrapy_bills - INFO - The work on page2248 has finished.
2017-08-26 20:36:26,339 - Task:Scrapy_bills - INFO - The work on page2249 has finished.
2017-08-26 20:36:27,094 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2241-2250.json
2017-08-26 20:39:41,866 - Task:Scrapy_bills - INFO - The work on page2250 has finished.
2017-08-26 20:42:58,484 - Task:Scrapy_bills - INFO - The work on page2251 has finished.
2017-08-26 20:46:13,243 - Task:Scrapy_bills - INFO - The work on page2252 has finished.
2017-08-26 20:49:28,363 - Task:Scrapy_bills - INFO - The work on page2253 has finished.
2017-08-26 20:52:42,285 - Task:Scrapy_bills - INFO - The work on page2254 has finished.
2017-08-26 20:55:54,350 - Task:Scrapy_bills - INFO - The work on page2255 has finished.
2017-08-26 20:59:05,651 - Task:Scrapy_bills - INFO - The work on page2256 has finished.
2017-08-26 21:02:19,301 - Task:Scrapy_bills - INFO - The work on page2257 has finished.
2017-08-26 21:05:30,953 - Task:Scrapy_bills - INFO - The work on page2258 has finished.
2017-08-26 21:08:42,098 - Task:Scrapy_bills - INFO - The work on page2259 has finished.
2017-08-26 21:08:42,866 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2251-2260.json
2017-08-26 21:11:55,875 - Task:Scrapy_bills - INFO - The work on page2260 has finished.
2017-08-26 21:15:23,930 - Task:Scrapy_bills - INFO - The work on page2261 has finished.
2017-08-26 21:18:45,677 - Task:Scrapy_bills - INFO - The work on page2262 has finished.
2017-08-26 21:22:05,582 - Task:Scrapy_bills - INFO - The work on page2263 has finished.
2017-08-26 21:25:32,120 - Task:Scrapy_bills - INFO - The work on page2264 has finished.
2017-08-26 21:28:56,805 - Task:Scrapy_bills - INFO - The work on page2265 has finished.
2017-08-26 21:32:25,527 - Task:Scrapy_bills - INFO - The work on page2266 has finished.
2017-08-26 21:35:54,712 - Task:Scrapy_bills - INFO - The work on page2267 has finished.
2017-08-26 21:39:23,026 - Task:Scrapy_bills - INFO - The work on page2268 has finished.
2017-08-26 21:42:51,169 - Task:Scrapy_bills - INFO - The work on page2269 has finished.
2017-08-26 21:42:52,005 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2261-2270.json
2017-08-26 21:46:21,017 - Task:Scrapy_bills - INFO - The work on page2270 has finished.
2017-08-26 21:49:47,332 - Task:Scrapy_bills - INFO - The work on page2271 has finished.
2017-08-26 21:53:14,386 - Task:Scrapy_bills - INFO - The work on page2272 has finished.
2017-08-26 21:56:42,375 - Task:Scrapy_bills - INFO - The work on page2273 has finished.
2017-08-26 22:00:07,518 - Task:Scrapy_bills - INFO - The work on page2274 has finished.
2017-08-26 22:03:34,170 - Task:Scrapy_bills - INFO - The work on page2275 has finished.
2017-08-26 22:07:06,707 - Task:Scrapy_bills - INFO - The work on page2276 has finished.
2017-08-26 22:10:35,896 - Task:Scrapy_bills - INFO - The work on page2277 has finished.
2017-08-26 22:14:11,445 - Task:Scrapy_bills - INFO - The work on page2278 has finished.
2017-08-26 22:17:40,456 - Task:Scrapy_bills - INFO - The work on page2279 has finished.
2017-08-26 22:17:41,287 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2271-2280.json
2017-08-26 22:21:08,267 - Task:Scrapy_bills - INFO - The work on page2280 has finished.
2017-08-26 22:24:34,774 - Task:Scrapy_bills - INFO - The work on page2281 has finished.
2017-08-26 22:28:03,816 - Task:Scrapy_bills - INFO - The work on page2282 has finished.
2017-08-26 22:31:32,295 - Task:Scrapy_bills - INFO - The work on page2283 has finished.
2017-08-26 22:35:02,005 - Task:Scrapy_bills - INFO - The work on page2284 has finished.
2017-08-26 22:38:26,463 - Task:Scrapy_bills - INFO - The work on page2285 has finished.
2017-08-26 22:41:59,808 - Task:Scrapy_bills - INFO - The work on page2286 has finished.
2017-08-26 22:45:34,341 - Task:Scrapy_bills - INFO - The work on page2287 has finished.
2017-08-26 22:49:04,911 - Task:Scrapy_bills - INFO - The work on page2288 has finished.
2017-08-26 22:52:30,812 - Task:Scrapy_bills - INFO - The work on page2289 has finished.
2017-08-26 22:52:31,660 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2281-2290.json
2017-08-26 22:56:15,867 - Task:Scrapy_bills - INFO - The work on page2290 has finished.
2017-08-26 22:59:47,693 - Task:Scrapy_bills - INFO - The work on page2291 has finished.
2017-08-26 23:03:21,493 - Task:Scrapy_bills - INFO - The work on page2292 has finished.
2017-08-26 23:06:48,296 - Task:Scrapy_bills - INFO - The work on page2293 has finished.
2017-08-26 23:10:25,575 - Task:Scrapy_bills - INFO - The work on page2294 has finished.
2017-08-26 23:14:01,248 - Task:Scrapy_bills - INFO - The work on page2295 has finished.
2017-08-26 23:17:35,506 - Task:Scrapy_bills - INFO - The work on page2296 has finished.
2017-08-26 23:21:06,893 - Task:Scrapy_bills - INFO - The work on page2297 has finished.
2017-08-26 23:24:38,026 - Task:Scrapy_bills - INFO - The work on page2298 has finished.
2017-08-26 23:28:16,222 - Task:Scrapy_bills - INFO - The work on page2299 has finished.
2017-08-26 23:28:17,055 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2291-2300.json
2017-08-26 23:31:58,015 - Task:Scrapy_bills - INFO - The work on page2300 has finished.
2017-08-26 23:35:39,854 - Task:Scrapy_bills - INFO - The work on page2301 has finished.
2017-08-26 23:39:12,440 - Task:Scrapy_bills - INFO - The work on page2302 has finished.
2017-08-26 23:42:43,545 - Task:Scrapy_bills - INFO - The work on page2303 has finished.
2017-08-26 23:46:15,313 - Task:Scrapy_bills - INFO - The work on page2304 has finished.
2017-08-26 23:49:43,515 - Task:Scrapy_bills - INFO - The work on page2305 has finished.
2017-08-26 23:53:16,545 - Task:Scrapy_bills - INFO - The work on page2306 has finished.
2017-08-26 23:56:49,701 - Task:Scrapy_bills - INFO - The work on page2307 has finished.
2017-08-26 23:57:24,173 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-26 23:57:24,175 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-27 00:01:05,924 - Task:Scrapy_bills - INFO - The work on page2308 has finished.
2017-08-27 00:04:31,524 - Task:Scrapy_bills - INFO - The work on page2309 has finished.
2017-08-27 00:04:32,356 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2301-2310.json
2017-08-27 00:08:04,620 - Task:Scrapy_bills - INFO - The work on page2310 has finished.
2017-08-27 00:11:37,726 - Task:Scrapy_bills - INFO - The work on page2311 has finished.
2017-08-27 00:15:09,192 - Task:Scrapy_bills - INFO - The work on page2312 has finished.
2017-08-27 00:18:37,845 - Task:Scrapy_bills - INFO - The work on page2313 has finished.
2017-08-27 00:22:09,698 - Task:Scrapy_bills - INFO - The work on page2314 has finished.
2017-08-27 00:25:45,287 - Task:Scrapy_bills - INFO - The work on page2315 has finished.
2017-08-27 00:29:19,706 - Task:Scrapy_bills - INFO - The work on page2316 has finished.
2017-08-27 00:32:59,419 - Task:Scrapy_bills - INFO - The work on page2317 has finished.
2017-08-27 00:36:30,794 - Task:Scrapy_bills - INFO - The work on page2318 has finished.
2017-08-27 00:39:07,216 - Task:Scrapy_bills - INFO - The work on page2319 has finished.
2017-08-27 00:39:08,026 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2311-2320.json
2017-08-27 00:39:45,682 - Task:Scrapy_bills - INFO - The work on page2320 has finished.
2017-08-27 00:40:16,041 - Task:Scrapy_bills - INFO - The work on page2321 has finished.
2017-08-27 00:40:51,903 - Task:Scrapy_bills - INFO - The work on page2322 has finished.
2017-08-27 00:41:13,651 - Task:Scrapy_bills - INFO - The work on page2323 has finished.
2017-08-27 00:41:41,148 - Task:Scrapy_bills - INFO - The work on page2324 has finished.
2017-08-27 00:42:11,014 - Task:Scrapy_bills - INFO - The work on page2325 has finished.
2017-08-27 00:42:19,188 - Task:Scrapy_bills - INFO - The work on page2326 has finished.
2017-08-27 00:42:24,481 - Task:Scrapy_bills - INFO - The work on page2327 has finished.
2017-08-27 00:42:29,150 - Task:Scrapy_bills - INFO - The work on page2328 has finished.
2017-08-27 00:42:33,878 - Task:Scrapy_bills - INFO - The work on page2329 has finished.
2017-08-27 00:42:34,435 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2321-2330.json
2017-08-27 00:44:25,092 - Task:Scrapy_bills - INFO - The work on page2330 has finished.
2017-08-27 00:48:02,233 - Task:Scrapy_bills - INFO - The work on page2331 has finished.
2017-08-27 00:51:36,124 - Task:Scrapy_bills - INFO - The work on page2332 has finished.
2017-08-27 00:55:14,891 - Task:Scrapy_bills - INFO - The work on page2333 has finished.
2017-08-27 00:58:48,766 - Task:Scrapy_bills - INFO - The work on page2334 has finished.
2017-08-27 01:02:23,197 - Task:Scrapy_bills - INFO - The work on page2335 has finished.
2017-08-27 01:05:39,630 - Task:Scrapy_bills - INFO - The work on page2336 has finished.
2017-08-27 01:08:54,227 - Task:Scrapy_bills - INFO - The work on page2337 has finished.
2017-08-27 01:12:06,854 - Task:Scrapy_bills - INFO - The work on page2338 has finished.
2017-08-27 01:15:19,853 - Task:Scrapy_bills - INFO - The work on page2339 has finished.
2017-08-27 01:15:20,642 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2331-2340.json
2017-08-27 01:18:35,148 - Task:Scrapy_bills - INFO - The work on page2340 has finished.
2017-08-27 01:21:47,795 - Task:Scrapy_bills - INFO - The work on page2341 has finished.
2017-08-27 01:25:02,331 - Task:Scrapy_bills - INFO - The work on page2342 has finished.
2017-08-27 01:28:11,116 - Task:Scrapy_bills - INFO - The work on page2343 has finished.
2017-08-27 01:31:21,498 - Task:Scrapy_bills - INFO - The work on page2344 has finished.
2017-08-27 01:34:50,537 - Task:Scrapy_bills - INFO - The work on page2345 has finished.
2017-08-27 01:38:23,746 - Task:Scrapy_bills - INFO - The work on page2346 has finished.
2017-08-27 01:41:55,613 - Task:Scrapy_bills - INFO - The work on page2347 has finished.
2017-08-27 01:45:31,482 - Task:Scrapy_bills - INFO - The work on page2348 has finished.
2017-08-27 01:49:07,775 - Task:Scrapy_bills - INFO - The work on page2349 has finished.
2017-08-27 01:49:08,568 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2341-2350.json
2017-08-27 01:52:40,846 - Task:Scrapy_bills - INFO - The work on page2350 has finished.
2017-08-27 01:56:13,579 - Task:Scrapy_bills - INFO - The work on page2351 has finished.
2017-08-27 01:59:45,772 - Task:Scrapy_bills - INFO - The work on page2352 has finished.
2017-08-27 02:03:18,766 - Task:Scrapy_bills - INFO - The work on page2353 has finished.
2017-08-27 02:06:51,945 - Task:Scrapy_bills - INFO - The work on page2354 has finished.
2017-08-27 02:10:23,600 - Task:Scrapy_bills - INFO - The work on page2355 has finished.
2017-08-27 02:13:54,613 - Task:Scrapy_bills - INFO - The work on page2356 has finished.
2017-08-27 02:17:26,038 - Task:Scrapy_bills - INFO - The work on page2357 has finished.
2017-08-27 02:20:58,336 - Task:Scrapy_bills - INFO - The work on page2358 has finished.
2017-08-27 02:24:28,517 - Task:Scrapy_bills - INFO - The work on page2359 has finished.
2017-08-27 02:24:29,345 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2351-2360.json
2017-08-27 02:28:00,120 - Task:Scrapy_bills - INFO - The work on page2360 has finished.
2017-08-27 02:31:35,580 - Task:Scrapy_bills - INFO - The work on page2361 has finished.
2017-08-27 02:35:12,863 - Task:Scrapy_bills - INFO - The work on page2362 has finished.
2017-08-27 02:38:48,531 - Task:Scrapy_bills - INFO - The work on page2363 has finished.
2017-08-27 02:42:24,349 - Task:Scrapy_bills - INFO - The work on page2364 has finished.
2017-08-27 02:45:57,945 - Task:Scrapy_bills - INFO - The work on page2365 has finished.
2017-08-27 02:49:31,886 - Task:Scrapy_bills - INFO - The work on page2366 has finished.
2017-08-27 02:52:59,933 - Task:Scrapy_bills - INFO - The work on page2367 has finished.
2017-08-27 02:56:36,114 - Task:Scrapy_bills - INFO - The work on page2368 has finished.
2017-08-27 03:00:17,957 - Task:Scrapy_bills - INFO - The work on page2369 has finished.
2017-08-27 03:00:18,782 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2361-2370.json
2017-08-27 03:04:00,523 - Task:Scrapy_bills - INFO - The work on page2370 has finished.
2017-08-27 03:07:37,912 - Task:Scrapy_bills - INFO - The work on page2371 has finished.
2017-08-27 03:11:16,137 - Task:Scrapy_bills - INFO - The work on page2372 has finished.
2017-08-27 03:14:49,981 - Task:Scrapy_bills - INFO - The work on page2373 has finished.
2017-08-27 03:18:20,990 - Task:Scrapy_bills - INFO - The work on page2374 has finished.
2017-08-27 03:21:59,446 - Task:Scrapy_bills - INFO - The work on page2375 has finished.
2017-08-27 03:25:32,264 - Task:Scrapy_bills - INFO - The work on page2376 has finished.
2017-08-27 03:28:30,433 - Task:Scrapy_bills - INFO - The work on page2377 has finished.
2017-08-27 03:29:47,898 - Task:Scrapy_bills - INFO - The work on page2378 has finished.
2017-08-27 03:31:02,146 - Task:Scrapy_bills - INFO - The work on page2379 has finished.
2017-08-27 03:31:02,935 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2371-2380.json
2017-08-27 03:32:22,726 - Task:Scrapy_bills - INFO - The work on page2380 has finished.
2017-08-27 03:32:58,821 - Task:Scrapy_bills - INFO - The work on page2381 has finished.
2017-08-27 03:33:03,764 - Task:Scrapy_bills - INFO - The work on page2382 has finished.
2017-08-27 03:35:44,028 - Task:Scrapy_bills - INFO - The work on page2383 has finished.
2017-08-27 03:39:23,895 - Task:Scrapy_bills - INFO - The work on page2384 has finished.
2017-08-27 03:42:57,282 - Task:Scrapy_bills - INFO - The work on page2385 has finished.
2017-08-27 03:46:30,762 - Task:Scrapy_bills - INFO - The work on page2386 has finished.
2017-08-27 03:49:42,792 - Task:Scrapy_bills - INFO - The work on page2387 has finished.
2017-08-27 03:52:53,904 - Task:Scrapy_bills - INFO - The work on page2388 has finished.
2017-08-27 03:56:08,723 - Task:Scrapy_bills - INFO - The work on page2389 has finished.
2017-08-27 03:56:09,441 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2381-2390.json
2017-08-27 03:59:23,309 - Task:Scrapy_bills - INFO - The work on page2390 has finished.
2017-08-27 04:02:35,891 - Task:Scrapy_bills - INFO - The work on page2391 has finished.
2017-08-27 04:05:49,486 - Task:Scrapy_bills - INFO - The work on page2392 has finished.
2017-08-27 04:09:01,533 - Task:Scrapy_bills - INFO - The work on page2393 has finished.
2017-08-27 04:12:13,942 - Task:Scrapy_bills - INFO - The work on page2394 has finished.
2017-08-27 04:15:27,717 - Task:Scrapy_bills - INFO - The work on page2395 has finished.
2017-08-27 04:18:39,451 - Task:Scrapy_bills - INFO - The work on page2396 has finished.
2017-08-27 04:21:50,966 - Task:Scrapy_bills - INFO - The work on page2397 has finished.
2017-08-27 04:25:06,012 - Task:Scrapy_bills - INFO - The work on page2398 has finished.
2017-08-27 04:28:18,927 - Task:Scrapy_bills - INFO - The work on page2399 has finished.
2017-08-27 04:28:19,688 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2391-2400.json
2017-08-27 04:31:40,577 - Task:Scrapy_bills - INFO - The work on page2400 has finished.
2017-08-27 04:34:59,452 - Task:Scrapy_bills - INFO - The work on page2401 has finished.
2017-08-27 04:38:16,961 - Task:Scrapy_bills - INFO - The work on page2402 has finished.
2017-08-27 04:41:30,231 - Task:Scrapy_bills - INFO - The work on page2403 has finished.
2017-08-27 04:44:46,761 - Task:Scrapy_bills - INFO - The work on page2404 has finished.
2017-08-27 04:47:59,892 - Task:Scrapy_bills - INFO - The work on page2405 has finished.
2017-08-27 04:51:15,258 - Task:Scrapy_bills - INFO - The work on page2406 has finished.
2017-08-27 04:54:32,444 - Task:Scrapy_bills - INFO - The work on page2407 has finished.
2017-08-27 04:57:44,597 - Task:Scrapy_bills - INFO - The work on page2408 has finished.
2017-08-27 05:00:55,220 - Task:Scrapy_bills - INFO - The work on page2409 has finished.
2017-08-27 05:00:55,973 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2401-2410.json
2017-08-27 05:04:10,251 - Task:Scrapy_bills - INFO - The work on page2410 has finished.
2017-08-27 05:07:21,230 - Task:Scrapy_bills - INFO - The work on page2411 has finished.
2017-08-27 05:10:33,190 - Task:Scrapy_bills - INFO - The work on page2412 has finished.
2017-08-27 05:13:46,075 - Task:Scrapy_bills - INFO - The work on page2413 has finished.
2017-08-27 05:17:00,327 - Task:Scrapy_bills - INFO - The work on page2414 has finished.
2017-08-27 05:20:13,996 - Task:Scrapy_bills - INFO - The work on page2415 has finished.
2017-08-27 05:23:26,996 - Task:Scrapy_bills - INFO - The work on page2416 has finished.
2017-08-27 05:26:40,782 - Task:Scrapy_bills - INFO - The work on page2417 has finished.
2017-08-27 05:29:50,038 - Task:Scrapy_bills - INFO - The work on page2418 has finished.
2017-08-27 05:33:09,465 - Task:Scrapy_bills - INFO - The work on page2419 has finished.
2017-08-27 05:33:10,225 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2411-2420.json
2017-08-27 05:36:35,931 - Task:Scrapy_bills - INFO - The work on page2420 has finished.
2017-08-27 05:39:56,638 - Task:Scrapy_bills - INFO - The work on page2421 has finished.
2017-08-27 05:43:24,057 - Task:Scrapy_bills - INFO - The work on page2422 has finished.
2017-08-27 05:46:53,454 - Task:Scrapy_bills - INFO - The work on page2423 has finished.
2017-08-27 05:50:24,470 - Task:Scrapy_bills - INFO - The work on page2424 has finished.
2017-08-27 05:53:48,935 - Task:Scrapy_bills - INFO - The work on page2425 has finished.
2017-08-27 05:57:19,175 - Task:Scrapy_bills - INFO - The work on page2426 has finished.
2017-08-27 06:00:52,677 - Task:Scrapy_bills - INFO - The work on page2427 has finished.
2017-08-27 06:04:20,119 - Task:Scrapy_bills - INFO - The work on page2428 has finished.
2017-08-27 06:07:46,035 - Task:Scrapy_bills - INFO - The work on page2429 has finished.
2017-08-27 06:07:46,870 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2421-2430.json
2017-08-27 06:11:17,163 - Task:Scrapy_bills - INFO - The work on page2430 has finished.
2017-08-27 06:14:48,109 - Task:Scrapy_bills - INFO - The work on page2431 has finished.
2017-08-27 06:18:15,439 - Task:Scrapy_bills - INFO - The work on page2432 has finished.
2017-08-27 06:21:46,278 - Task:Scrapy_bills - INFO - The work on page2433 has finished.
2017-08-27 06:25:15,119 - Task:Scrapy_bills - INFO - The work on page2434 has finished.
2017-08-27 06:28:44,382 - Task:Scrapy_bills - INFO - The work on page2435 has finished.
2017-08-27 06:32:13,899 - Task:Scrapy_bills - INFO - The work on page2436 has finished.
2017-08-27 06:35:45,862 - Task:Scrapy_bills - INFO - The work on page2437 has finished.
2017-08-27 06:39:20,065 - Task:Scrapy_bills - INFO - The work on page2438 has finished.
2017-08-27 06:42:54,814 - Task:Scrapy_bills - INFO - The work on page2439 has finished.
2017-08-27 06:42:55,650 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2431-2440.json
2017-08-27 06:46:25,915 - Task:Scrapy_bills - INFO - The work on page2440 has finished.
2017-08-27 06:50:02,504 - Task:Scrapy_bills - INFO - The work on page2441 has finished.
2017-08-27 06:53:37,172 - Task:Scrapy_bills - INFO - The work on page2442 has finished.
2017-08-27 06:57:05,112 - Task:Scrapy_bills - INFO - The work on page2443 has finished.
2017-08-27 07:00:38,267 - Task:Scrapy_bills - INFO - The work on page2444 has finished.
2017-08-27 07:04:14,027 - Task:Scrapy_bills - INFO - The work on page2445 has finished.
2017-08-27 07:07:46,017 - Task:Scrapy_bills - INFO - The work on page2446 has finished.
2017-08-27 07:11:19,499 - Task:Scrapy_bills - INFO - The work on page2447 has finished.
2017-08-27 07:14:55,066 - Task:Scrapy_bills - INFO - The work on page2448 has finished.
2017-08-27 07:18:29,542 - Task:Scrapy_bills - INFO - The work on page2449 has finished.
2017-08-27 07:18:30,359 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2441-2450.json
2017-08-27 07:22:06,298 - Task:Scrapy_bills - INFO - The work on page2450 has finished.
2017-08-27 07:25:46,427 - Task:Scrapy_bills - INFO - The work on page2451 has finished.
2017-08-27 07:29:20,303 - Task:Scrapy_bills - INFO - The work on page2452 has finished.
2017-08-27 07:32:58,559 - Task:Scrapy_bills - INFO - The work on page2453 has finished.
2017-08-27 07:36:31,354 - Task:Scrapy_bills - INFO - The work on page2454 has finished.
2017-08-27 07:40:16,351 - Task:Scrapy_bills - INFO - The work on page2455 has finished.
2017-08-27 07:43:52,742 - Task:Scrapy_bills - INFO - The work on page2456 has finished.
2017-08-27 07:47:21,920 - Task:Scrapy_bills - INFO - The work on page2457 has finished.
2017-08-27 07:50:52,603 - Task:Scrapy_bills - INFO - The work on page2458 has finished.
2017-08-27 07:54:22,125 - Task:Scrapy_bills - INFO - The work on page2459 has finished.
2017-08-27 07:54:22,952 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2451-2460.json
2017-08-27 07:57:57,334 - Task:Scrapy_bills - INFO - The work on page2460 has finished.
2017-08-27 08:01:30,537 - Task:Scrapy_bills - INFO - The work on page2461 has finished.
2017-08-27 08:05:06,230 - Task:Scrapy_bills - INFO - The work on page2462 has finished.
2017-08-27 08:08:37,166 - Task:Scrapy_bills - INFO - The work on page2463 has finished.
2017-08-27 08:12:04,432 - Task:Scrapy_bills - INFO - The work on page2464 has finished.
2017-08-27 08:15:36,999 - Task:Scrapy_bills - INFO - The work on page2465 has finished.
2017-08-27 08:19:02,195 - Task:Scrapy_bills - INFO - The work on page2466 has finished.
2017-08-27 08:22:37,711 - Task:Scrapy_bills - INFO - The work on page2467 has finished.
2017-08-27 08:26:14,416 - Task:Scrapy_bills - INFO - The work on page2468 has finished.
2017-08-27 08:29:46,497 - Task:Scrapy_bills - INFO - The work on page2469 has finished.
2017-08-27 08:29:47,321 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2461-2470.json
2017-08-27 08:33:24,304 - Task:Scrapy_bills - INFO - The work on page2470 has finished.
2017-08-27 08:36:51,793 - Task:Scrapy_bills - INFO - The work on page2471 has finished.
2017-08-27 08:40:25,430 - Task:Scrapy_bills - INFO - The work on page2472 has finished.
2017-08-27 08:43:57,914 - Task:Scrapy_bills - INFO - The work on page2473 has finished.
2017-08-27 08:47:23,300 - Task:Scrapy_bills - INFO - The work on page2474 has finished.
2017-08-27 08:47:57,044 - Task:Scrapy_bills - INFO - The work on page2475 has finished.
2017-08-27 08:48:39,087 - Task:Scrapy_bills - INFO - The work on page2476 has finished.
2017-08-27 08:49:22,996 - Task:Scrapy_bills - INFO - The work on page2477 has finished.
2017-08-27 08:49:55,938 - Task:Scrapy_bills - INFO - The work on page2478 has finished.
2017-08-27 08:50:17,324 - Task:Scrapy_bills - INFO - The work on page2479 has finished.
2017-08-27 08:50:18,031 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2471-2480.json
2017-08-27 08:50:54,198 - Task:Scrapy_bills - INFO - The work on page2480 has finished.
2017-08-27 08:51:06,234 - Task:Scrapy_bills - INFO - The work on page2481 has finished.
2017-08-27 08:51:11,127 - Task:Scrapy_bills - INFO - The work on page2482 has finished.
2017-08-27 08:51:15,798 - Task:Scrapy_bills - INFO - The work on page2483 has finished.
2017-08-27 08:51:20,586 - Task:Scrapy_bills - INFO - The work on page2484 has finished.
2017-08-27 08:52:18,301 - Task:Scrapy_bills - INFO - The work on page2485 has finished.
2017-08-27 08:55:53,086 - Task:Scrapy_bills - INFO - The work on page2486 has finished.
2017-08-27 08:59:28,640 - Task:Scrapy_bills - INFO - The work on page2487 has finished.
2017-08-27 09:03:15,074 - Task:Scrapy_bills - INFO - The work on page2488 has finished.
2017-08-27 09:06:55,907 - Task:Scrapy_bills - INFO - The work on page2489 has finished.
2017-08-27 09:06:56,560 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2481-2490.json
2017-08-27 09:10:31,124 - Task:Scrapy_bills - INFO - The work on page2490 has finished.
2017-08-27 09:14:03,866 - Task:Scrapy_bills - INFO - The work on page2491 has finished.
2017-08-27 09:17:15,620 - Task:Scrapy_bills - INFO - The work on page2492 has finished.
2017-08-27 09:20:26,978 - Task:Scrapy_bills - INFO - The work on page2493 has finished.
2017-08-27 09:23:38,952 - Task:Scrapy_bills - INFO - The work on page2494 has finished.
2017-08-27 09:26:51,012 - Task:Scrapy_bills - INFO - The work on page2495 has finished.
2017-08-27 09:30:07,032 - Task:Scrapy_bills - INFO - The work on page2496 has finished.
2017-08-27 09:33:19,393 - Task:Scrapy_bills - INFO - The work on page2497 has finished.
2017-08-27 09:36:31,873 - Task:Scrapy_bills - INFO - The work on page2498 has finished.
2017-08-27 09:39:43,367 - Task:Scrapy_bills - INFO - The work on page2499 has finished.
2017-08-27 09:39:44,145 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2491-2500.json
2017-08-27 09:42:58,286 - Task:Scrapy_bills - INFO - The work on page2500 has finished.
2017-08-27 09:46:29,992 - Task:Scrapy_bills - INFO - The work on page2501 has finished.
2017-08-27 09:50:06,137 - Task:Scrapy_bills - INFO - The work on page2502 has finished.
2017-08-27 09:53:34,611 - Task:Scrapy_bills - INFO - The work on page2503 has finished.
2017-08-27 09:57:09,856 - Task:Scrapy_bills - INFO - The work on page2504 has finished.
2017-08-27 10:00:35,987 - Task:Scrapy_bills - INFO - The work on page2505 has finished.
2017-08-27 10:04:10,295 - Task:Scrapy_bills - INFO - The work on page2506 has finished.
2017-08-27 10:07:44,177 - Task:Scrapy_bills - INFO - The work on page2507 has finished.
2017-08-27 10:11:14,770 - Task:Scrapy_bills - INFO - The work on page2508 has finished.
2017-08-27 10:14:43,787 - Task:Scrapy_bills - INFO - The work on page2509 has finished.
2017-08-27 10:14:44,612 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2501-2510.json
2017-08-27 10:18:18,501 - Task:Scrapy_bills - INFO - The work on page2510 has finished.
2017-08-27 10:21:50,716 - Task:Scrapy_bills - INFO - The work on page2511 has finished.
2017-08-27 10:25:21,570 - Task:Scrapy_bills - INFO - The work on page2512 has finished.
2017-08-27 10:28:49,766 - Task:Scrapy_bills - INFO - The work on page2513 has finished.
2017-08-27 10:32:19,424 - Task:Scrapy_bills - INFO - The work on page2514 has finished.
2017-08-27 10:35:45,955 - Task:Scrapy_bills - INFO - The work on page2515 has finished.
2017-08-27 10:39:27,626 - Task:Scrapy_bills - INFO - The work on page2516 has finished.
2017-08-27 10:43:01,941 - Task:Scrapy_bills - INFO - The work on page2517 has finished.
2017-08-27 10:46:36,891 - Task:Scrapy_bills - INFO - The work on page2518 has finished.
2017-08-27 10:50:17,089 - Task:Scrapy_bills - INFO - The work on page2519 has finished.
2017-08-27 10:50:17,924 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2511-2520.json
2017-08-27 10:53:57,921 - Task:Scrapy_bills - INFO - The work on page2520 has finished.
2017-08-27 10:57:34,751 - Task:Scrapy_bills - INFO - The work on page2521 has finished.
2017-08-27 11:01:08,394 - Task:Scrapy_bills - INFO - The work on page2522 has finished.
2017-08-27 11:04:45,065 - Task:Scrapy_bills - INFO - The work on page2523 has finished.
2017-08-27 11:08:24,889 - Task:Scrapy_bills - INFO - The work on page2524 has finished.
2017-08-27 11:12:03,493 - Task:Scrapy_bills - INFO - The work on page2525 has finished.
2017-08-27 11:15:40,937 - Task:Scrapy_bills - INFO - The work on page2526 has finished.
2017-08-27 11:19:18,884 - Task:Scrapy_bills - INFO - The work on page2527 has finished.
2017-08-27 11:23:00,120 - Task:Scrapy_bills - INFO - The work on page2528 has finished.
2017-08-27 11:26:32,028 - Task:Scrapy_bills - INFO - The work on page2529 has finished.
2017-08-27 11:26:32,857 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2521-2530.json
2017-08-27 11:28:13,448 - Task:Scrapy_bills - INFO - The work on page2530 has finished.
2017-08-27 11:29:41,507 - Task:Scrapy_bills - INFO - The work on page2531 has finished.
2017-08-27 11:30:53,237 - Task:Scrapy_bills - INFO - The work on page2532 has finished.
2017-08-27 11:32:11,672 - Task:Scrapy_bills - INFO - The work on page2533 has finished.
2017-08-27 11:32:23,547 - Task:Scrapy_bills - INFO - The work on page2534 has finished.
2017-08-27 11:32:50,384 - Task:Scrapy_bills - INFO - The work on page2535 has finished.
2017-08-27 11:36:25,392 - Task:Scrapy_bills - INFO - The work on page2536 has finished.
2017-08-27 11:40:02,280 - Task:Scrapy_bills - INFO - The work on page2537 has finished.
2017-08-27 11:43:34,742 - Task:Scrapy_bills - INFO - The work on page2538 has finished.
2017-08-27 11:47:12,503 - Task:Scrapy_bills - INFO - The work on page2539 has finished.
2017-08-27 11:47:13,204 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2531-2540.json
2017-08-27 11:50:58,300 - Task:Scrapy_bills - INFO - The work on page2540 has finished.
2017-08-27 11:54:15,322 - Task:Scrapy_bills - INFO - The work on page2541 has finished.
2017-08-27 11:57:27,647 - Task:Scrapy_bills - INFO - The work on page2542 has finished.
2017-08-27 12:00:40,787 - Task:Scrapy_bills - INFO - The work on page2543 has finished.
2017-08-27 12:03:10,194 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 12:03:10,197 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 56, in <module>
    data = sm.amendment_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 129, in amendment_process
    all_information=str(self.read_code(all_infor_url))
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-27 12:03:51,220 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 12:03:51,220 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-27 12:07:13,088 - Task:Scrapy_bills - INFO - The work on page2544 has finished.
2017-08-27 12:10:27,273 - Task:Scrapy_bills - INFO - The work on page2545 has finished.
2017-08-27 12:13:43,511 - Task:Scrapy_bills - INFO - The work on page2546 has finished.
2017-08-27 12:16:57,410 - Task:Scrapy_bills - INFO - The work on page2547 has finished.
2017-08-27 12:20:11,313 - Task:Scrapy_bills - INFO - The work on page2548 has finished.
2017-08-27 12:23:29,782 - Task:Scrapy_bills - INFO - The work on page2549 has finished.
2017-08-27 12:23:30,578 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2541-2550.json
2017-08-27 12:26:46,453 - Task:Scrapy_bills - INFO - The work on page2550 has finished.
2017-08-27 12:29:59,116 - Task:Scrapy_bills - INFO - The work on page2551 has finished.
2017-08-27 12:33:09,641 - Task:Scrapy_bills - INFO - The work on page2552 has finished.
2017-08-27 12:36:31,691 - Task:Scrapy_bills - INFO - The work on page2553 has finished.
2017-08-27 12:39:47,111 - Task:Scrapy_bills - INFO - The work on page2554 has finished.
2017-08-27 12:43:00,530 - Task:Scrapy_bills - INFO - The work on page2555 has finished.
2017-08-27 12:46:15,260 - Task:Scrapy_bills - INFO - The work on page2556 has finished.
2017-08-27 12:49:29,481 - Task:Scrapy_bills - INFO - The work on page2557 has finished.
2017-08-27 12:52:44,052 - Task:Scrapy_bills - INFO - The work on page2558 has finished.
2017-08-27 12:55:56,544 - Task:Scrapy_bills - INFO - The work on page2559 has finished.
2017-08-27 12:55:57,291 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2551-2560.json
2017-08-27 12:59:14,148 - Task:Scrapy_bills - INFO - The work on page2560 has finished.
2017-08-27 13:02:26,835 - Task:Scrapy_bills - INFO - The work on page2561 has finished.
2017-08-27 13:05:42,432 - Task:Scrapy_bills - INFO - The work on page2562 has finished.
2017-08-27 13:08:55,243 - Task:Scrapy_bills - INFO - The work on page2563 has finished.
2017-08-27 13:12:11,720 - Task:Scrapy_bills - INFO - The work on page2564 has finished.
2017-08-27 13:15:27,444 - Task:Scrapy_bills - INFO - The work on page2565 has finished.
2017-08-27 13:18:45,851 - Task:Scrapy_bills - INFO - The work on page2566 has finished.
2017-08-27 13:22:00,913 - Task:Scrapy_bills - INFO - The work on page2567 has finished.
2017-08-27 13:25:15,912 - Task:Scrapy_bills - INFO - The work on page2568 has finished.
2017-08-27 13:28:31,162 - Task:Scrapy_bills - INFO - The work on page2569 has finished.
2017-08-27 13:28:31,922 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2561-2570.json
2017-08-27 13:31:47,185 - Task:Scrapy_bills - INFO - The work on page2570 has finished.
2017-08-27 13:35:07,270 - Task:Scrapy_bills - INFO - The work on page2571 has finished.
2017-08-27 13:38:24,012 - Task:Scrapy_bills - INFO - The work on page2572 has finished.
2017-08-27 13:41:40,965 - Task:Scrapy_bills - INFO - The work on page2573 has finished.
2017-08-27 13:44:56,910 - Task:Scrapy_bills - INFO - The work on page2574 has finished.
2017-08-27 13:48:13,974 - Task:Scrapy_bills - INFO - The work on page2575 has finished.
2017-08-27 13:51:31,352 - Task:Scrapy_bills - INFO - The work on page2576 has finished.
2017-08-27 13:54:54,180 - Task:Scrapy_bills - INFO - The work on page2577 has finished.
2017-08-27 13:58:09,661 - Task:Scrapy_bills - INFO - The work on page2578 has finished.
2017-08-27 14:01:40,764 - Task:Scrapy_bills - INFO - The work on page2579 has finished.
2017-08-27 14:01:41,523 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2571-2580.json
2017-08-27 14:05:16,920 - Task:Scrapy_bills - INFO - The work on page2580 has finished.
2017-08-27 14:08:47,506 - Task:Scrapy_bills - INFO - The work on page2581 has finished.
2017-08-27 14:12:16,069 - Task:Scrapy_bills - INFO - The work on page2582 has finished.
2017-08-27 14:15:53,773 - Task:Scrapy_bills - INFO - The work on page2583 has finished.
2017-08-27 14:19:28,174 - Task:Scrapy_bills - INFO - The work on page2584 has finished.
2017-08-27 14:23:06,197 - Task:Scrapy_bills - INFO - The work on page2585 has finished.
2017-08-27 14:26:36,259 - Task:Scrapy_bills - INFO - The work on page2586 has finished.
2017-08-27 14:30:07,561 - Task:Scrapy_bills - INFO - The work on page2587 has finished.
2017-08-27 14:33:39,554 - Task:Scrapy_bills - INFO - The work on page2588 has finished.
2017-08-27 14:37:10,608 - Task:Scrapy_bills - INFO - The work on page2589 has finished.
2017-08-27 14:37:11,439 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2581-2590.json
2017-08-27 14:40:51,305 - Task:Scrapy_bills - INFO - The work on page2590 has finished.
2017-08-27 14:44:26,459 - Task:Scrapy_bills - INFO - The work on page2591 has finished.
2017-08-27 14:48:04,553 - Task:Scrapy_bills - INFO - The work on page2592 has finished.
2017-08-27 14:51:47,636 - Task:Scrapy_bills - INFO - The work on page2593 has finished.
2017-08-27 14:55:21,853 - Task:Scrapy_bills - INFO - The work on page2594 has finished.
2017-08-27 14:58:09,280 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 14:58:09,283 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-27 14:58:25,037 - Task:Scrapy_bills - INFO - The work on page2596 has finished.
2017-08-27 15:02:04,747 - Task:Scrapy_bills - INFO - The work on page2597 has finished.
2017-08-27 15:05:39,815 - Task:Scrapy_bills - INFO - The work on page2598 has finished.
2017-08-27 15:09:17,872 - Task:Scrapy_bills - INFO - The work on page2599 has finished.
2017-08-27 15:09:18,659 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2591-2600.json
2017-08-27 15:12:56,194 - Task:Scrapy_bills - INFO - The work on page2600 has finished.
2017-08-27 15:16:31,458 - Task:Scrapy_bills - INFO - The work on page2601 has finished.
2017-08-27 15:20:09,671 - Task:Scrapy_bills - INFO - The work on page2602 has finished.
2017-08-27 15:20:44,365 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 15:20:44,367 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-27 15:24:27,532 - Task:Scrapy_bills - INFO - The work on page2603 has finished.
2017-08-27 15:28:04,040 - Task:Scrapy_bills - INFO - The work on page2604 has finished.
2017-08-27 15:31:39,876 - Task:Scrapy_bills - INFO - The work on page2605 has finished.
2017-08-27 15:35:18,657 - Task:Scrapy_bills - INFO - The work on page2606 has finished.
2017-08-27 15:38:50,492 - Task:Scrapy_bills - INFO - The work on page2607 has finished.
2017-08-27 15:42:26,416 - Task:Scrapy_bills - INFO - The work on page2608 has finished.
2017-08-27 15:45:57,603 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 15:45:57,604 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 503: Service Unavailable

2017-08-27 15:46:13,488 - Task:Scrapy_bills - INFO - The work on page2610 has finished.
2017-08-27 15:46:14,313 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2601-2610.json
2017-08-27 15:47:58,068 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 15:47:58,070 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 503: Service Unavailable

2017-08-27 15:48:14,263 - Task:Scrapy_bills - INFO - The work on page2611 has finished.
2017-08-27 15:51:49,928 - Task:Scrapy_bills - INFO - The work on page2612 has finished.
2017-08-27 15:55:28,965 - Task:Scrapy_bills - INFO - The work on page2613 has finished.
2017-08-27 15:59:01,995 - Task:Scrapy_bills - INFO - The work on page2614 has finished.
2017-08-27 16:02:41,831 - Task:Scrapy_bills - INFO - The work on page2615 has finished.
2017-08-27 16:06:19,765 - Task:Scrapy_bills - INFO - The work on page2616 has finished.
2017-08-27 16:10:01,461 - Task:Scrapy_bills - INFO - The work on page2617 has finished.
2017-08-27 16:12:20,805 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-27 16:12:20,807 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-27 16:12:36,396 - Task:Scrapy_bills - INFO - The work on page2619 has finished.
2017-08-27 16:12:37,135 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2611-2620.json
2017-08-27 16:16:18,973 - Task:Scrapy_bills - INFO - The work on page2620 has finished.
2017-08-27 16:19:59,528 - Task:Scrapy_bills - INFO - The work on page2621 has finished.
2017-08-27 16:23:44,357 - Task:Scrapy_bills - INFO - The work on page2622 has finished.
2017-08-27 16:27:31,711 - Task:Scrapy_bills - INFO - The work on page2623 has finished.
2017-08-27 16:31:13,336 - Task:Scrapy_bills - INFO - The work on page2624 has finished.
2017-08-27 16:34:56,810 - Task:Scrapy_bills - INFO - The work on page2625 has finished.
2017-08-27 16:38:41,183 - Task:Scrapy_bills - INFO - The work on page2626 has finished.
2017-08-27 16:42:18,918 - Task:Scrapy_bills - INFO - The work on page2627 has finished.
2017-08-27 16:45:58,820 - Task:Scrapy_bills - INFO - The work on page2628 has finished.
2017-08-27 16:49:43,542 - Task:Scrapy_bills - INFO - The work on page2629 has finished.
2017-08-27 16:49:44,376 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2621-2630.json
2017-08-27 16:53:22,640 - Task:Scrapy_bills - INFO - The work on page2630 has finished.
2017-08-27 16:57:11,984 - Task:Scrapy_bills - INFO - The work on page2631 has finished.
2017-08-27 17:01:02,413 - Task:Scrapy_bills - INFO - The work on page2632 has finished.
2017-08-27 17:04:44,424 - Task:Scrapy_bills - INFO - The work on page2633 has finished.
2017-08-27 17:08:24,525 - Task:Scrapy_bills - INFO - The work on page2634 has finished.
2017-08-27 17:12:04,880 - Task:Scrapy_bills - INFO - The work on page2635 has finished.
2017-08-27 17:13:40,413 - Task:Scrapy_bills - INFO - The work on page2636 has finished.
2017-08-27 17:14:26,182 - Task:Scrapy_bills - INFO - The work on page2637 has finished.
2017-08-27 17:15:05,884 - Task:Scrapy_bills - INFO - The work on page2638 has finished.
2017-08-27 17:15:53,390 - Task:Scrapy_bills - INFO - The work on page2639 has finished.
2017-08-27 17:15:54,123 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2631-2640.json
2017-08-27 17:16:24,826 - Task:Scrapy_bills - INFO - The work on page2640 has finished.
2017-08-27 17:16:56,696 - Task:Scrapy_bills - INFO - The work on page2641 has finished.
2017-08-27 17:17:23,927 - Task:Scrapy_bills - INFO - The work on page2642 has finished.
2017-08-27 17:17:49,553 - Task:Scrapy_bills - INFO - The work on page2643 has finished.
2017-08-27 17:17:54,580 - Task:Scrapy_bills - INFO - The work on page2644 has finished.
2017-08-27 17:17:59,641 - Task:Scrapy_bills - INFO - The work on page2645 has finished.
2017-08-27 17:18:04,845 - Task:Scrapy_bills - INFO - The work on page2646 has finished.
2017-08-27 17:18:09,739 - Task:Scrapy_bills - INFO - The work on page2647 has finished.
2017-08-27 17:21:39,708 - Task:Scrapy_bills - INFO - The work on page2648 has finished.
2017-08-27 17:25:19,575 - Task:Scrapy_bills - INFO - The work on page2649 has finished.
2017-08-27 17:25:20,181 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2641-2650.json
2017-08-27 17:29:06,405 - Task:Scrapy_bills - INFO - The work on page2650 has finished.
2017-08-27 17:32:53,480 - Task:Scrapy_bills - INFO - The work on page2651 has finished.
2017-08-27 17:36:41,901 - Task:Scrapy_bills - INFO - The work on page2652 has finished.
2017-08-27 17:40:30,044 - Task:Scrapy_bills - INFO - The work on page2653 has finished.
2017-08-27 17:43:47,508 - Task:Scrapy_bills - INFO - The work on page2654 has finished.
2017-08-27 17:47:02,145 - Task:Scrapy_bills - INFO - The work on page2655 has finished.
2017-08-27 17:50:14,203 - Task:Scrapy_bills - INFO - The work on page2656 has finished.
2017-08-27 17:53:29,021 - Task:Scrapy_bills - INFO - The work on page2657 has finished.
2017-08-27 17:56:50,471 - Task:Scrapy_bills - INFO - The work on page2658 has finished.
2017-08-27 18:00:07,546 - Task:Scrapy_bills - INFO - The work on page2659 has finished.
2017-08-27 18:00:08,333 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2651-2660.json
2017-08-27 18:03:24,942 - Task:Scrapy_bills - INFO - The work on page2660 has finished.
2017-08-27 18:06:39,914 - Task:Scrapy_bills - INFO - The work on page2661 has finished.
2017-08-27 18:10:01,639 - Task:Scrapy_bills - INFO - The work on page2662 has finished.
2017-08-27 18:13:31,038 - Task:Scrapy_bills - INFO - The work on page2663 has finished.
2017-08-27 18:16:54,867 - Task:Scrapy_bills - INFO - The work on page2664 has finished.
2017-08-27 18:20:08,513 - Task:Scrapy_bills - INFO - The work on page2665 has finished.
2017-08-27 18:23:32,407 - Task:Scrapy_bills - INFO - The work on page2666 has finished.
2017-08-27 18:27:11,931 - Task:Scrapy_bills - INFO - The work on page2667 has finished.
2017-08-27 18:30:49,543 - Task:Scrapy_bills - INFO - The work on page2668 has finished.
2017-08-27 18:34:25,492 - Task:Scrapy_bills - INFO - The work on page2669 has finished.
2017-08-27 18:34:26,279 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2661-2670.json
2017-08-27 18:38:05,274 - Task:Scrapy_bills - INFO - The work on page2670 has finished.
2017-08-27 18:41:39,736 - Task:Scrapy_bills - INFO - The work on page2671 has finished.
2017-08-27 18:45:16,847 - Task:Scrapy_bills - INFO - The work on page2672 has finished.
2017-08-27 18:48:57,980 - Task:Scrapy_bills - INFO - The work on page2673 has finished.
2017-08-27 18:52:31,829 - Task:Scrapy_bills - INFO - The work on page2674 has finished.
2017-08-27 18:56:12,714 - Task:Scrapy_bills - INFO - The work on page2675 has finished.
2017-08-27 18:59:57,653 - Task:Scrapy_bills - INFO - The work on page2676 has finished.
2017-08-27 19:03:47,235 - Task:Scrapy_bills - INFO - The work on page2677 has finished.
2017-08-27 19:07:50,104 - Task:Scrapy_bills - INFO - The work on page2678 has finished.
2017-08-27 19:11:43,460 - Task:Scrapy_bills - INFO - The work on page2679 has finished.
2017-08-27 19:11:44,289 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2671-2680.json
2017-08-27 19:15:39,703 - Task:Scrapy_bills - INFO - The work on page2680 has finished.
2017-08-27 19:19:35,570 - Task:Scrapy_bills - INFO - The work on page2681 has finished.
2017-08-27 19:23:16,779 - Task:Scrapy_bills - INFO - The work on page2682 has finished.
2017-08-27 19:26:56,056 - Task:Scrapy_bills - INFO - The work on page2683 has finished.
2017-08-27 19:30:34,336 - Task:Scrapy_bills - INFO - The work on page2684 has finished.
2017-08-27 19:34:12,680 - Task:Scrapy_bills - INFO - The work on page2685 has finished.
2017-08-27 19:37:56,573 - Task:Scrapy_bills - INFO - The work on page2686 has finished.
2017-08-27 19:41:34,937 - Task:Scrapy_bills - INFO - The work on page2687 has finished.
2017-08-27 19:45:16,996 - Task:Scrapy_bills - INFO - The work on page2688 has finished.
2017-08-27 19:49:03,072 - Task:Scrapy_bills - INFO - The work on page2689 has finished.
2017-08-27 19:49:03,896 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2681-2690.json
2017-08-27 19:52:49,106 - Task:Scrapy_bills - INFO - The work on page2690 has finished.
2017-08-27 19:56:32,264 - Task:Scrapy_bills - INFO - The work on page2691 has finished.
2017-08-27 20:00:12,304 - Task:Scrapy_bills - INFO - The work on page2692 has finished.
2017-08-27 20:03:53,624 - Task:Scrapy_bills - INFO - The work on page2693 has finished.
2017-08-27 20:07:35,762 - Task:Scrapy_bills - INFO - The work on page2694 has finished.
2017-08-27 20:11:16,548 - Task:Scrapy_bills - INFO - The work on page2695 has finished.
2017-08-27 20:12:32,276 - Task:Scrapy_bills - INFO - The work on page2696 has finished.
2017-08-27 20:14:08,868 - Task:Scrapy_bills - INFO - The work on page2697 has finished.
2017-08-27 20:15:37,908 - Task:Scrapy_bills - INFO - The work on page2698 has finished.
2017-08-27 20:17:04,615 - Task:Scrapy_bills - INFO - The work on page2699 has finished.
2017-08-27 20:17:05,376 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2691-2700.json
2017-08-27 20:17:24,088 - Task:Scrapy_bills - INFO - The work on page2700 has finished.
2017-08-27 20:17:29,042 - Task:Scrapy_bills - INFO - The work on page2701 has finished.
2017-08-27 20:20:53,277 - Task:Scrapy_bills - INFO - The work on page2702 has finished.
2017-08-27 20:24:30,082 - Task:Scrapy_bills - INFO - The work on page2703 has finished.
2017-08-27 20:28:04,802 - Task:Scrapy_bills - INFO - The work on page2704 has finished.
2017-08-27 20:31:40,433 - Task:Scrapy_bills - INFO - The work on page2705 has finished.
2017-08-27 20:35:22,821 - Task:Scrapy_bills - INFO - The work on page2706 has finished.
2017-08-27 20:38:52,308 - Task:Scrapy_bills - INFO - The work on page2707 has finished.
2017-08-27 20:42:04,284 - Task:Scrapy_bills - INFO - The work on page2708 has finished.
2017-08-27 20:45:17,937 - Task:Scrapy_bills - INFO - The work on page2709 has finished.
2017-08-27 20:45:18,682 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2701-2710.json
2017-08-27 20:48:36,311 - Task:Scrapy_bills - INFO - The work on page2710 has finished.
2017-08-27 20:51:49,935 - Task:Scrapy_bills - INFO - The work on page2711 has finished.
2017-08-27 20:55:02,953 - Task:Scrapy_bills - INFO - The work on page2712 has finished.
2017-08-27 20:58:14,413 - Task:Scrapy_bills - INFO - The work on page2713 has finished.
2017-08-27 21:01:27,321 - Task:Scrapy_bills - INFO - The work on page2714 has finished.
2017-08-27 21:04:40,022 - Task:Scrapy_bills - INFO - The work on page2715 has finished.
2017-08-27 21:07:55,091 - Task:Scrapy_bills - INFO - The work on page2716 has finished.
2017-08-27 21:11:08,501 - Task:Scrapy_bills - INFO - The work on page2717 has finished.
2017-08-27 21:14:20,560 - Task:Scrapy_bills - INFO - The work on page2718 has finished.
2017-08-27 21:17:34,032 - Task:Scrapy_bills - INFO - The work on page2719 has finished.
2017-08-27 21:17:34,779 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2711-2720.json
2017-08-27 21:20:49,102 - Task:Scrapy_bills - INFO - The work on page2720 has finished.
2017-08-27 21:24:01,541 - Task:Scrapy_bills - INFO - The work on page2721 has finished.
2017-08-27 21:27:16,311 - Task:Scrapy_bills - INFO - The work on page2722 has finished.
2017-08-27 21:30:26,864 - Task:Scrapy_bills - INFO - The work on page2723 has finished.
2017-08-27 21:33:39,913 - Task:Scrapy_bills - INFO - The work on page2724 has finished.
2017-08-27 21:36:52,963 - Task:Scrapy_bills - INFO - The work on page2725 has finished.
2017-08-27 21:40:04,756 - Task:Scrapy_bills - INFO - The work on page2726 has finished.
2017-08-27 21:43:17,460 - Task:Scrapy_bills - INFO - The work on page2727 has finished.
2017-08-27 21:46:30,977 - Task:Scrapy_bills - INFO - The work on page2728 has finished.
2017-08-27 21:49:44,266 - Task:Scrapy_bills - INFO - The work on page2729 has finished.
2017-08-27 21:49:45,022 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2721-2730.json
2017-08-27 21:53:03,469 - Task:Scrapy_bills - INFO - The work on page2730 has finished.
2017-08-27 21:56:18,316 - Task:Scrapy_bills - INFO - The work on page2731 has finished.
2017-08-27 21:59:30,781 - Task:Scrapy_bills - INFO - The work on page2732 has finished.
2017-08-27 22:02:43,062 - Task:Scrapy_bills - INFO - The work on page2733 has finished.
2017-08-27 22:05:54,101 - Task:Scrapy_bills - INFO - The work on page2734 has finished.
2017-08-27 22:09:06,580 - Task:Scrapy_bills - INFO - The work on page2735 has finished.
2017-08-27 22:12:20,444 - Task:Scrapy_bills - INFO - The work on page2736 has finished.
2017-08-27 22:15:34,921 - Task:Scrapy_bills - INFO - The work on page2737 has finished.
2017-08-27 22:18:47,685 - Task:Scrapy_bills - INFO - The work on page2738 has finished.
2017-08-27 22:22:02,119 - Task:Scrapy_bills - INFO - The work on page2739 has finished.
2017-08-27 22:22:02,867 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2731-2740.json
2017-08-27 22:25:18,489 - Task:Scrapy_bills - INFO - The work on page2740 has finished.
2017-08-27 22:28:28,794 - Task:Scrapy_bills - INFO - The work on page2741 has finished.
2017-08-27 22:31:40,590 - Task:Scrapy_bills - INFO - The work on page2742 has finished.
2017-08-27 22:35:02,985 - Task:Scrapy_bills - INFO - The work on page2743 has finished.
2017-08-27 22:38:32,135 - Task:Scrapy_bills - INFO - The work on page2744 has finished.
2017-08-27 22:42:00,976 - Task:Scrapy_bills - INFO - The work on page2745 has finished.
2017-08-27 22:45:30,656 - Task:Scrapy_bills - INFO - The work on page2746 has finished.
2017-08-27 22:49:02,597 - Task:Scrapy_bills - INFO - The work on page2747 has finished.
2017-08-27 22:52:34,814 - Task:Scrapy_bills - INFO - The work on page2748 has finished.
2017-08-27 22:56:04,665 - Task:Scrapy_bills - INFO - The work on page2749 has finished.
2017-08-27 22:56:05,468 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2741-2750.json
2017-08-27 22:59:38,431 - Task:Scrapy_bills - INFO - The work on page2750 has finished.
2017-08-27 23:03:14,132 - Task:Scrapy_bills - INFO - The work on page2751 has finished.
2017-08-27 23:06:44,003 - Task:Scrapy_bills - INFO - The work on page2752 has finished.
2017-08-27 23:10:13,521 - Task:Scrapy_bills - INFO - The work on page2753 has finished.
2017-08-27 23:13:46,669 - Task:Scrapy_bills - INFO - The work on page2754 has finished.
2017-08-27 23:17:22,217 - Task:Scrapy_bills - INFO - The work on page2755 has finished.
2017-08-27 23:20:56,927 - Task:Scrapy_bills - INFO - The work on page2756 has finished.
2017-08-27 23:24:28,785 - Task:Scrapy_bills - INFO - The work on page2757 has finished.
2017-08-27 23:28:03,585 - Task:Scrapy_bills - INFO - The work on page2758 has finished.
2017-08-27 23:31:39,478 - Task:Scrapy_bills - INFO - The work on page2759 has finished.
2017-08-27 23:31:40,306 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2751-2760.json
2017-08-27 23:35:21,502 - Task:Scrapy_bills - INFO - The work on page2760 has finished.
2017-08-27 23:39:00,201 - Task:Scrapy_bills - INFO - The work on page2761 has finished.
2017-08-27 23:42:34,225 - Task:Scrapy_bills - INFO - The work on page2762 has finished.
2017-08-27 23:46:13,875 - Task:Scrapy_bills - INFO - The work on page2763 has finished.
2017-08-27 23:49:53,303 - Task:Scrapy_bills - INFO - The work on page2764 has finished.
2017-08-27 23:53:28,216 - Task:Scrapy_bills - INFO - The work on page2765 has finished.
2017-08-27 23:57:06,297 - Task:Scrapy_bills - INFO - The work on page2766 has finished.
2017-08-28 00:00:40,312 - Task:Scrapy_bills - INFO - The work on page2767 has finished.
2017-08-28 00:04:15,445 - Task:Scrapy_bills - INFO - The work on page2768 has finished.
2017-08-28 00:07:50,024 - Task:Scrapy_bills - INFO - The work on page2769 has finished.
2017-08-28 00:07:50,848 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2761-2770.json
2017-08-28 00:11:25,750 - Task:Scrapy_bills - INFO - The work on page2770 has finished.
2017-08-28 00:15:02,564 - Task:Scrapy_bills - INFO - The work on page2771 has finished.
2017-08-28 00:18:43,462 - Task:Scrapy_bills - INFO - The work on page2772 has finished.
2017-08-28 00:22:20,173 - Task:Scrapy_bills - INFO - The work on page2773 has finished.
2017-08-28 00:26:02,184 - Task:Scrapy_bills - INFO - The work on page2774 has finished.
2017-08-28 00:29:40,047 - Task:Scrapy_bills - INFO - The work on page2775 has finished.
2017-08-28 00:33:12,256 - Task:Scrapy_bills - INFO - The work on page2776 has finished.
2017-08-28 00:36:52,524 - Task:Scrapy_bills - INFO - The work on page2777 has finished.
2017-08-28 00:40:34,043 - Task:Scrapy_bills - INFO - The work on page2778 has finished.
2017-08-28 00:44:08,363 - Task:Scrapy_bills - INFO - The work on page2779 has finished.
2017-08-28 00:44:09,195 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2771-2780.json
2017-08-28 00:47:51,506 - Task:Scrapy_bills - INFO - The work on page2780 has finished.
2017-08-28 00:51:29,641 - Task:Scrapy_bills - INFO - The work on page2781 has finished.
2017-08-28 00:55:09,624 - Task:Scrapy_bills - INFO - The work on page2782 has finished.
2017-08-28 00:58:48,719 - Task:Scrapy_bills - INFO - The work on page2783 has finished.
2017-08-28 01:02:25,682 - Task:Scrapy_bills - INFO - The work on page2784 has finished.
2017-08-28 01:06:06,505 - Task:Scrapy_bills - INFO - The work on page2785 has finished.
2017-08-28 01:09:48,437 - Task:Scrapy_bills - INFO - The work on page2786 has finished.
2017-08-28 01:13:23,773 - Task:Scrapy_bills - INFO - The work on page2787 has finished.
2017-08-28 01:17:07,074 - Task:Scrapy_bills - INFO - The work on page2788 has finished.
2017-08-28 01:20:45,889 - Task:Scrapy_bills - INFO - The work on page2789 has finished.
2017-08-28 01:20:46,706 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2781-2790.json
2017-08-28 01:24:30,400 - Task:Scrapy_bills - INFO - The work on page2790 has finished.
2017-08-28 01:28:24,928 - Task:Scrapy_bills - INFO - The work on page2791 has finished.
2017-08-28 01:32:27,766 - Task:Scrapy_bills - INFO - The work on page2792 has finished.
2017-08-28 01:36:22,877 - Task:Scrapy_bills - INFO - The work on page2793 has finished.
2017-08-28 01:40:01,051 - Task:Scrapy_bills - INFO - The work on page2794 has finished.
2017-08-28 01:43:39,445 - Task:Scrapy_bills - INFO - The work on page2795 has finished.
2017-08-28 01:47:16,525 - Task:Scrapy_bills - INFO - The work on page2796 has finished.
2017-08-28 01:50:56,295 - Task:Scrapy_bills - INFO - The work on page2797 has finished.
2017-08-28 01:54:39,463 - Task:Scrapy_bills - INFO - The work on page2798 has finished.
2017-08-28 01:58:20,142 - Task:Scrapy_bills - INFO - The work on page2799 has finished.
2017-08-28 01:58:20,963 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2791-2800.json
2017-08-28 02:02:04,613 - Task:Scrapy_bills - INFO - The work on page2800 has finished.
2017-08-28 02:05:43,470 - Task:Scrapy_bills - INFO - The work on page2801 has finished.
2017-08-28 02:09:21,944 - Task:Scrapy_bills - INFO - The work on page2802 has finished.
2017-08-28 02:13:04,501 - Task:Scrapy_bills - INFO - The work on page2803 has finished.
2017-08-28 02:16:55,215 - Task:Scrapy_bills - INFO - The work on page2804 has finished.
2017-08-28 02:20:37,853 - Task:Scrapy_bills - INFO - The work on page2805 has finished.
2017-08-28 02:23:53,912 - Task:Scrapy_bills - INFO - The work on page2806 has finished.
2017-08-28 02:24:36,736 - Task:Scrapy_bills - INFO - The work on page2807 has finished.
2017-08-28 02:25:13,997 - Task:Scrapy_bills - INFO - The work on page2808 has finished.
2017-08-28 02:25:47,573 - Task:Scrapy_bills - INFO - The work on page2809 has finished.
2017-08-28 02:25:48,315 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2801-2810.json
2017-08-28 02:26:19,396 - Task:Scrapy_bills - INFO - The work on page2810 has finished.
2017-08-28 02:26:44,651 - Task:Scrapy_bills - INFO - The work on page2811 has finished.
2017-08-28 02:27:00,014 - Task:Scrapy_bills - INFO - The work on page2812 has finished.
2017-08-28 02:27:04,809 - Task:Scrapy_bills - INFO - The work on page2813 has finished.
2017-08-28 02:27:09,474 - Task:Scrapy_bills - INFO - The work on page2814 has finished.
2017-08-28 02:27:14,190 - Task:Scrapy_bills - INFO - The work on page2815 has finished.
2017-08-28 02:27:18,859 - Task:Scrapy_bills - INFO - The work on page2816 has finished.
2017-08-28 02:29:52,770 - Task:Scrapy_bills - INFO - The work on page2817 has finished.
2017-08-28 02:33:44,392 - Task:Scrapy_bills - INFO - The work on page2818 has finished.
2017-08-28 02:37:37,274 - Task:Scrapy_bills - INFO - The work on page2819 has finished.
2017-08-28 02:37:37,883 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2811-2820.json
2017-08-28 02:41:29,026 - Task:Scrapy_bills - INFO - The work on page2820 has finished.
2017-08-28 02:45:21,743 - Task:Scrapy_bills - INFO - The work on page2821 has finished.
2017-08-28 02:49:17,324 - Task:Scrapy_bills - INFO - The work on page2822 has finished.
2017-08-28 02:52:56,593 - Task:Scrapy_bills - INFO - The work on page2823 has finished.
2017-08-28 02:56:33,388 - Task:Scrapy_bills - INFO - The work on page2824 has finished.
2017-08-28 03:00:12,283 - Task:Scrapy_bills - INFO - The work on page2825 has finished.
2017-08-28 03:04:01,137 - Task:Scrapy_bills - INFO - The work on page2826 has finished.
2017-08-28 03:07:36,081 - Task:Scrapy_bills - INFO - The work on page2827 has finished.
2017-08-28 03:11:07,810 - Task:Scrapy_bills - INFO - The work on page2828 has finished.
2017-08-28 03:14:32,270 - Task:Scrapy_bills - INFO - The work on page2829 has finished.
2017-08-28 03:14:33,048 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2821-2830.json
2017-08-28 03:18:02,750 - Task:Scrapy_bills - INFO - The work on page2830 has finished.
2017-08-28 03:21:22,032 - Task:Scrapy_bills - INFO - The work on page2831 has finished.
2017-08-28 03:24:44,473 - Task:Scrapy_bills - INFO - The work on page2832 has finished.
2017-08-28 03:28:04,739 - Task:Scrapy_bills - INFO - The work on page2833 has finished.
2017-08-28 03:31:36,087 - Task:Scrapy_bills - INFO - The work on page2834 has finished.
2017-08-28 03:35:16,368 - Task:Scrapy_bills - INFO - The work on page2835 has finished.
2017-08-28 03:38:59,833 - Task:Scrapy_bills - INFO - The work on page2836 has finished.
2017-08-28 03:42:35,624 - Task:Scrapy_bills - INFO - The work on page2837 has finished.
2017-08-28 03:46:10,584 - Task:Scrapy_bills - INFO - The work on page2838 has finished.
2017-08-28 03:49:41,364 - Task:Scrapy_bills - INFO - The work on page2839 has finished.
2017-08-28 03:49:42,159 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2831-2840.json
2017-08-28 03:53:24,796 - Task:Scrapy_bills - INFO - The work on page2840 has finished.
2017-08-28 03:57:09,862 - Task:Scrapy_bills - INFO - The work on page2841 has finished.
2017-08-28 04:00:46,247 - Task:Scrapy_bills - INFO - The work on page2842 has finished.
2017-08-28 04:04:27,700 - Task:Scrapy_bills - INFO - The work on page2843 has finished.
2017-08-28 04:08:05,998 - Task:Scrapy_bills - INFO - The work on page2844 has finished.
2017-08-28 04:11:43,876 - Task:Scrapy_bills - INFO - The work on page2845 has finished.
2017-08-28 04:15:21,980 - Task:Scrapy_bills - INFO - The work on page2846 has finished.
2017-08-28 04:18:59,316 - Task:Scrapy_bills - INFO - The work on page2847 has finished.
2017-08-28 04:22:37,480 - Task:Scrapy_bills - INFO - The work on page2848 has finished.
2017-08-28 04:26:14,965 - Task:Scrapy_bills - INFO - The work on page2849 has finished.
2017-08-28 04:26:15,791 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2841-2850.json
2017-08-28 04:29:53,425 - Task:Scrapy_bills - INFO - The work on page2850 has finished.
2017-08-28 04:33:36,887 - Task:Scrapy_bills - INFO - The work on page2851 has finished.
2017-08-28 04:37:13,695 - Task:Scrapy_bills - INFO - The work on page2852 has finished.
2017-08-28 04:40:49,557 - Task:Scrapy_bills - INFO - The work on page2853 has finished.
2017-08-28 04:44:23,986 - Task:Scrapy_bills - INFO - The work on page2854 has finished.
2017-08-28 04:48:02,306 - Task:Scrapy_bills - INFO - The work on page2855 has finished.
2017-08-28 04:51:38,528 - Task:Scrapy_bills - INFO - The work on page2856 has finished.
2017-08-28 04:55:12,064 - Task:Scrapy_bills - INFO - The work on page2857 has finished.
2017-08-28 04:58:48,652 - Task:Scrapy_bills - INFO - The work on page2858 has finished.
2017-08-28 05:02:23,808 - Task:Scrapy_bills - INFO - The work on page2859 has finished.
2017-08-28 05:02:24,631 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2851-2860.json
2017-08-28 05:06:03,525 - Task:Scrapy_bills - INFO - The work on page2860 has finished.
2017-08-28 05:09:45,055 - Task:Scrapy_bills - INFO - The work on page2861 has finished.
2017-08-28 05:13:23,402 - Task:Scrapy_bills - INFO - The work on page2862 has finished.
2017-08-28 05:17:02,043 - Task:Scrapy_bills - INFO - The work on page2863 has finished.
2017-08-28 05:20:44,524 - Task:Scrapy_bills - INFO - The work on page2864 has finished.
2017-08-28 05:22:38,707 - Task:Scrapy_bills - INFO - The work on page2865 has finished.
2017-08-28 05:23:46,192 - Task:Scrapy_bills - INFO - The work on page2866 has finished.
2017-08-28 05:24:44,190 - Task:Scrapy_bills - INFO - The work on page2867 has finished.
2017-08-28 05:25:45,318 - Task:Scrapy_bills - INFO - The work on page2868 has finished.
2017-08-28 05:25:50,174 - Task:Scrapy_bills - INFO - The work on page2869 has finished.
2017-08-28 05:25:50,890 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2861-2870.json
2017-08-28 05:27:40,246 - Task:Scrapy_bills - INFO - The work on page2870 has finished.
2017-08-28 05:31:19,805 - Task:Scrapy_bills - INFO - The work on page2871 has finished.
2017-08-28 05:35:08,155 - Task:Scrapy_bills - INFO - The work on page2872 has finished.
2017-08-28 05:38:54,557 - Task:Scrapy_bills - INFO - The work on page2873 has finished.
2017-08-28 05:42:43,382 - Task:Scrapy_bills - INFO - The work on page2874 has finished.
2017-08-28 05:46:23,057 - Task:Scrapy_bills - INFO - The work on page2875 has finished.
2017-08-28 05:49:59,950 - Task:Scrapy_bills - INFO - The work on page2876 has finished.
2017-08-28 05:53:37,422 - Task:Scrapy_bills - INFO - The work on page2877 has finished.
2017-08-28 05:57:07,965 - Task:Scrapy_bills - INFO - The work on page2878 has finished.
2017-08-28 06:00:33,723 - Task:Scrapy_bills - INFO - The work on page2879 has finished.
2017-08-28 06:00:34,492 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2871-2880.json
2017-08-28 06:03:56,779 - Task:Scrapy_bills - INFO - The work on page2880 has finished.
2017-08-28 06:07:13,003 - Task:Scrapy_bills - INFO - The work on page2881 has finished.
2017-08-28 06:10:28,303 - Task:Scrapy_bills - INFO - The work on page2882 has finished.
2017-08-28 06:13:43,370 - Task:Scrapy_bills - INFO - The work on page2883 has finished.
2017-08-28 06:16:57,694 - Task:Scrapy_bills - INFO - The work on page2884 has finished.
2017-08-28 06:20:13,081 - Task:Scrapy_bills - INFO - The work on page2885 has finished.
2017-08-28 06:23:28,045 - Task:Scrapy_bills - INFO - The work on page2886 has finished.
2017-08-28 06:26:44,201 - Task:Scrapy_bills - INFO - The work on page2887 has finished.
2017-08-28 06:30:01,379 - Task:Scrapy_bills - INFO - The work on page2888 has finished.
2017-08-28 06:33:17,907 - Task:Scrapy_bills - INFO - The work on page2889 has finished.
2017-08-28 06:33:18,659 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2881-2890.json
2017-08-28 06:36:38,294 - Task:Scrapy_bills - INFO - The work on page2890 has finished.
2017-08-28 06:39:55,756 - Task:Scrapy_bills - INFO - The work on page2891 has finished.
2017-08-28 06:43:12,173 - Task:Scrapy_bills - INFO - The work on page2892 has finished.
2017-08-28 06:46:25,483 - Task:Scrapy_bills - INFO - The work on page2893 has finished.
2017-08-28 06:49:41,832 - Task:Scrapy_bills - INFO - The work on page2894 has finished.
2017-08-28 06:52:59,780 - Task:Scrapy_bills - INFO - The work on page2895 has finished.
2017-08-28 06:56:14,737 - Task:Scrapy_bills - INFO - The work on page2896 has finished.
2017-08-28 06:59:28,186 - Task:Scrapy_bills - INFO - The work on page2897 has finished.
2017-08-28 07:02:44,176 - Task:Scrapy_bills - INFO - The work on page2898 has finished.
2017-08-28 07:05:59,610 - Task:Scrapy_bills - INFO - The work on page2899 has finished.
2017-08-28 07:06:00,363 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2891-2900.json
2017-08-28 07:09:18,760 - Task:Scrapy_bills - INFO - The work on page2900 has finished.
2017-08-28 07:12:32,954 - Task:Scrapy_bills - INFO - The work on page2901 has finished.
2017-08-28 07:15:51,495 - Task:Scrapy_bills - INFO - The work on page2902 has finished.
2017-08-28 07:19:08,710 - Task:Scrapy_bills - INFO - The work on page2903 has finished.
2017-08-28 07:22:24,163 - Task:Scrapy_bills - INFO - The work on page2904 has finished.
2017-08-28 07:25:41,083 - Task:Scrapy_bills - INFO - The work on page2905 has finished.
2017-08-28 07:28:56,414 - Task:Scrapy_bills - INFO - The work on page2906 has finished.
2017-08-28 07:32:11,347 - Task:Scrapy_bills - INFO - The work on page2907 has finished.
2017-08-28 07:35:26,088 - Task:Scrapy_bills - INFO - The work on page2908 has finished.
2017-08-28 07:38:45,523 - Task:Scrapy_bills - INFO - The work on page2909 has finished.
2017-08-28 07:38:46,289 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2901-2910.json
2017-08-28 07:42:20,663 - Task:Scrapy_bills - INFO - The work on page2910 has finished.
2017-08-28 07:45:35,952 - Task:Scrapy_bills - INFO - The work on page2911 has finished.
2017-08-28 07:48:49,675 - Task:Scrapy_bills - INFO - The work on page2912 has finished.
2017-08-28 07:52:03,569 - Task:Scrapy_bills - INFO - The work on page2913 has finished.
2017-08-28 07:55:19,616 - Task:Scrapy_bills - INFO - The work on page2914 has finished.
2017-08-28 07:58:36,612 - Task:Scrapy_bills - INFO - The work on page2915 has finished.
2017-08-28 08:01:51,462 - Task:Scrapy_bills - INFO - The work on page2916 has finished.
2017-08-28 08:05:06,615 - Task:Scrapy_bills - INFO - The work on page2917 has finished.
2017-08-28 08:08:23,200 - Task:Scrapy_bills - INFO - The work on page2918 has finished.
2017-08-28 08:11:38,084 - Task:Scrapy_bills - INFO - The work on page2919 has finished.
2017-08-28 08:11:38,834 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2911-2920.json
2017-08-28 08:14:58,485 - Task:Scrapy_bills - INFO - The work on page2920 has finished.
2017-08-28 08:18:12,764 - Task:Scrapy_bills - INFO - The work on page2921 has finished.
2017-08-28 08:21:25,543 - Task:Scrapy_bills - INFO - The work on page2922 has finished.
2017-08-28 08:24:40,450 - Task:Scrapy_bills - INFO - The work on page2923 has finished.
2017-08-28 08:27:54,828 - Task:Scrapy_bills - INFO - The work on page2924 has finished.
2017-08-28 08:31:07,055 - Task:Scrapy_bills - INFO - The work on page2925 has finished.
2017-08-28 08:34:16,004 - Task:Scrapy_bills - INFO - The work on page2926 has finished.
2017-08-28 08:37:24,504 - Task:Scrapy_bills - INFO - The work on page2927 has finished.
2017-08-28 08:40:32,458 - Task:Scrapy_bills - INFO - The work on page2928 has finished.
2017-08-28 08:43:41,482 - Task:Scrapy_bills - INFO - The work on page2929 has finished.
2017-08-28 08:43:42,234 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2921-2930.json
2017-08-28 08:46:53,269 - Task:Scrapy_bills - INFO - The work on page2930 has finished.
2017-08-28 08:50:03,721 - Task:Scrapy_bills - INFO - The work on page2931 has finished.
2017-08-28 08:53:17,183 - Task:Scrapy_bills - INFO - The work on page2932 has finished.
2017-08-28 08:56:25,964 - Task:Scrapy_bills - INFO - The work on page2933 has finished.
2017-08-28 08:59:34,393 - Task:Scrapy_bills - INFO - The work on page2934 has finished.
2017-08-28 09:02:48,979 - Task:Scrapy_bills - INFO - The work on page2935 has finished.
2017-08-28 09:06:06,441 - Task:Scrapy_bills - INFO - The work on page2936 has finished.
2017-08-28 09:09:17,711 - Task:Scrapy_bills - INFO - The work on page2937 has finished.
2017-08-28 09:12:29,931 - Task:Scrapy_bills - INFO - The work on page2938 has finished.
2017-08-28 09:15:42,375 - Task:Scrapy_bills - INFO - The work on page2939 has finished.
2017-08-28 09:15:43,124 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2931-2940.json
2017-08-28 09:18:56,397 - Task:Scrapy_bills - INFO - The work on page2940 has finished.
2017-08-28 09:22:07,318 - Task:Scrapy_bills - INFO - The work on page2941 has finished.
2017-08-28 09:25:17,361 - Task:Scrapy_bills - INFO - The work on page2942 has finished.
2017-08-28 09:28:28,334 - Task:Scrapy_bills - INFO - The work on page2943 has finished.
2017-08-28 09:31:40,033 - Task:Scrapy_bills - INFO - The work on page2944 has finished.
2017-08-28 09:34:50,923 - Task:Scrapy_bills - INFO - The work on page2945 has finished.
2017-08-28 09:38:04,426 - Task:Scrapy_bills - INFO - The work on page2946 has finished.
2017-08-28 09:41:18,077 - Task:Scrapy_bills - INFO - The work on page2947 has finished.
2017-08-28 09:44:43,317 - Task:Scrapy_bills - INFO - The work on page2948 has finished.
2017-08-28 09:48:10,667 - Task:Scrapy_bills - INFO - The work on page2949 has finished.
2017-08-28 09:48:11,433 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2941-2950.json
2017-08-28 09:51:48,133 - Task:Scrapy_bills - INFO - The work on page2950 has finished.
2017-08-28 09:55:19,995 - Task:Scrapy_bills - INFO - The work on page2951 has finished.
2017-08-28 09:58:47,917 - Task:Scrapy_bills - INFO - The work on page2952 has finished.
2017-08-28 10:02:21,405 - Task:Scrapy_bills - INFO - The work on page2953 has finished.
2017-08-28 10:06:00,005 - Task:Scrapy_bills - INFO - The work on page2954 has finished.
2017-08-28 10:09:36,689 - Task:Scrapy_bills - INFO - The work on page2955 has finished.
2017-08-28 10:13:11,207 - Task:Scrapy_bills - INFO - The work on page2956 has finished.
2017-08-28 10:16:45,717 - Task:Scrapy_bills - INFO - The work on page2957 has finished.
2017-08-28 10:20:25,277 - Task:Scrapy_bills - INFO - The work on page2958 has finished.
2017-08-28 10:23:58,708 - Task:Scrapy_bills - INFO - The work on page2959 has finished.
2017-08-28 10:23:59,538 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2951-2960.json
2017-08-28 10:27:39,054 - Task:Scrapy_bills - INFO - The work on page2960 has finished.
2017-08-28 10:31:12,740 - Task:Scrapy_bills - INFO - The work on page2961 has finished.
2017-08-28 10:34:39,626 - Task:Scrapy_bills - INFO - The work on page2962 has finished.
2017-08-28 10:38:22,888 - Task:Scrapy_bills - INFO - The work on page2963 has finished.
2017-08-28 10:41:56,957 - Task:Scrapy_bills - INFO - The work on page2964 has finished.
2017-08-28 10:45:34,635 - Task:Scrapy_bills - INFO - The work on page2965 has finished.
2017-08-28 10:49:10,545 - Task:Scrapy_bills - INFO - The work on page2966 has finished.
2017-08-28 10:52:42,354 - Task:Scrapy_bills - INFO - The work on page2967 has finished.
2017-08-28 10:56:17,480 - Task:Scrapy_bills - INFO - The work on page2968 has finished.
2017-08-28 10:59:52,905 - Task:Scrapy_bills - INFO - The work on page2969 has finished.
2017-08-28 10:59:53,731 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2961-2970.json
2017-08-28 11:03:35,299 - Task:Scrapy_bills - INFO - The work on page2970 has finished.
2017-08-28 11:07:12,608 - Task:Scrapy_bills - INFO - The work on page2971 has finished.
2017-08-28 11:10:48,728 - Task:Scrapy_bills - INFO - The work on page2972 has finished.
2017-08-28 11:14:29,358 - Task:Scrapy_bills - INFO - The work on page2973 has finished.
2017-08-28 11:18:05,631 - Task:Scrapy_bills - INFO - The work on page2974 has finished.
2017-08-28 11:21:43,161 - Task:Scrapy_bills - INFO - The work on page2975 has finished.
2017-08-28 11:25:24,145 - Task:Scrapy_bills - INFO - The work on page2976 has finished.
2017-08-28 11:29:02,714 - Task:Scrapy_bills - INFO - The work on page2977 has finished.
2017-08-28 11:32:37,303 - Task:Scrapy_bills - INFO - The work on page2978 has finished.
2017-08-28 11:36:14,806 - Task:Scrapy_bills - INFO - The work on page2979 has finished.
2017-08-28 11:36:15,633 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2971-2980.json
2017-08-28 11:40:04,135 - Task:Scrapy_bills - INFO - The work on page2980 has finished.
2017-08-28 11:43:44,432 - Task:Scrapy_bills - INFO - The work on page2981 has finished.
2017-08-28 11:47:20,103 - Task:Scrapy_bills - INFO - The work on page2982 has finished.
2017-08-28 11:51:03,449 - Task:Scrapy_bills - INFO - The work on page2983 has finished.
2017-08-28 11:54:48,734 - Task:Scrapy_bills - INFO - The work on page2984 has finished.
2017-08-28 11:58:26,701 - Task:Scrapy_bills - INFO - The work on page2985 has finished.
2017-08-28 12:02:11,718 - Task:Scrapy_bills - INFO - The work on page2986 has finished.
2017-08-28 12:05:59,613 - Task:Scrapy_bills - INFO - The work on page2987 has finished.
2017-08-28 12:09:38,896 - Task:Scrapy_bills - INFO - The work on page2988 has finished.
2017-08-28 12:13:20,354 - Task:Scrapy_bills - INFO - The work on page2989 has finished.
2017-08-28 12:13:21,196 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2981-2990.json
2017-08-28 12:17:04,573 - Task:Scrapy_bills - INFO - The work on page2990 has finished.
2017-08-28 12:20:49,915 - Task:Scrapy_bills - INFO - The work on page2991 has finished.
2017-08-28 12:24:40,683 - Task:Scrapy_bills - INFO - The work on page2992 has finished.
2017-08-28 12:28:23,657 - Task:Scrapy_bills - INFO - The work on page2993 has finished.
2017-08-28 12:32:03,312 - Task:Scrapy_bills - INFO - The work on page2994 has finished.
2017-08-28 12:35:55,283 - Task:Scrapy_bills - INFO - The work on page2995 has finished.
2017-08-28 12:39:45,319 - Task:Scrapy_bills - INFO - The work on page2996 has finished.
2017-08-28 12:43:32,747 - Task:Scrapy_bills - INFO - The work on page2997 has finished.
2017-08-28 12:47:14,476 - Task:Scrapy_bills - INFO - The work on page2998 has finished.
2017-08-28 12:50:54,318 - Task:Scrapy_bills - INFO - The work on page2999 has finished.
2017-08-28 12:50:55,140 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation2991-3000.json
2017-08-28 12:54:42,102 - Task:Scrapy_bills - INFO - The work on page3000 has finished.
2017-08-28 12:58:25,549 - Task:Scrapy_bills - INFO - The work on page3001 has finished.
2017-08-28 13:02:11,977 - Task:Scrapy_bills - INFO - The work on page3002 has finished.
2017-08-28 13:06:02,502 - Task:Scrapy_bills - INFO - The work on page3003 has finished.
2017-08-28 13:09:48,795 - Task:Scrapy_bills - INFO - The work on page3004 has finished.
2017-08-28 13:13:32,876 - Task:Scrapy_bills - INFO - The work on page3005 has finished.
2017-08-28 13:17:10,197 - Task:Scrapy_bills - INFO - The work on page3006 has finished.
2017-08-28 13:20:46,325 - Task:Scrapy_bills - INFO - The work on page3007 has finished.
2017-08-28 13:24:36,356 - Task:Scrapy_bills - INFO - The work on page3008 has finished.
2017-08-28 13:28:17,085 - Task:Scrapy_bills - INFO - The work on page3009 has finished.
2017-08-28 13:28:17,905 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3001-3010.json
2017-08-28 13:32:05,614 - Task:Scrapy_bills - INFO - The work on page3010 has finished.
2017-08-28 13:35:43,140 - Task:Scrapy_bills - INFO - The work on page3011 has finished.
2017-08-28 13:39:28,006 - Task:Scrapy_bills - INFO - The work on page3012 has finished.
2017-08-28 13:43:09,267 - Task:Scrapy_bills - INFO - The work on page3013 has finished.
2017-08-28 13:46:49,876 - Task:Scrapy_bills - INFO - The work on page3014 has finished.
2017-08-28 13:50:32,346 - Task:Scrapy_bills - INFO - The work on page3015 has finished.
2017-08-28 13:54:14,838 - Task:Scrapy_bills - INFO - The work on page3016 has finished.
2017-08-28 13:54:32,877 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 13:54:32,879 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 73, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 520: Origin Error

2017-08-28 13:54:48,773 - Task:Scrapy_bills - INFO - The work on page3018 has finished.
2017-08-28 13:58:27,230 - Task:Scrapy_bills - INFO - The work on page3019 has finished.
2017-08-28 13:58:28,004 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3011-3020.json
2017-08-28 14:02:28,158 - Task:Scrapy_bills - INFO - The work on page3020 has finished.
2017-08-28 14:05:56,678 - Task:Scrapy_bills - INFO - The work on page3021 has finished.
2017-08-28 14:08:33,909 - Task:Scrapy_bills - INFO - The work on page3022 has finished.
2017-08-28 14:08:59,471 - Task:Scrapy_bills - INFO - The work on page3023 has finished.
2017-08-28 14:09:26,521 - Task:Scrapy_bills - INFO - The work on page3024 has finished.
2017-08-28 14:09:54,632 - Task:Scrapy_bills - INFO - The work on page3025 has finished.
2017-08-28 14:10:19,441 - Task:Scrapy_bills - INFO - The work on page3026 has finished.
2017-08-28 14:10:31,466 - Task:Scrapy_bills - INFO - The work on page3027 has finished.
2017-08-28 14:10:37,937 - Task:Scrapy_bills - INFO - The work on page3028 has finished.
2017-08-28 14:10:43,086 - Task:Scrapy_bills - INFO - The work on page3029 has finished.
2017-08-28 14:10:43,773 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3021-3030.json
2017-08-28 14:10:49,399 - Task:Scrapy_bills - INFO - The work on page3030 has finished.
2017-08-28 14:10:54,385 - Task:Scrapy_bills - INFO - The work on page3031 has finished.
2017-08-28 14:11:28,903 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 14:11:28,905 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-564922dd56a7>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-28 14:11:43,108 - Task:Scrapy_bills - INFO - The work on page3032 has finished.
2017-08-28 14:13:47,117 - Task:Scrapy_bills - INFO - The work on page3033 has finished.
2017-08-28 14:17:27,363 - Task:Scrapy_bills - INFO - The work on page3034 has finished.
2017-08-28 14:21:05,396 - Task:Scrapy_bills - INFO - The work on page3035 has finished.
2017-08-28 14:24:43,904 - Task:Scrapy_bills - INFO - The work on page3036 has finished.
2017-08-28 14:28:19,035 - Task:Scrapy_bills - INFO - The work on page3037 has finished.
2017-08-28 14:31:59,065 - Task:Scrapy_bills - INFO - The work on page3038 has finished.
2017-08-28 14:35:36,165 - Task:Scrapy_bills - INFO - The work on page3039 has finished.
2017-08-28 14:35:36,878 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3031-3040.json
2017-08-28 14:38:56,265 - Task:Scrapy_bills - INFO - The work on page3040 has finished.
2017-08-28 14:42:06,736 - Task:Scrapy_bills - INFO - The work on page3041 has finished.
2017-08-28 14:45:27,695 - Task:Scrapy_bills - INFO - The work on page3042 has finished.
2017-08-28 14:48:35,916 - Task:Scrapy_bills - INFO - The work on page3043 has finished.
2017-08-28 14:51:47,567 - Task:Scrapy_bills - INFO - The work on page3044 has finished.
2017-08-28 14:54:59,444 - Task:Scrapy_bills - INFO - The work on page3045 has finished.
2017-08-28 14:58:09,155 - Task:Scrapy_bills - INFO - The work on page3046 has finished.
2017-08-28 15:01:21,405 - Task:Scrapy_bills - INFO - The work on page3047 has finished.
2017-08-28 15:04:33,466 - Task:Scrapy_bills - INFO - The work on page3048 has finished.
2017-08-28 15:07:46,346 - Task:Scrapy_bills - INFO - The work on page3049 has finished.
2017-08-28 15:07:47,106 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3041-3050.json
2017-08-28 15:11:27,290 - Task:Scrapy_bills - INFO - The work on page3050 has finished.
2017-08-28 15:15:02,056 - Task:Scrapy_bills - INFO - The work on page3051 has finished.
2017-08-28 15:18:44,824 - Task:Scrapy_bills - INFO - The work on page3052 has finished.
2017-08-28 15:22:24,651 - Task:Scrapy_bills - INFO - The work on page3053 has finished.
2017-08-28 15:26:07,746 - Task:Scrapy_bills - INFO - The work on page3054 has finished.
2017-08-28 15:29:55,473 - Task:Scrapy_bills - INFO - The work on page3055 has finished.
2017-08-28 15:33:33,605 - Task:Scrapy_bills - INFO - The work on page3056 has finished.
2017-08-28 15:37:13,967 - Task:Scrapy_bills - INFO - The work on page3057 has finished.
2017-08-28 15:40:52,998 - Task:Scrapy_bills - INFO - The work on page3058 has finished.
2017-08-28 15:44:31,370 - Task:Scrapy_bills - INFO - The work on page3059 has finished.
2017-08-28 15:44:32,207 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3051-3060.json
2017-08-28 15:48:14,057 - Task:Scrapy_bills - INFO - The work on page3060 has finished.
2017-08-28 15:51:53,005 - Task:Scrapy_bills - INFO - The work on page3061 has finished.
2017-08-28 15:55:28,934 - Task:Scrapy_bills - INFO - The work on page3062 has finished.
2017-08-28 15:59:08,719 - Task:Scrapy_bills - INFO - The work on page3063 has finished.
2017-08-28 16:02:44,510 - Task:Scrapy_bills - INFO - The work on page3064 has finished.
2017-08-28 16:06:26,505 - Task:Scrapy_bills - INFO - The work on page3065 has finished.
2017-08-28 16:10:06,918 - Task:Scrapy_bills - INFO - The work on page3066 has finished.
2017-08-28 16:13:48,271 - Task:Scrapy_bills - INFO - The work on page3067 has finished.
2017-08-28 16:17:35,155 - Task:Scrapy_bills - INFO - The work on page3068 has finished.
2017-08-28 16:21:12,687 - Task:Scrapy_bills - INFO - The work on page3069 has finished.
2017-08-28 16:21:13,507 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3061-3070.json
2017-08-28 16:24:54,528 - Task:Scrapy_bills - INFO - The work on page3070 has finished.
2017-08-28 16:28:31,826 - Task:Scrapy_bills - INFO - The work on page3071 has finished.
2017-08-28 16:32:09,749 - Task:Scrapy_bills - INFO - The work on page3072 has finished.
2017-08-28 16:35:57,470 - Task:Scrapy_bills - INFO - The work on page3073 has finished.
2017-08-28 16:39:39,864 - Task:Scrapy_bills - INFO - The work on page3074 has finished.
2017-08-28 16:43:16,934 - Task:Scrapy_bills - INFO - The work on page3075 has finished.
2017-08-28 16:46:57,983 - Task:Scrapy_bills - INFO - The work on page3076 has finished.
2017-08-28 16:50:44,505 - Task:Scrapy_bills - INFO - The work on page3077 has finished.
2017-08-28 16:54:25,367 - Task:Scrapy_bills - INFO - The work on page3078 has finished.
2017-08-28 16:58:03,279 - Task:Scrapy_bills - INFO - The work on page3079 has finished.
2017-08-28 16:58:04,087 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3071-3080.json
2017-08-28 17:01:44,149 - Task:Scrapy_bills - INFO - The work on page3080 has finished.
2017-08-28 17:02:56,734 - Task:Scrapy_bills - INFO - The work on page3081 has finished.
2017-08-28 17:03:55,700 - Task:Scrapy_bills - INFO - The work on page3082 has finished.
2017-08-28 17:04:29,489 - Task:Scrapy_bills - INFO - The work on page3083 has finished.
2017-08-28 17:04:34,440 - Task:Scrapy_bills - INFO - The work on page3084 has finished.
2017-08-28 17:07:22,731 - Task:Scrapy_bills - INFO - The work on page3085 has finished.
2017-08-28 17:11:05,793 - Task:Scrapy_bills - INFO - The work on page3086 has finished.
2017-08-28 17:14:44,184 - Task:Scrapy_bills - INFO - The work on page3087 has finished.
2017-08-28 17:18:19,749 - Task:Scrapy_bills - INFO - The work on page3088 has finished.
2017-08-28 17:21:57,836 - Task:Scrapy_bills - INFO - The work on page3089 has finished.
2017-08-28 17:21:58,549 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3081-3090.json
2017-08-28 17:25:33,582 - Task:Scrapy_bills - INFO - The work on page3090 has finished.
2017-08-28 17:28:42,747 - Task:Scrapy_bills - INFO - The work on page3091 has finished.
2017-08-28 17:31:52,833 - Task:Scrapy_bills - INFO - The work on page3092 has finished.
2017-08-28 17:35:02,292 - Task:Scrapy_bills - INFO - The work on page3093 has finished.
2017-08-28 17:38:12,762 - Task:Scrapy_bills - INFO - The work on page3094 has finished.
2017-08-28 17:41:22,337 - Task:Scrapy_bills - INFO - The work on page3095 has finished.
2017-08-28 17:44:32,952 - Task:Scrapy_bills - INFO - The work on page3096 has finished.
2017-08-28 17:47:43,723 - Task:Scrapy_bills - INFO - The work on page3097 has finished.
2017-08-28 17:50:57,077 - Task:Scrapy_bills - INFO - The work on page3098 has finished.
2017-08-28 17:54:06,465 - Task:Scrapy_bills - INFO - The work on page3099 has finished.
2017-08-28 17:54:07,224 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3091-3100.json
2017-08-28 17:57:20,269 - Task:Scrapy_bills - INFO - The work on page3100 has finished.
2017-08-28 18:00:28,728 - Task:Scrapy_bills - INFO - The work on page3101 has finished.
2017-08-28 18:03:39,304 - Task:Scrapy_bills - INFO - The work on page3102 has finished.
2017-08-28 18:06:51,797 - Task:Scrapy_bills - INFO - The work on page3103 has finished.
2017-08-28 18:10:00,712 - Task:Scrapy_bills - INFO - The work on page3104 has finished.
2017-08-28 18:13:11,001 - Task:Scrapy_bills - INFO - The work on page3105 has finished.
2017-08-28 18:16:20,389 - Task:Scrapy_bills - INFO - The work on page3106 has finished.
2017-08-28 18:19:31,482 - Task:Scrapy_bills - INFO - The work on page3107 has finished.
2017-08-28 18:22:41,633 - Task:Scrapy_bills - INFO - The work on page3108 has finished.
2017-08-28 18:25:51,631 - Task:Scrapy_bills - INFO - The work on page3109 has finished.
2017-08-28 18:25:52,382 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3101-3110.json
2017-08-28 18:29:06,743 - Task:Scrapy_bills - INFO - The work on page3110 has finished.
2017-08-28 18:32:15,735 - Task:Scrapy_bills - INFO - The work on page3111 has finished.
2017-08-28 18:35:24,977 - Task:Scrapy_bills - INFO - The work on page3112 has finished.
2017-08-28 18:38:34,018 - Task:Scrapy_bills - INFO - The work on page3113 has finished.
2017-08-28 18:41:44,755 - Task:Scrapy_bills - INFO - The work on page3114 has finished.
2017-08-28 18:44:55,942 - Task:Scrapy_bills - INFO - The work on page3115 has finished.
2017-08-28 18:48:05,227 - Task:Scrapy_bills - INFO - The work on page3116 has finished.
2017-08-28 18:51:14,126 - Task:Scrapy_bills - INFO - The work on page3117 has finished.
2017-08-28 18:54:25,038 - Task:Scrapy_bills - INFO - The work on page3118 has finished.
2017-08-28 18:57:37,550 - Task:Scrapy_bills - INFO - The work on page3119 has finished.
2017-08-28 18:57:38,297 - Task:Scrapy_bills - INFO - Successfully save the file in ./dataBase/legislation3111-3120.json
2017-08-28 19:57:03,080 - Task:Scrapy_bills - INFO - The number of the search result is:403658
2017-08-28 20:01:19,657 - Task:Scrapy_bills - INFO - The number of the search result is:43404
2017-08-28 20:05:06,597 - Task:Scrapy_bills - INFO - The number of the search result is:403658
2017-08-28 20:05:21,000 - Task:Scrapy_bills - INFO - The work on page0 has finished.
2017-08-28 20:09:16,005 - Task:Scrapy_bills - INFO - The work on page0 has finished.
2017-08-28 20:09:55,066 - Task:Scrapy_bills - INFO - The work on page1 has finished.
2017-08-28 20:13:26,543 - Task:Scrapy_bills - INFO - The work on page1 has finished.
2017-08-28 20:14:01,745 - Task:Scrapy_bills - INFO - The work on page2 has finished.
2017-08-28 20:17:42,972 - Task:Scrapy_bills - INFO - The work on page2 has finished.
2017-08-28 20:18:19,364 - Task:Scrapy_bills - INFO - The work on page3 has finished.
2017-08-28 20:21:48,546 - Task:Scrapy_bills - INFO - The work on page3 has finished.
2017-08-28 20:22:17,662 - Task:Scrapy_bills - INFO - The work on page4 has finished.
2017-08-28 20:26:00,725 - Task:Scrapy_bills - INFO - The work on page4 has finished.
2017-08-28 20:26:28,990 - Task:Scrapy_bills - INFO - The work on page5 has finished.
2017-08-28 20:30:22,398 - Task:Scrapy_bills - INFO - The work on page5 has finished.
2017-08-28 20:30:47,489 - Task:Scrapy_bills - INFO - The work on page6 has finished.
2017-08-28 20:34:17,032 - Task:Scrapy_bills - INFO - The work on page6 has finished.
2017-08-28 20:35:10,465 - Task:Scrapy_bills - INFO - The work on page7 has finished.
2017-08-28 20:38:13,756 - Task:Scrapy_bills - INFO - The work on page7 has finished.
2017-08-28 20:39:33,652 - Task:Scrapy_bills - INFO - The work on page8 has finished.
2017-08-28 20:42:09,568 - Task:Scrapy_bills - INFO - The work on page8 has finished.
2017-08-28 20:44:03,458 - Task:Scrapy_bills - INFO - The work on page9 has finished.
2017-08-28 20:44:04,544 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation1-10.json
2017-08-28 20:46:05,753 - Task:Scrapy_bills - INFO - The work on page9 has finished.
2017-08-28 20:46:06,697 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation1-10.json
2017-08-28 20:48:40,843 - Task:Scrapy_bills - INFO - The work on page10 has finished.
2017-08-28 20:50:07,189 - Task:Scrapy_bills - INFO - The work on page10 has finished.
2017-08-28 20:53:09,126 - Task:Scrapy_bills - INFO - The work on page11 has finished.
2017-08-28 20:54:04,999 - Task:Scrapy_bills - INFO - The work on page11 has finished.
2017-08-28 20:57:34,682 - Task:Scrapy_bills - INFO - The work on page12 has finished.
2017-08-28 20:58:18,536 - Task:Scrapy_bills - INFO - The work on page12 has finished.
2017-08-28 21:01:13,317 - Task:Scrapy_bills - INFO - The work on page13 has finished.
2017-08-28 21:02:35,369 - Task:Scrapy_bills - INFO - The work on page13 has finished.
2017-08-28 21:03:45,722 - Task:Scrapy_bills - INFO - The work on page14 has finished.
2017-08-28 21:06:57,269 - Task:Scrapy_bills - INFO - The work on page14 has finished.
2017-08-28 21:07:45,923 - Task:Scrapy_bills - INFO - The work on page15 has finished.
2017-08-28 21:09:36,525 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 21:09:36,543 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-28 21:09:52,259 - Task:Scrapy_bills - INFO - The work on page17 has finished.
2017-08-28 21:11:27,747 - Task:Scrapy_bills - INFO - The work on page15 has finished.
2017-08-28 21:12:57,367 - Task:Scrapy_bills - INFO - The work on page18 has finished.
2017-08-28 21:15:45,922 - Task:Scrapy_bills - INFO - The work on page16 has finished.
2017-08-28 21:16:44,303 - Task:Scrapy_bills - INFO - The work on page19 has finished.
2017-08-28 21:16:45,251 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation11-20.json
2017-08-28 21:20:06,434 - Task:Scrapy_bills - INFO - The work on page17 has finished.
2017-08-28 21:20:36,438 - Task:Scrapy_bills - INFO - The work on page20 has finished.
2017-08-28 21:24:29,840 - Task:Scrapy_bills - INFO - The work on page18 has finished.
2017-08-28 21:24:30,444 - Task:Scrapy_bills - INFO - The work on page21 has finished.
2017-08-28 21:28:17,660 - Task:Scrapy_bills - INFO - The work on page22 has finished.
2017-08-28 21:28:42,138 - Task:Scrapy_bills - INFO - The work on page19 has finished.
2017-08-28 21:28:43,072 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation11-20.json
2017-08-28 21:32:25,737 - Task:Scrapy_bills - INFO - The work on page23 has finished.
2017-08-28 21:33:05,101 - Task:Scrapy_bills - INFO - The work on page20 has finished.
2017-08-28 21:36:55,106 - Task:Scrapy_bills - INFO - The work on page24 has finished.
2017-08-28 21:37:19,215 - Task:Scrapy_bills - INFO - The work on page21 has finished.
2017-08-28 21:41:26,697 - Task:Scrapy_bills - INFO - The work on page22 has finished.
2017-08-28 21:41:30,506 - Task:Scrapy_bills - INFO - The work on page25 has finished.
2017-08-28 21:45:40,413 - Task:Scrapy_bills - INFO - The work on page23 has finished.
2017-08-28 21:46:00,642 - Task:Scrapy_bills - INFO - The work on page26 has finished.
2017-08-28 21:49:52,997 - Task:Scrapy_bills - INFO - The work on page24 has finished.
2017-08-28 21:50:33,778 - Task:Scrapy_bills - INFO - The work on page27 has finished.
2017-08-28 21:54:15,324 - Task:Scrapy_bills - INFO - The work on page25 has finished.
2017-08-28 21:55:12,987 - Task:Scrapy_bills - INFO - The work on page28 has finished.
2017-08-28 21:57:05,165 - Task:Scrapy_bills - INFO - The work on page29 has finished.
2017-08-28 21:57:06,272 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation21-30.json
2017-08-28 21:58:32,519 - Task:Scrapy_bills - INFO - The work on page26 has finished.
2017-08-28 22:01:00,969 - Task:Scrapy_bills - INFO - The work on page30 has finished.
2017-08-28 22:02:51,050 - Task:Scrapy_bills - INFO - The work on page27 has finished.
2017-08-28 22:05:00,230 - Task:Scrapy_bills - INFO - The work on page31 has finished.
2017-08-28 22:07:19,720 - Task:Scrapy_bills - INFO - The work on page28 has finished.
2017-08-28 22:09:32,644 - Task:Scrapy_bills - INFO - The work on page32 has finished.
2017-08-28 22:11:35,732 - Task:Scrapy_bills - INFO - The work on page29 has finished.
2017-08-28 22:11:36,709 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation21-30.json
2017-08-28 22:12:28,611 - Task:Scrapy_bills - INFO - The work on page33 has finished.
2017-08-28 22:15:48,795 - Task:Scrapy_bills - INFO - The work on page30 has finished.
2017-08-28 22:16:19,104 - Task:Scrapy_bills - INFO - The work on page34 has finished.
2017-08-28 22:19:44,244 - Task:Scrapy_bills - INFO - The work on page31 has finished.
2017-08-28 22:20:07,835 - Task:Scrapy_bills - INFO - The work on page35 has finished.
2017-08-28 22:23:35,503 - Task:Scrapy_bills - INFO - The work on page32 has finished.
2017-08-28 22:23:58,347 - Task:Scrapy_bills - INFO - The work on page36 has finished.
2017-08-28 22:27:27,201 - Task:Scrapy_bills - INFO - The work on page33 has finished.
2017-08-28 22:27:59,054 - Task:Scrapy_bills - INFO - The work on page37 has finished.
2017-08-28 22:28:01,345 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 22:28:01,352 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-28 22:30:43,001 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 22:30:43,004 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-28 22:30:59,589 - Task:Scrapy_bills - INFO - The work on page39 has finished.
2017-08-28 22:31:00,493 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation31-40.json
2017-08-28 22:32:03,090 - Task:Scrapy_bills - INFO - The work on page34 has finished.
2017-08-28 22:35:39,860 - Task:Scrapy_bills - INFO - The work on page40 has finished.
2017-08-28 22:35:51,834 - Task:Scrapy_bills - INFO - The work on page35 has finished.
2017-08-28 22:37:49,203 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-28 22:37:49,204 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-28 22:38:05,337 - Task:Scrapy_bills - INFO - The work on page37 has finished.
2017-08-28 22:39:37,956 - Task:Scrapy_bills - INFO - The work on page38 has finished.
2017-08-28 22:40:13,903 - Task:Scrapy_bills - INFO - The work on page41 has finished.
2017-08-28 22:42:43,892 - Task:Scrapy_bills - INFO - The work on page42 has finished.
2017-08-28 22:43:16,753 - Task:Scrapy_bills - INFO - The work on page39 has finished.
2017-08-28 22:43:17,623 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation31-40.json
2017-08-28 22:46:35,938 - Task:Scrapy_bills - INFO - The work on page43 has finished.
2017-08-28 22:47:29,643 - Task:Scrapy_bills - INFO - The work on page40 has finished.
2017-08-28 22:50:29,969 - Task:Scrapy_bills - INFO - The work on page44 has finished.
2017-08-28 22:51:28,504 - Task:Scrapy_bills - INFO - The work on page41 has finished.
2017-08-28 22:54:44,072 - Task:Scrapy_bills - INFO - The work on page45 has finished.
2017-08-28 22:55:07,189 - Task:Scrapy_bills - INFO - The work on page42 has finished.
2017-08-28 22:57:33,423 - Task:Scrapy_bills - INFO - The work on page46 has finished.
2017-08-28 22:58:19,490 - Task:Scrapy_bills - INFO - The work on page43 has finished.
2017-08-28 23:01:22,786 - Task:Scrapy_bills - INFO - The work on page44 has finished.
2017-08-28 23:01:24,035 - Task:Scrapy_bills - INFO - The work on page47 has finished.
2017-08-28 23:04:47,035 - Task:Scrapy_bills - INFO - The work on page45 has finished.
2017-08-28 23:05:14,122 - Task:Scrapy_bills - INFO - The work on page48 has finished.
2017-08-28 23:08:28,684 - Task:Scrapy_bills - INFO - The work on page46 has finished.
2017-08-28 23:09:02,429 - Task:Scrapy_bills - INFO - The work on page49 has finished.
2017-08-28 23:09:03,441 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation41-50.json
2017-08-28 23:12:21,827 - Task:Scrapy_bills - INFO - The work on page47 has finished.
2017-08-28 23:12:52,431 - Task:Scrapy_bills - INFO - The work on page50 has finished.
2017-08-28 23:16:12,986 - Task:Scrapy_bills - INFO - The work on page48 has finished.
2017-08-28 23:16:56,785 - Task:Scrapy_bills - INFO - The work on page51 has finished.
2017-08-28 23:20:02,062 - Task:Scrapy_bills - INFO - The work on page49 has finished.
2017-08-28 23:20:02,996 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation41-50.json
2017-08-28 23:21:20,025 - Task:Scrapy_bills - INFO - The work on page52 has finished.
2017-08-28 23:23:53,240 - Task:Scrapy_bills - INFO - The work on page50 has finished.
2017-08-28 23:25:46,136 - Task:Scrapy_bills - INFO - The work on page53 has finished.
2017-08-28 23:27:36,160 - Task:Scrapy_bills - INFO - The work on page51 has finished.
2017-08-28 23:30:15,600 - Task:Scrapy_bills - INFO - The work on page54 has finished.
2017-08-28 23:31:45,381 - Task:Scrapy_bills - INFO - The work on page52 has finished.
2017-08-28 23:34:55,583 - Task:Scrapy_bills - INFO - The work on page55 has finished.
2017-08-28 23:36:05,148 - Task:Scrapy_bills - INFO - The work on page53 has finished.
2017-08-28 23:39:22,452 - Task:Scrapy_bills - INFO - The work on page56 has finished.
2017-08-28 23:40:23,312 - Task:Scrapy_bills - INFO - The work on page54 has finished.
2017-08-28 23:43:50,639 - Task:Scrapy_bills - INFO - The work on page57 has finished.
2017-08-28 23:44:36,447 - Task:Scrapy_bills - INFO - The work on page55 has finished.
2017-08-28 23:47:34,817 - Task:Scrapy_bills - INFO - The work on page58 has finished.
2017-08-28 23:47:38,991 - Task:Scrapy_bills - INFO - The work on page59 has finished.
2017-08-28 23:47:40,050 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation51-60.json
2017-08-28 23:48:58,533 - Task:Scrapy_bills - INFO - The work on page56 has finished.
2017-08-28 23:51:33,404 - Task:Scrapy_bills - INFO - The work on page60 has finished.
2017-08-28 23:53:19,391 - Task:Scrapy_bills - INFO - The work on page57 has finished.
2017-08-28 23:55:48,421 - Task:Scrapy_bills - INFO - The work on page61 has finished.
2017-08-28 23:57:33,904 - Task:Scrapy_bills - INFO - The work on page58 has finished.
2017-08-28 23:59:51,591 - Task:Scrapy_bills - INFO - The work on page62 has finished.
2017-08-29 00:01:38,939 - Task:Scrapy_bills - INFO - The work on page59 has finished.
2017-08-29 00:01:39,832 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation51-60.json
2017-08-29 00:03:57,447 - Task:Scrapy_bills - INFO - The work on page63 has finished.
2017-08-29 00:05:44,129 - Task:Scrapy_bills - INFO - The work on page60 has finished.
2017-08-29 00:08:05,500 - Task:Scrapy_bills - INFO - The work on page64 has finished.
2017-08-29 00:09:32,611 - Task:Scrapy_bills - INFO - The work on page61 has finished.
2017-08-29 00:12:12,131 - Task:Scrapy_bills - INFO - The work on page65 has finished.
2017-08-29 00:13:20,530 - Task:Scrapy_bills - INFO - The work on page62 has finished.
2017-08-29 00:16:20,091 - Task:Scrapy_bills - INFO - The work on page66 has finished.
2017-08-29 00:16:27,707 - Task:Scrapy_bills - INFO - The work on page63 has finished.
2017-08-29 00:17:19,536 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 00:17:19,538 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 00:17:39,837 - Task:Scrapy_bills - INFO - The work on page65 has finished.
2017-08-29 00:20:53,963 - Task:Scrapy_bills - INFO - The work on page67 has finished.
2017-08-29 00:21:18,565 - Task:Scrapy_bills - INFO - The work on page66 has finished.
2017-08-29 00:24:43,693 - Task:Scrapy_bills - INFO - The work on page67 has finished.
2017-08-29 00:25:04,467 - Task:Scrapy_bills - INFO - The work on page68 has finished.
2017-08-29 00:27:21,322 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 00:27:21,323 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 00:27:36,975 - Task:Scrapy_bills - INFO - The work on page70 has finished.
2017-08-29 00:27:37,923 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation61-70.json
2017-08-29 00:28:23,560 - Task:Scrapy_bills - INFO - The work on page68 has finished.
2017-08-29 00:31:24,461 - Task:Scrapy_bills - INFO - The work on page70 has finished.
2017-08-29 00:31:25,644 - Task:Scrapy_bills - INFO - The work on page69 has finished.
2017-08-29 00:31:26,462 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation61-70.json
2017-08-29 00:34:40,992 - Task:Scrapy_bills - INFO - The work on page70 has finished.
2017-08-29 00:34:44,032 - Task:Scrapy_bills - INFO - The work on page71 has finished.
2017-08-29 00:37:44,150 - Task:Scrapy_bills - INFO - The work on page71 has finished.
2017-08-29 00:38:46,530 - Task:Scrapy_bills - INFO - The work on page72 has finished.
2017-08-29 00:40:52,677 - Task:Scrapy_bills - INFO - The work on page72 has finished.
2017-08-29 00:42:44,668 - Task:Scrapy_bills - INFO - The work on page73 has finished.
2017-08-29 00:43:47,561 - Task:Scrapy_bills - INFO - The work on page73 has finished.
2017-08-29 00:46:43,410 - Task:Scrapy_bills - INFO - The work on page74 has finished.
2017-08-29 00:47:01,855 - Task:Scrapy_bills - INFO - The work on page74 has finished.
2017-08-29 00:50:36,777 - Task:Scrapy_bills - INFO - The work on page75 has finished.
2017-08-29 00:51:17,271 - Task:Scrapy_bills - INFO - The work on page75 has finished.
2017-08-29 00:54:42,984 - Task:Scrapy_bills - INFO - The work on page76 has finished.
2017-08-29 00:55:19,559 - Task:Scrapy_bills - INFO - The work on page76 has finished.
2017-08-29 00:59:02,055 - Task:Scrapy_bills - INFO - The work on page77 has finished.
2017-08-29 00:59:21,007 - Task:Scrapy_bills - INFO - The work on page77 has finished.
2017-08-29 01:03:23,266 - Task:Scrapy_bills - INFO - The work on page78 has finished.
2017-08-29 01:03:28,007 - Task:Scrapy_bills - INFO - The work on page78 has finished.
2017-08-29 01:07:33,890 - Task:Scrapy_bills - INFO - The work on page79 has finished.
2017-08-29 01:07:34,753 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation71-80.json
2017-08-29 01:07:43,601 - Task:Scrapy_bills - INFO - The work on page79 has finished.
2017-08-29 01:07:44,589 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation71-80.json
2017-08-29 01:10:13,761 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:10:13,763 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 01:10:30,906 - Task:Scrapy_bills - INFO - The work on page81 has finished.
2017-08-29 01:11:32,813 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:11:32,814 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 01:11:44,770 - Task:Scrapy_bills - INFO - The work on page80 has finished.
2017-08-29 01:11:48,703 - Task:Scrapy_bills - INFO - The work on page83 has finished.
2017-08-29 01:15:45,207 - Task:Scrapy_bills - INFO - The work on page81 has finished.
2017-08-29 01:16:12,274 - Task:Scrapy_bills - INFO - The work on page84 has finished.
2017-08-29 01:19:14,929 - Task:Scrapy_bills - INFO - The work on page85 has finished.
2017-08-29 01:19:19,976 - Task:Scrapy_bills - INFO - The work on page86 has finished.
2017-08-29 01:19:46,188 - Task:Scrapy_bills - INFO - The work on page82 has finished.
2017-08-29 01:21:10,506 - Task:Scrapy_bills - INFO - The work on page87 has finished.
2017-08-29 01:23:41,760 - Task:Scrapy_bills - INFO - The work on page83 has finished.
2017-08-29 01:25:03,997 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:25:04,002 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 01:25:25,275 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:25:25,278 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1260, in connect
    server_hostname=server_hostname)
  File "D:\Applications\anaconda3\lib\ssl.py", line 377, in wrap_socket
    _context=self)
  File "D:\Applications\anaconda3\lib\ssl.py", line 752, in __init__
    self.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 988, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Applications\anaconda3\lib\ssl.py", line 633, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [WinError 10054] 远程主机强迫关闭了一个现有的连接。>

2017-08-29 01:25:44,299 - Task:Scrapy_bills - INFO - The work on page89 has finished.
2017-08-29 01:25:44,996 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation81-90.json
2017-08-29 01:25:49,849 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:25:49,851 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 561, in _readall_chunked
    value.append(self._safe_read(chunk_left))
  File "D:\Applications\anaconda3\lib\http\client.py", line 607, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 01:26:08,626 - Task:Scrapy_bills - INFO - The work on page85 has finished.
2017-08-29 01:30:02,459 - Task:Scrapy_bills - INFO - The work on page90 has finished.
2017-08-29 01:30:11,191 - Task:Scrapy_bills - INFO - The work on page86 has finished.
2017-08-29 01:30:49,827 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:30:49,829 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 01:31:03,436 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:31:03,438 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 01:31:06,015 - Task:Scrapy_bills - INFO - The work on page92 has finished.
2017-08-29 01:31:19,865 - Task:Scrapy_bills - INFO - The work on page88 has finished.
2017-08-29 01:35:26,314 - Task:Scrapy_bills - INFO - The work on page93 has finished.
2017-08-29 01:35:35,679 - Task:Scrapy_bills - INFO - The work on page89 has finished.
2017-08-29 01:35:36,500 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation81-90.json
2017-08-29 01:39:35,608 - Task:Scrapy_bills - INFO - The work on page94 has finished.
2017-08-29 01:39:45,769 - Task:Scrapy_bills - INFO - The work on page90 has finished.
2017-08-29 01:43:42,783 - Task:Scrapy_bills - INFO - The work on page91 has finished.
2017-08-29 01:43:43,484 - Task:Scrapy_bills - INFO - The work on page95 has finished.
2017-08-29 01:45:29,794 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 01:45:29,794 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 01:45:46,958 - Task:Scrapy_bills - INFO - The work on page97 has finished.
2017-08-29 01:47:40,318 - Task:Scrapy_bills - INFO - The work on page92 has finished.
2017-08-29 01:47:44,076 - Task:Scrapy_bills - INFO - The work on page98 has finished.
2017-08-29 01:51:34,858 - Task:Scrapy_bills - INFO - The work on page93 has finished.
2017-08-29 01:51:51,911 - Task:Scrapy_bills - INFO - The work on page99 has finished.
2017-08-29 01:51:52,700 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation91-100.json
2017-08-29 01:55:38,900 - Task:Scrapy_bills - INFO - The work on page94 has finished.
2017-08-29 01:56:05,895 - Task:Scrapy_bills - INFO - The work on page100 has finished.
2017-08-29 01:59:34,845 - Task:Scrapy_bills - INFO - The work on page95 has finished.
2017-08-29 02:00:08,035 - Task:Scrapy_bills - INFO - The work on page101 has finished.
2017-08-29 02:03:33,837 - Task:Scrapy_bills - INFO - The work on page96 has finished.
2017-08-29 02:04:13,137 - Task:Scrapy_bills - INFO - The work on page102 has finished.
2017-08-29 02:07:29,220 - Task:Scrapy_bills - INFO - The work on page97 has finished.
2017-08-29 02:08:11,683 - Task:Scrapy_bills - INFO - The work on page103 has finished.
2017-08-29 02:11:25,228 - Task:Scrapy_bills - INFO - The work on page98 has finished.
2017-08-29 02:12:33,734 - Task:Scrapy_bills - INFO - The work on page104 has finished.
2017-08-29 02:15:28,829 - Task:Scrapy_bills - INFO - The work on page99 has finished.
2017-08-29 02:15:29,801 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation91-100.json
2017-08-29 02:16:58,573 - Task:Scrapy_bills - INFO - The work on page105 has finished.
2017-08-29 02:19:25,853 - Task:Scrapy_bills - INFO - The work on page100 has finished.
2017-08-29 02:21:13,977 - Task:Scrapy_bills - INFO - The work on page106 has finished.
2017-08-29 02:23:23,437 - Task:Scrapy_bills - INFO - The work on page101 has finished.
2017-08-29 02:25:52,834 - Task:Scrapy_bills - INFO - The work on page107 has finished.
2017-08-29 02:27:23,133 - Task:Scrapy_bills - INFO - The work on page102 has finished.
2017-08-29 02:30:15,661 - Task:Scrapy_bills - INFO - The work on page108 has finished.
2017-08-29 02:31:19,321 - Task:Scrapy_bills - INFO - The work on page103 has finished.
2017-08-29 02:34:43,389 - Task:Scrapy_bills - INFO - The work on page109 has finished.
2017-08-29 02:34:44,490 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation101-110.json
2017-08-29 02:35:23,495 - Task:Scrapy_bills - INFO - The work on page104 has finished.
2017-08-29 02:35:32,311 - Task:Scrapy_bills - INFO - The work on page110 has finished.
2017-08-29 02:36:04,982 - Task:Scrapy_bills - INFO - The work on page111 has finished.
2017-08-29 02:39:19,780 - Task:Scrapy_bills - INFO - The work on page105 has finished.
2017-08-29 02:40:05,259 - Task:Scrapy_bills - INFO - The work on page112 has finished.
2017-08-29 02:43:15,542 - Task:Scrapy_bills - INFO - The work on page106 has finished.
2017-08-29 02:44:07,196 - Task:Scrapy_bills - INFO - The work on page113 has finished.
2017-08-29 02:47:12,261 - Task:Scrapy_bills - INFO - The work on page107 has finished.
2017-08-29 02:48:13,172 - Task:Scrapy_bills - INFO - The work on page114 has finished.
2017-08-29 02:51:04,649 - Task:Scrapy_bills - INFO - The work on page108 has finished.
2017-08-29 02:52:16,859 - Task:Scrapy_bills - INFO - The work on page115 has finished.
2017-08-29 02:55:08,935 - Task:Scrapy_bills - INFO - The work on page109 has finished.
2017-08-29 02:55:09,909 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation101-110.json
2017-08-29 02:56:31,772 - Task:Scrapy_bills - INFO - The work on page116 has finished.
2017-08-29 02:59:07,135 - Task:Scrapy_bills - INFO - The work on page110 has finished.
2017-08-29 03:00:58,046 - Task:Scrapy_bills - INFO - The work on page117 has finished.
2017-08-29 03:03:12,859 - Task:Scrapy_bills - INFO - The work on page111 has finished.
2017-08-29 03:05:27,362 - Task:Scrapy_bills - INFO - The work on page118 has finished.
2017-08-29 03:07:13,970 - Task:Scrapy_bills - INFO - The work on page112 has finished.
2017-08-29 03:09:54,407 - Task:Scrapy_bills - INFO - The work on page119 has finished.
2017-08-29 03:09:55,327 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation111-120.json
2017-08-29 03:11:13,482 - Task:Scrapy_bills - INFO - The work on page113 has finished.
2017-08-29 03:12:16,188 - Task:Scrapy_bills - INFO - The work on page120 has finished.
2017-08-29 03:15:21,629 - Task:Scrapy_bills - INFO - The work on page114 has finished.
2017-08-29 03:16:35,877 - Task:Scrapy_bills - INFO - The work on page121 has finished.
2017-08-29 03:19:17,492 - Task:Scrapy_bills - INFO - The work on page115 has finished.
2017-08-29 03:20:51,027 - Task:Scrapy_bills - INFO - The work on page122 has finished.
2017-08-29 03:23:16,872 - Task:Scrapy_bills - INFO - The work on page116 has finished.
2017-08-29 03:25:09,979 - Task:Scrapy_bills - INFO - The work on page123 has finished.
2017-08-29 03:27:13,589 - Task:Scrapy_bills - INFO - The work on page117 has finished.
2017-08-29 03:29:12,623 - Task:Scrapy_bills - INFO - The work on page124 has finished.
2017-08-29 03:31:07,082 - Task:Scrapy_bills - INFO - The work on page118 has finished.
2017-08-29 03:33:32,491 - Task:Scrapy_bills - INFO - The work on page125 has finished.
2017-08-29 03:35:14,931 - Task:Scrapy_bills - INFO - The work on page119 has finished.
2017-08-29 03:35:15,933 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation111-120.json
2017-08-29 03:37:48,782 - Task:Scrapy_bills - INFO - The work on page126 has finished.
2017-08-29 03:39:22,544 - Task:Scrapy_bills - INFO - The work on page120 has finished.
2017-08-29 03:40:22,189 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 03:40:22,191 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 03:40:39,315 - Task:Scrapy_bills - INFO - The work on page128 has finished.
2017-08-29 03:43:18,356 - Task:Scrapy_bills - INFO - The work on page121 has finished.
2017-08-29 03:45:06,249 - Task:Scrapy_bills - INFO - The work on page129 has finished.
2017-08-29 03:45:07,199 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation121-130.json
2017-08-29 03:47:20,620 - Task:Scrapy_bills - INFO - The work on page122 has finished.
2017-08-29 03:49:27,073 - Task:Scrapy_bills - INFO - The work on page130 has finished.
2017-08-29 03:51:13,466 - Task:Scrapy_bills - INFO - The work on page131 has finished.
2017-08-29 03:51:17,969 - Task:Scrapy_bills - INFO - The work on page132 has finished.
2017-08-29 03:51:19,048 - Task:Scrapy_bills - INFO - The work on page123 has finished.
2017-08-29 03:54:31,085 - Task:Scrapy_bills - INFO - The work on page133 has finished.
2017-08-29 03:55:17,011 - Task:Scrapy_bills - INFO - The work on page124 has finished.
2017-08-29 03:58:20,551 - Task:Scrapy_bills - INFO - The work on page134 has finished.
2017-08-29 03:59:14,258 - Task:Scrapy_bills - INFO - The work on page125 has finished.
2017-08-29 04:02:10,588 - Task:Scrapy_bills - INFO - The work on page135 has finished.
2017-08-29 04:03:14,097 - Task:Scrapy_bills - INFO - The work on page126 has finished.
2017-08-29 04:06:00,991 - Task:Scrapy_bills - INFO - The work on page136 has finished.
2017-08-29 04:07:12,003 - Task:Scrapy_bills - INFO - The work on page127 has finished.
2017-08-29 04:09:55,301 - Task:Scrapy_bills - INFO - The work on page137 has finished.
2017-08-29 04:11:15,829 - Task:Scrapy_bills - INFO - The work on page128 has finished.
2017-08-29 04:14:05,501 - Task:Scrapy_bills - INFO - The work on page138 has finished.
2017-08-29 04:15:13,350 - Task:Scrapy_bills - INFO - The work on page129 has finished.
2017-08-29 04:15:14,365 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation121-130.json
2017-08-29 04:18:20,256 - Task:Scrapy_bills - INFO - The work on page139 has finished.
2017-08-29 04:18:21,223 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation131-140.json
2017-08-29 04:19:20,572 - Task:Scrapy_bills - INFO - The work on page130 has finished.
2017-08-29 04:22:35,000 - Task:Scrapy_bills - INFO - The work on page140 has finished.
2017-08-29 04:23:19,166 - Task:Scrapy_bills - INFO - The work on page131 has finished.
2017-08-29 04:24:06,148 - Task:Scrapy_bills - INFO - The work on page141 has finished.
2017-08-29 04:27:07,482 - Task:Scrapy_bills - INFO - The work on page142 has finished.
2017-08-29 04:27:18,623 - Task:Scrapy_bills - INFO - The work on page132 has finished.
2017-08-29 04:30:57,420 - Task:Scrapy_bills - INFO - The work on page143 has finished.
2017-08-29 04:31:21,341 - Task:Scrapy_bills - INFO - The work on page133 has finished.
2017-08-29 04:34:47,721 - Task:Scrapy_bills - INFO - The work on page144 has finished.
2017-08-29 04:35:19,950 - Task:Scrapy_bills - INFO - The work on page134 has finished.
2017-08-29 04:38:43,558 - Task:Scrapy_bills - INFO - The work on page145 has finished.
2017-08-29 04:39:15,547 - Task:Scrapy_bills - INFO - The work on page135 has finished.
2017-08-29 04:43:06,731 - Task:Scrapy_bills - INFO - The work on page146 has finished.
2017-08-29 04:43:09,070 - Task:Scrapy_bills - INFO - The work on page136 has finished.
2017-08-29 04:47:07,257 - Task:Scrapy_bills - INFO - The work on page137 has finished.
2017-08-29 04:47:21,727 - Task:Scrapy_bills - INFO - The work on page147 has finished.
2017-08-29 04:51:02,226 - Task:Scrapy_bills - INFO - The work on page138 has finished.
2017-08-29 04:51:45,668 - Task:Scrapy_bills - INFO - The work on page148 has finished.
2017-08-29 04:54:34,788 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 04:54:34,788 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-29 04:54:50,938 - Task:Scrapy_bills - INFO - The work on page140 has finished.
2017-08-29 04:54:51,980 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation131-140.json
2017-08-29 04:55:10,612 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 04:55:10,613 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-29 04:55:27,327 - Task:Scrapy_bills - INFO - The work on page141 has finished.
2017-08-29 04:55:35,976 - Task:Scrapy_bills - INFO - The work on page142 has finished.
2017-08-29 04:56:09,179 - Task:Scrapy_bills - INFO - The work on page149 has finished.
2017-08-29 04:56:10,225 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation141-150.json
2017-08-29 04:59:21,005 - Task:Scrapy_bills - INFO - The work on page143 has finished.
2017-08-29 05:00:29,177 - Task:Scrapy_bills - INFO - The work on page150 has finished.
2017-08-29 05:02:50,010 - Task:Scrapy_bills - INFO - The work on page151 has finished.
2017-08-29 05:02:55,035 - Task:Scrapy_bills - INFO - The work on page152 has finished.
2017-08-29 05:03:10,874 - Task:Scrapy_bills - INFO - The work on page144 has finished.
2017-08-29 05:05:29,155 - Task:Scrapy_bills - INFO - The work on page153 has finished.
2017-08-29 05:07:00,098 - Task:Scrapy_bills - INFO - The work on page145 has finished.
2017-08-29 05:09:15,558 - Task:Scrapy_bills - INFO - The work on page154 has finished.
2017-08-29 05:10:48,795 - Task:Scrapy_bills - INFO - The work on page146 has finished.
2017-08-29 05:13:00,148 - Task:Scrapy_bills - INFO - The work on page155 has finished.
2017-08-29 05:14:35,772 - Task:Scrapy_bills - INFO - The work on page147 has finished.
2017-08-29 05:16:51,822 - Task:Scrapy_bills - INFO - The work on page156 has finished.
2017-08-29 05:18:23,886 - Task:Scrapy_bills - INFO - The work on page148 has finished.
2017-08-29 05:21:04,042 - Task:Scrapy_bills - INFO - The work on page157 has finished.
2017-08-29 05:22:10,636 - Task:Scrapy_bills - INFO - The work on page149 has finished.
2017-08-29 05:22:11,454 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation141-150.json
2017-08-29 05:25:09,831 - Task:Scrapy_bills - INFO - The work on page158 has finished.
2017-08-29 05:26:03,088 - Task:Scrapy_bills - INFO - The work on page159 has finished.
2017-08-29 05:26:03,991 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation151-160.json
2017-08-29 05:26:04,512 - Task:Scrapy_bills - INFO - The work on page150 has finished.
2017-08-29 05:29:48,517 - Task:Scrapy_bills - INFO - The work on page151 has finished.
2017-08-29 05:29:52,511 - Task:Scrapy_bills - INFO - The work on page160 has finished.
2017-08-29 05:33:25,409 - Task:Scrapy_bills - INFO - The work on page152 has finished.
2017-08-29 05:33:44,764 - Task:Scrapy_bills - INFO - The work on page161 has finished.
2017-08-29 05:36:42,687 - Task:Scrapy_bills - INFO - The work on page153 has finished.
2017-08-29 05:37:47,135 - Task:Scrapy_bills - INFO - The work on page162 has finished.
2017-08-29 05:40:02,132 - Task:Scrapy_bills - INFO - The work on page154 has finished.
2017-08-29 05:42:08,538 - Task:Scrapy_bills - INFO - The work on page163 has finished.
2017-08-29 05:43:21,924 - Task:Scrapy_bills - INFO - The work on page155 has finished.
2017-08-29 05:43:35,279 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 05:43:35,281 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 05:43:51,875 - Task:Scrapy_bills - INFO - The work on page165 has finished.
2017-08-29 05:46:39,022 - Task:Scrapy_bills - INFO - The work on page156 has finished.
2017-08-29 05:48:27,114 - Task:Scrapy_bills - INFO - The work on page166 has finished.
2017-08-29 05:49:55,916 - Task:Scrapy_bills - INFO - The work on page157 has finished.
2017-08-29 05:52:53,800 - Task:Scrapy_bills - INFO - The work on page167 has finished.
2017-08-29 05:53:14,779 - Task:Scrapy_bills - INFO - The work on page158 has finished.
2017-08-29 05:55:14,335 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 05:55:14,337 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 05:55:30,939 - Task:Scrapy_bills - INFO - The work on page169 has finished.
2017-08-29 05:55:31,842 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation161-170.json
2017-08-29 05:55:39,686 - Task:Scrapy_bills - INFO - The work on page170 has finished.
2017-08-29 05:56:33,462 - Task:Scrapy_bills - INFO - The work on page159 has finished.
2017-08-29 05:56:34,274 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation151-160.json
2017-08-29 05:58:20,532 - Task:Scrapy_bills - INFO - The work on page171 has finished.
2017-08-29 05:59:49,782 - Task:Scrapy_bills - INFO - The work on page160 has finished.
2017-08-29 06:02:03,770 - Task:Scrapy_bills - INFO - The work on page172 has finished.
2017-08-29 06:03:07,481 - Task:Scrapy_bills - INFO - The work on page161 has finished.
2017-08-29 06:05:50,363 - Task:Scrapy_bills - INFO - The work on page173 has finished.
2017-08-29 06:06:22,250 - Task:Scrapy_bills - INFO - The work on page162 has finished.
2017-08-29 06:09:38,245 - Task:Scrapy_bills - INFO - The work on page163 has finished.
2017-08-29 06:09:38,806 - Task:Scrapy_bills - INFO - The work on page174 has finished.
2017-08-29 06:12:53,684 - Task:Scrapy_bills - INFO - The work on page164 has finished.
2017-08-29 06:13:38,255 - Task:Scrapy_bills - INFO - The work on page175 has finished.
2017-08-29 06:16:11,513 - Task:Scrapy_bills - INFO - The work on page165 has finished.
2017-08-29 06:17:45,868 - Task:Scrapy_bills - INFO - The work on page176 has finished.
2017-08-29 06:19:29,145 - Task:Scrapy_bills - INFO - The work on page166 has finished.
2017-08-29 06:22:03,938 - Task:Scrapy_bills - INFO - The work on page177 has finished.
2017-08-29 06:23:09,426 - Task:Scrapy_bills - INFO - The work on page167 has finished.
2017-08-29 06:26:11,607 - Task:Scrapy_bills - INFO - The work on page178 has finished.
2017-08-29 06:26:44,189 - Task:Scrapy_bills - INFO - The work on page179 has finished.
2017-08-29 06:26:45,103 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation171-180.json
2017-08-29 06:27:07,045 - Task:Scrapy_bills - INFO - The work on page168 has finished.
2017-08-29 06:30:37,318 - Task:Scrapy_bills - INFO - The work on page180 has finished.
2017-08-29 06:31:02,370 - Task:Scrapy_bills - INFO - The work on page169 has finished.
2017-08-29 06:31:03,182 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation161-170.json
2017-08-29 06:34:28,907 - Task:Scrapy_bills - INFO - The work on page181 has finished.
2017-08-29 06:35:00,814 - Task:Scrapy_bills - INFO - The work on page170 has finished.
2017-08-29 06:38:26,215 - Task:Scrapy_bills - INFO - The work on page182 has finished.
2017-08-29 06:38:48,531 - Task:Scrapy_bills - INFO - The work on page171 has finished.
2017-08-29 06:42:42,660 - Task:Scrapy_bills - INFO - The work on page172 has finished.
2017-08-29 06:42:59,480 - Task:Scrapy_bills - INFO - The work on page183 has finished.
2017-08-29 06:46:37,798 - Task:Scrapy_bills - INFO - The work on page173 has finished.
2017-08-29 06:47:26,957 - Task:Scrapy_bills - INFO - The work on page184 has finished.
2017-08-29 06:50:30,821 - Task:Scrapy_bills - INFO - The work on page174 has finished.
2017-08-29 06:52:08,634 - Task:Scrapy_bills - INFO - The work on page185 has finished.
2017-08-29 06:54:18,562 - Task:Scrapy_bills - INFO - The work on page175 has finished.
2017-08-29 06:56:53,335 - Task:Scrapy_bills - INFO - The work on page186 has finished.
2017-08-29 06:58:09,036 - Task:Scrapy_bills - INFO - The work on page176 has finished.
2017-08-29 07:01:21,299 - Task:Scrapy_bills - INFO - The work on page187 has finished.
2017-08-29 07:01:58,110 - Task:Scrapy_bills - INFO - The work on page177 has finished.
2017-08-29 07:02:17,618 - Task:Scrapy_bills - INFO - The work on page188 has finished.
2017-08-29 07:05:26,664 - Task:Scrapy_bills - INFO - The work on page189 has finished.
2017-08-29 07:05:27,685 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation181-190.json
2017-08-29 07:05:48,463 - Task:Scrapy_bills - INFO - The work on page178 has finished.
2017-08-29 07:09:35,257 - Task:Scrapy_bills - INFO - The work on page179 has finished.
2017-08-29 07:09:36,205 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation171-180.json
2017-08-29 07:09:38,794 - Task:Scrapy_bills - INFO - The work on page190 has finished.
2017-08-29 07:13:24,865 - Task:Scrapy_bills - INFO - The work on page180 has finished.
2017-08-29 07:13:49,064 - Task:Scrapy_bills - INFO - The work on page191 has finished.
2017-08-29 07:17:15,931 - Task:Scrapy_bills - INFO - The work on page181 has finished.
2017-08-29 07:17:57,382 - Task:Scrapy_bills - INFO - The work on page192 has finished.
2017-08-29 07:21:08,211 - Task:Scrapy_bills - INFO - The work on page182 has finished.
2017-08-29 07:22:14,915 - Task:Scrapy_bills - INFO - The work on page193 has finished.
2017-08-29 07:24:59,550 - Task:Scrapy_bills - INFO - The work on page183 has finished.
2017-08-29 07:26:30,394 - Task:Scrapy_bills - INFO - The work on page194 has finished.
2017-08-29 07:28:51,600 - Task:Scrapy_bills - INFO - The work on page184 has finished.
2017-08-29 07:30:40,386 - Task:Scrapy_bills - INFO - The work on page195 has finished.
2017-08-29 07:32:21,589 - Task:Scrapy_bills - INFO - The work on page196 has finished.
2017-08-29 07:32:41,234 - Task:Scrapy_bills - INFO - The work on page185 has finished.
2017-08-29 07:36:30,776 - Task:Scrapy_bills - INFO - The work on page197 has finished.
2017-08-29 07:36:34,000 - Task:Scrapy_bills - INFO - The work on page186 has finished.
2017-08-29 07:40:26,912 - Task:Scrapy_bills - INFO - The work on page187 has finished.
2017-08-29 07:40:42,111 - Task:Scrapy_bills - INFO - The work on page198 has finished.
2017-08-29 07:44:19,304 - Task:Scrapy_bills - INFO - The work on page188 has finished.
2017-08-29 07:45:08,206 - Task:Scrapy_bills - INFO - The work on page199 has finished.
2017-08-29 07:45:09,188 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation191-200.json
2017-08-29 07:48:13,598 - Task:Scrapy_bills - INFO - The work on page189 has finished.
2017-08-29 07:48:14,601 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation181-190.json
2017-08-29 07:49:38,470 - Task:Scrapy_bills - INFO - The work on page200 has finished.
2017-08-29 07:52:08,140 - Task:Scrapy_bills - INFO - The work on page190 has finished.
2017-08-29 07:54:10,375 - Task:Scrapy_bills - INFO - The work on page201 has finished.
2017-08-29 07:56:00,918 - Task:Scrapy_bills - INFO - The work on page191 has finished.
2017-08-29 07:58:35,722 - Task:Scrapy_bills - INFO - The work on page202 has finished.
2017-08-29 07:59:49,217 - Task:Scrapy_bills - INFO - The work on page192 has finished.
2017-08-29 08:01:51,682 - Task:Scrapy_bills - INFO - The work on page203 has finished.
2017-08-29 08:03:36,238 - Task:Scrapy_bills - INFO - The work on page193 has finished.
2017-08-29 08:03:41,993 - Task:Scrapy_bills - INFO - The work on page204 has finished.
2017-08-29 08:07:26,889 - Task:Scrapy_bills - INFO - The work on page194 has finished.
2017-08-29 08:07:35,811 - Task:Scrapy_bills - INFO - The work on page205 has finished.
2017-08-29 08:11:13,860 - Task:Scrapy_bills - INFO - The work on page195 has finished.
2017-08-29 08:11:29,314 - Task:Scrapy_bills - INFO - The work on page206 has finished.
2017-08-29 08:15:03,837 - Task:Scrapy_bills - INFO - The work on page196 has finished.
2017-08-29 08:15:22,213 - Task:Scrapy_bills - INFO - The work on page207 has finished.
2017-08-29 08:18:51,273 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 08:18:51,274 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 08:18:55,758 - Task:Scrapy_bills - INFO - The work on page197 has finished.
2017-08-29 08:19:07,644 - Task:Scrapy_bills - INFO - The work on page209 has finished.
2017-08-29 08:19:08,594 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation201-210.json
2017-08-29 08:21:41,214 - Task:Scrapy_bills - INFO - The work on page210 has finished.
2017-08-29 08:22:46,464 - Task:Scrapy_bills - INFO - The work on page198 has finished.
2017-08-29 08:25:33,781 - Task:Scrapy_bills - INFO - The work on page211 has finished.
2017-08-29 08:26:33,512 - Task:Scrapy_bills - INFO - The work on page199 has finished.
2017-08-29 08:26:34,460 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation191-200.json
2017-08-29 08:29:36,098 - Task:Scrapy_bills - INFO - The work on page212 has finished.
2017-08-29 08:30:26,871 - Task:Scrapy_bills - INFO - The work on page200 has finished.
2017-08-29 08:33:56,868 - Task:Scrapy_bills - INFO - The work on page213 has finished.
2017-08-29 08:34:18,326 - Task:Scrapy_bills - INFO - The work on page201 has finished.
2017-08-29 08:37:39,981 - Task:Scrapy_bills - INFO - The work on page202 has finished.
2017-08-29 08:38:08,933 - Task:Scrapy_bills - INFO - The work on page203 has finished.
2017-08-29 08:38:20,409 - Task:Scrapy_bills - INFO - The work on page214 has finished.
2017-08-29 08:41:51,864 - Task:Scrapy_bills - INFO - The work on page204 has finished.
2017-08-29 08:42:38,779 - Task:Scrapy_bills - INFO - The work on page215 has finished.
2017-08-29 08:45:43,278 - Task:Scrapy_bills - INFO - The work on page205 has finished.
2017-08-29 08:47:09,788 - Task:Scrapy_bills - INFO - The work on page216 has finished.
2017-08-29 08:49:29,071 - Task:Scrapy_bills - INFO - The work on page206 has finished.
2017-08-29 08:51:23,280 - Task:Scrapy_bills - INFO - The work on page217 has finished.
2017-08-29 08:53:02,740 - Task:Scrapy_bills - INFO - The work on page218 has finished.
2017-08-29 08:53:13,480 - Task:Scrapy_bills - INFO - The work on page207 has finished.
2017-08-29 08:56:23,911 - Task:Scrapy_bills - INFO - The work on page219 has finished.
2017-08-29 08:56:24,887 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation211-220.json
2017-08-29 08:56:58,513 - Task:Scrapy_bills - INFO - The work on page208 has finished.
2017-08-29 09:00:36,433 - Task:Scrapy_bills - INFO - The work on page220 has finished.
2017-08-29 09:00:44,397 - Task:Scrapy_bills - INFO - The work on page209 has finished.
2017-08-29 09:00:45,298 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation201-210.json
2017-08-29 09:04:45,132 - Task:Scrapy_bills - INFO - The work on page210 has finished.
2017-08-29 09:05:18,347 - Task:Scrapy_bills - INFO - The work on page221 has finished.
2017-08-29 09:08:11,966 - Task:Scrapy_bills - INFO - The work on page211 has finished.
2017-08-29 09:09:40,824 - Task:Scrapy_bills - INFO - The work on page222 has finished.
2017-08-29 09:11:29,958 - Task:Scrapy_bills - INFO - The work on page212 has finished.
2017-08-29 09:13:58,525 - Task:Scrapy_bills - INFO - The work on page223 has finished.
2017-08-29 09:14:50,561 - Task:Scrapy_bills - INFO - The work on page213 has finished.
2017-08-29 09:17:02,558 - Task:Scrapy_bills - INFO - The work on page224 has finished.
2017-08-29 09:18:11,095 - Task:Scrapy_bills - INFO - The work on page214 has finished.
2017-08-29 09:18:58,622 - Task:Scrapy_bills - INFO - The work on page225 has finished.
2017-08-29 09:21:31,814 - Task:Scrapy_bills - INFO - The work on page215 has finished.
2017-08-29 09:22:58,668 - Task:Scrapy_bills - INFO - The work on page226 has finished.
2017-08-29 09:24:52,688 - Task:Scrapy_bills - INFO - The work on page216 has finished.
2017-08-29 09:27:06,353 - Task:Scrapy_bills - INFO - The work on page227 has finished.
2017-08-29 09:28:16,123 - Task:Scrapy_bills - INFO - The work on page217 has finished.
2017-08-29 09:31:22,576 - Task:Scrapy_bills - INFO - The work on page228 has finished.
2017-08-29 09:31:40,665 - Task:Scrapy_bills - INFO - The work on page218 has finished.
2017-08-29 09:35:03,052 - Task:Scrapy_bills - INFO - The work on page219 has finished.
2017-08-29 09:35:03,844 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation211-220.json
2017-08-29 09:35:52,242 - Task:Scrapy_bills - INFO - The work on page229 has finished.
2017-08-29 09:35:53,233 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation221-230.json
2017-08-29 09:38:29,263 - Task:Scrapy_bills - INFO - The work on page220 has finished.
2017-08-29 09:40:17,148 - Task:Scrapy_bills - INFO - The work on page230 has finished.
2017-08-29 09:41:48,199 - Task:Scrapy_bills - INFO - The work on page221 has finished.
2017-08-29 09:44:53,292 - Task:Scrapy_bills - INFO - The work on page231 has finished.
2017-08-29 09:45:07,516 - Task:Scrapy_bills - INFO - The work on page222 has finished.
2017-08-29 09:48:27,020 - Task:Scrapy_bills - INFO - The work on page223 has finished.
2017-08-29 09:49:21,257 - Task:Scrapy_bills - INFO - The work on page232 has finished.
2017-08-29 09:51:45,915 - Task:Scrapy_bills - INFO - The work on page224 has finished.
2017-08-29 09:53:40,974 - Task:Scrapy_bills - INFO - The work on page233 has finished.
2017-08-29 09:55:06,384 - Task:Scrapy_bills - INFO - The work on page225 has finished.
2017-08-29 09:57:27,028 - Task:Scrapy_bills - INFO - The work on page234 has finished.
2017-08-29 09:58:09,818 - Task:Scrapy_bills - INFO - The work on page235 has finished.
2017-08-29 09:58:26,871 - Task:Scrapy_bills - INFO - The work on page226 has finished.
2017-08-29 10:01:51,043 - Task:Scrapy_bills - INFO - The work on page227 has finished.
2017-08-29 10:02:23,617 - Task:Scrapy_bills - INFO - The work on page236 has finished.
2017-08-29 10:05:23,172 - Task:Scrapy_bills - INFO - The work on page228 has finished.
2017-08-29 10:06:42,433 - Task:Scrapy_bills - INFO - The work on page237 has finished.
2017-08-29 10:08:48,693 - Task:Scrapy_bills - INFO - The work on page229 has finished.
2017-08-29 10:08:49,480 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation221-230.json
2017-08-29 10:11:00,347 - Task:Scrapy_bills - INFO - The work on page238 has finished.
2017-08-29 10:12:16,360 - Task:Scrapy_bills - INFO - The work on page230 has finished.
2017-08-29 10:15:20,241 - Task:Scrapy_bills - INFO - The work on page239 has finished.
2017-08-29 10:15:21,268 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation231-240.json
2017-08-29 10:15:38,034 - Task:Scrapy_bills - INFO - The work on page231 has finished.
2017-08-29 10:18:55,557 - Task:Scrapy_bills - INFO - The work on page232 has finished.
2017-08-29 10:19:45,360 - Task:Scrapy_bills - INFO - The work on page240 has finished.
2017-08-29 10:22:13,892 - Task:Scrapy_bills - INFO - The work on page233 has finished.
2017-08-29 10:24:06,264 - Task:Scrapy_bills - INFO - The work on page241 has finished.
2017-08-29 10:25:33,029 - Task:Scrapy_bills - INFO - The work on page234 has finished.
2017-08-29 10:26:30,596 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 10:26:30,598 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 10:26:46,187 - Task:Scrapy_bills - INFO - The work on page243 has finished.
2017-08-29 10:28:51,379 - Task:Scrapy_bills - INFO - The work on page235 has finished.
2017-08-29 10:29:49,594 - Task:Scrapy_bills - INFO - The work on page244 has finished.
2017-08-29 10:32:15,012 - Task:Scrapy_bills - INFO - The work on page236 has finished.
2017-08-29 10:33:53,511 - Task:Scrapy_bills - INFO - The work on page245 has finished.
2017-08-29 10:35:42,573 - Task:Scrapy_bills - INFO - The work on page237 has finished.
2017-08-29 10:38:01,276 - Task:Scrapy_bills - INFO - The work on page246 has finished.
2017-08-29 10:39:08,956 - Task:Scrapy_bills - INFO - The work on page238 has finished.
2017-08-29 10:42:30,848 - Task:Scrapy_bills - INFO - The work on page247 has finished.
2017-08-29 10:42:32,471 - Task:Scrapy_bills - INFO - The work on page239 has finished.
2017-08-29 10:42:33,250 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation231-240.json
2017-08-29 10:46:01,762 - Task:Scrapy_bills - INFO - The work on page240 has finished.
2017-08-29 10:46:56,883 - Task:Scrapy_bills - INFO - The work on page248 has finished.
2017-08-29 10:49:23,238 - Task:Scrapy_bills - INFO - The work on page241 has finished.
2017-08-29 10:51:26,254 - Task:Scrapy_bills - INFO - The work on page249 has finished.
2017-08-29 10:51:27,230 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation241-250.json
2017-08-29 10:52:44,152 - Task:Scrapy_bills - INFO - The work on page242 has finished.
2017-08-29 10:56:01,103 - Task:Scrapy_bills - INFO - The work on page250 has finished.
2017-08-29 10:56:04,423 - Task:Scrapy_bills - INFO - The work on page243 has finished.
2017-08-29 10:59:27,136 - Task:Scrapy_bills - INFO - The work on page244 has finished.
2017-08-29 11:00:30,604 - Task:Scrapy_bills - INFO - The work on page251 has finished.
2017-08-29 11:02:50,659 - Task:Scrapy_bills - INFO - The work on page245 has finished.
2017-08-29 11:04:27,557 - Task:Scrapy_bills - INFO - The work on page252 has finished.
2017-08-29 11:06:10,942 - Task:Scrapy_bills - INFO - The work on page246 has finished.
2017-08-29 11:06:40,075 - Task:Scrapy_bills - INFO - The work on page253 has finished.
2017-08-29 11:09:25,619 - Task:Scrapy_bills - INFO - The work on page254 has finished.
2017-08-29 11:09:31,672 - Task:Scrapy_bills - INFO - The work on page247 has finished.
2017-08-29 11:12:52,542 - Task:Scrapy_bills - INFO - The work on page248 has finished.
2017-08-29 11:13:38,314 - Task:Scrapy_bills - INFO - The work on page255 has finished.
2017-08-29 11:16:13,244 - Task:Scrapy_bills - INFO - The work on page249 has finished.
2017-08-29 11:16:14,017 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation241-250.json
2017-08-29 11:17:47,621 - Task:Scrapy_bills - INFO - The work on page256 has finished.
2017-08-29 11:19:34,489 - Task:Scrapy_bills - INFO - The work on page250 has finished.
2017-08-29 11:22:04,689 - Task:Scrapy_bills - INFO - The work on page257 has finished.
2017-08-29 11:22:56,171 - Task:Scrapy_bills - INFO - The work on page251 has finished.
2017-08-29 11:26:14,693 - Task:Scrapy_bills - INFO - The work on page252 has finished.
2017-08-29 11:26:18,526 - Task:Scrapy_bills - INFO - The work on page258 has finished.
2017-08-29 11:28:05,142 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 11:28:05,145 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 11:28:21,072 - Task:Scrapy_bills - INFO - The work on page260 has finished.
2017-08-29 11:28:22,054 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation251-260.json
2017-08-29 11:29:33,256 - Task:Scrapy_bills - INFO - The work on page253 has finished.
2017-08-29 11:32:10,531 - Task:Scrapy_bills - INFO - The work on page260 has finished.
2017-08-29 11:32:55,994 - Task:Scrapy_bills - INFO - The work on page254 has finished.
2017-08-29 11:34:58,106 - Task:Scrapy_bills - INFO - The work on page261 has finished.
2017-08-29 11:36:16,663 - Task:Scrapy_bills - INFO - The work on page255 has finished.
2017-08-29 11:36:49,594 - Task:Scrapy_bills - INFO - The work on page262 has finished.
2017-08-29 11:39:36,955 - Task:Scrapy_bills - INFO - The work on page263 has finished.
2017-08-29 11:39:37,185 - Task:Scrapy_bills - INFO - The work on page256 has finished.
2017-08-29 11:42:55,848 - Task:Scrapy_bills - INFO - The work on page257 has finished.
2017-08-29 11:43:42,128 - Task:Scrapy_bills - INFO - The work on page264 has finished.
2017-08-29 11:46:15,508 - Task:Scrapy_bills - INFO - The work on page258 has finished.
2017-08-29 11:47:54,283 - Task:Scrapy_bills - INFO - The work on page265 has finished.
2017-08-29 11:49:33,498 - Task:Scrapy_bills - INFO - The work on page259 has finished.
2017-08-29 11:49:34,280 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation251-260.json
2017-08-29 11:52:25,274 - Task:Scrapy_bills - INFO - The work on page266 has finished.
2017-08-29 11:52:57,024 - Task:Scrapy_bills - INFO - The work on page260 has finished.
2017-08-29 11:56:17,713 - Task:Scrapy_bills - INFO - The work on page261 has finished.
2017-08-29 11:56:54,801 - Task:Scrapy_bills - INFO - The work on page267 has finished.
2017-08-29 11:59:59,907 - Task:Scrapy_bills - INFO - The work on page262 has finished.
2017-08-29 12:01:16,665 - Task:Scrapy_bills - INFO - The work on page268 has finished.
2017-08-29 12:03:55,440 - Task:Scrapy_bills - INFO - The work on page263 has finished.
2017-08-29 12:05:46,416 - Task:Scrapy_bills - INFO - The work on page269 has finished.
2017-08-29 12:05:47,403 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation261-270.json
2017-08-29 12:07:43,616 - Task:Scrapy_bills - INFO - The work on page264 has finished.
2017-08-29 12:10:16,670 - Task:Scrapy_bills - INFO - The work on page270 has finished.
2017-08-29 12:11:32,458 - Task:Scrapy_bills - INFO - The work on page265 has finished.
2017-08-29 12:14:45,067 - Task:Scrapy_bills - INFO - The work on page271 has finished.
2017-08-29 12:15:24,868 - Task:Scrapy_bills - INFO - The work on page266 has finished.
2017-08-29 12:18:01,300 - Task:Scrapy_bills - INFO - The work on page272 has finished.
2017-08-29 12:19:14,608 - Task:Scrapy_bills - INFO - The work on page267 has finished.
2017-08-29 12:19:18,101 - Task:Scrapy_bills - INFO - The work on page273 has finished.
2017-08-29 12:21:48,030 - Task:Scrapy_bills - INFO - The work on page274 has finished.
2017-08-29 12:23:06,221 - Task:Scrapy_bills - INFO - The work on page268 has finished.
2017-08-29 12:26:06,601 - Task:Scrapy_bills - INFO - The work on page275 has finished.
2017-08-29 12:27:03,140 - Task:Scrapy_bills - INFO - The work on page269 has finished.
2017-08-29 12:27:04,075 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation261-270.json
2017-08-29 12:30:18,555 - Task:Scrapy_bills - INFO - The work on page276 has finished.
2017-08-29 12:31:07,281 - Task:Scrapy_bills - INFO - The work on page270 has finished.
2017-08-29 12:34:33,620 - Task:Scrapy_bills - INFO - The work on page277 has finished.
2017-08-29 12:35:03,796 - Task:Scrapy_bills - INFO - The work on page271 has finished.
2017-08-29 12:38:46,840 - Task:Scrapy_bills - INFO - The work on page278 has finished.
2017-08-29 12:38:59,651 - Task:Scrapy_bills - INFO - The work on page272 has finished.
2017-08-29 12:42:53,159 - Task:Scrapy_bills - INFO - The work on page273 has finished.
2017-08-29 12:43:05,335 - Task:Scrapy_bills - INFO - The work on page279 has finished.
2017-08-29 12:43:06,303 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation271-280.json
2017-08-29 12:46:25,783 - Task:Scrapy_bills - INFO - The work on page280 has finished.
2017-08-29 12:46:46,272 - Task:Scrapy_bills - INFO - The work on page274 has finished.
2017-08-29 12:47:20,429 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 12:47:20,432 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 12:49:44,734 - Task:Scrapy_bills - INFO - The work on page281 has finished.
2017-08-29 12:50:57,985 - Task:Scrapy_bills - INFO - The work on page282 has finished.
2017-08-29 12:51:22,440 - Task:Scrapy_bills - INFO - The work on page275 has finished.
2017-08-29 12:54:15,296 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 12:54:15,298 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 12:54:27,678 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 12:54:27,680 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 12:54:31,958 - Task:Scrapy_bills - INFO - The work on page277 has finished.
2017-08-29 12:54:43,816 - Task:Scrapy_bills - INFO - The work on page284 has finished.
2017-08-29 12:55:47,563 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 12:55:47,564 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 12:56:02,831 - Task:Scrapy_bills - INFO - The work on page286 has finished.
2017-08-29 12:56:24,097 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 12:56:24,099 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 12:58:41,784 - Task:Scrapy_bills - INFO - The work on page278 has finished.
2017-08-29 13:01:00,833 - Task:Scrapy_bills - INFO - The work on page287 has finished.
2017-08-29 13:02:44,515 - Task:Scrapy_bills - INFO - The work on page279 has finished.
2017-08-29 13:02:45,431 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation271-280.json
2017-08-29 13:06:04,449 - Task:Scrapy_bills - INFO - The work on page288 has finished.
2017-08-29 13:07:05,167 - Task:Scrapy_bills - INFO - The work on page280 has finished.
2017-08-29 13:11:07,551 - Task:Scrapy_bills - INFO - The work on page289 has finished.
2017-08-29 13:11:08,372 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation281-290.json
2017-08-29 13:11:23,590 - Task:Scrapy_bills - INFO - The work on page281 has finished.
2017-08-29 13:15:42,758 - Task:Scrapy_bills - INFO - The work on page282 has finished.
2017-08-29 13:16:19,538 - Task:Scrapy_bills - INFO - The work on page290 has finished.
2017-08-29 13:17:01,597 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:17:01,600 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 13:17:17,521 - Task:Scrapy_bills - INFO - The work on page284 has finished.
2017-08-29 13:21:02,468 - Task:Scrapy_bills - INFO - The work on page291 has finished.
2017-08-29 13:21:37,667 - Task:Scrapy_bills - INFO - The work on page285 has finished.
2017-08-29 13:25:31,109 - Task:Scrapy_bills - INFO - The work on page292 has finished.
2017-08-29 13:25:51,872 - Task:Scrapy_bills - INFO - The work on page286 has finished.
2017-08-29 13:26:01,408 - Task:Scrapy_bills - INFO - The work on page293 has finished.
2017-08-29 13:30:05,538 - Task:Scrapy_bills - INFO - The work on page287 has finished.
2017-08-29 13:30:35,400 - Task:Scrapy_bills - INFO - The work on page294 has finished.
2017-08-29 13:30:40,616 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:30:40,618 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 13:35:10,015 - Task:Scrapy_bills - INFO - The work on page288 has finished.
2017-08-29 13:35:26,490 - Task:Scrapy_bills - INFO - The work on page295 has finished.
2017-08-29 13:37:48,560 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:37:48,563 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 13:38:04,319 - Task:Scrapy_bills - INFO - The work on page297 has finished.
2017-08-29 13:39:23,232 - Task:Scrapy_bills - INFO - The work on page289 has finished.
2017-08-29 13:39:24,140 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation281-290.json
2017-08-29 13:39:31,371 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:39:31,373 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 13:39:47,723 - Task:Scrapy_bills - INFO - The work on page299 has finished.
2017-08-29 13:39:48,525 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation291-300.json
2017-08-29 13:43:14,122 - Task:Scrapy_bills - INFO - The work on page300 has finished.
2017-08-29 13:43:35,342 - Task:Scrapy_bills - INFO - The work on page290 has finished.
2017-08-29 13:45:32,444 - Task:Scrapy_bills - INFO - The work on page301 has finished.
2017-08-29 13:47:40,566 - Task:Scrapy_bills - INFO - The work on page291 has finished.
2017-08-29 13:48:37,489 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:48:37,491 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 13:48:52,943 - Task:Scrapy_bills - INFO - The work on page303 has finished.
2017-08-29 13:49:21,481 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:49:21,482 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 522: Origin Connection Time-out

2017-08-29 13:49:37,477 - Task:Scrapy_bills - INFO - The work on page293 has finished.
2017-08-29 13:53:21,573 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 13:53:21,574 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 13:53:23,187 - Task:Scrapy_bills - INFO - The work on page304 has finished.
2017-08-29 13:53:37,439 - Task:Scrapy_bills - INFO - The work on page295 has finished.
2017-08-29 13:57:43,081 - Task:Scrapy_bills - INFO - The work on page296 has finished.
2017-08-29 13:57:53,238 - Task:Scrapy_bills - INFO - The work on page305 has finished.
2017-08-29 14:01:42,580 - Task:Scrapy_bills - INFO - The work on page297 has finished.
2017-08-29 14:02:22,092 - Task:Scrapy_bills - INFO - The work on page306 has finished.
2017-08-29 14:05:44,372 - Task:Scrapy_bills - INFO - The work on page298 has finished.
2017-08-29 14:06:51,934 - Task:Scrapy_bills - INFO - The work on page307 has finished.
2017-08-29 14:09:46,305 - Task:Scrapy_bills - INFO - The work on page299 has finished.
2017-08-29 14:09:47,134 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation291-300.json
2017-08-29 14:11:21,997 - Task:Scrapy_bills - INFO - The work on page308 has finished.
2017-08-29 14:13:46,936 - Task:Scrapy_bills - INFO - The work on page300 has finished.
2017-08-29 14:15:52,355 - Task:Scrapy_bills - INFO - The work on page309 has finished.
2017-08-29 14:15:53,324 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation301-310.json
2017-08-29 14:17:48,991 - Task:Scrapy_bills - INFO - The work on page301 has finished.
2017-08-29 14:20:25,493 - Task:Scrapy_bills - INFO - The work on page310 has finished.
2017-08-29 14:21:52,263 - Task:Scrapy_bills - INFO - The work on page302 has finished.
2017-08-29 14:24:33,118 - Task:Scrapy_bills - INFO - The work on page311 has finished.
2017-08-29 14:25:37,954 - Task:Scrapy_bills - INFO - The work on page312 has finished.
2017-08-29 14:25:48,105 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 14:25:48,107 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 14:26:03,560 - Task:Scrapy_bills - INFO - The work on page304 has finished.
2017-08-29 14:29:33,375 - Task:Scrapy_bills - INFO - The work on page313 has finished.
2017-08-29 14:30:04,052 - Task:Scrapy_bills - INFO - The work on page305 has finished.
2017-08-29 14:33:45,279 - Task:Scrapy_bills - INFO - The work on page314 has finished.
2017-08-29 14:34:01,835 - Task:Scrapy_bills - INFO - The work on page306 has finished.
2017-08-29 14:37:59,387 - Task:Scrapy_bills - INFO - The work on page315 has finished.
2017-08-29 14:38:02,997 - Task:Scrapy_bills - INFO - The work on page307 has finished.
2017-08-29 14:38:52,386 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 14:38:52,388 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 14:39:08,735 - Task:Scrapy_bills - INFO - The work on page317 has finished.
2017-08-29 14:42:01,999 - Task:Scrapy_bills - INFO - The work on page308 has finished.
2017-08-29 14:43:32,066 - Task:Scrapy_bills - INFO - The work on page318 has finished.
2017-08-29 14:46:03,254 - Task:Scrapy_bills - INFO - The work on page309 has finished.
2017-08-29 14:46:04,210 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation301-310.json
2017-08-29 14:46:40,113 - Task:Scrapy_bills - INFO - The work on page319 has finished.
2017-08-29 14:46:40,997 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation311-320.json
2017-08-29 14:49:13,525 - Task:Scrapy_bills - INFO - The work on page320 has finished.
2017-08-29 14:50:02,943 - Task:Scrapy_bills - INFO - The work on page310 has finished.
2017-08-29 14:51:15,244 - Task:Scrapy_bills - INFO - The work on page321 has finished.
2017-08-29 14:54:06,915 - Task:Scrapy_bills - INFO - The work on page311 has finished.
2017-08-29 14:55:21,459 - Task:Scrapy_bills - INFO - The work on page322 has finished.
2017-08-29 14:58:06,691 - Task:Scrapy_bills - INFO - The work on page312 has finished.
2017-08-29 14:59:26,037 - Task:Scrapy_bills - INFO - The work on page323 has finished.
2017-08-29 15:02:06,683 - Task:Scrapy_bills - INFO - The work on page313 has finished.
2017-08-29 15:03:46,798 - Task:Scrapy_bills - INFO - The work on page324 has finished.
2017-08-29 15:06:02,279 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 15:06:02,282 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 15:06:11,148 - Task:Scrapy_bills - INFO - The work on page314 has finished.
2017-08-29 15:06:19,064 - Task:Scrapy_bills - INFO - The work on page326 has finished.
2017-08-29 15:10:10,063 - Task:Scrapy_bills - INFO - The work on page315 has finished.
2017-08-29 15:10:53,421 - Task:Scrapy_bills - INFO - The work on page327 has finished.
2017-08-29 15:14:07,702 - Task:Scrapy_bills - INFO - The work on page316 has finished.
2017-08-29 15:15:20,101 - Task:Scrapy_bills - INFO - The work on page328 has finished.
2017-08-29 15:18:13,647 - Task:Scrapy_bills - INFO - The work on page329 has finished.
2017-08-29 15:18:14,206 - Task:Scrapy_bills - INFO - The work on page317 has finished.
2017-08-29 15:18:14,502 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation321-330.json
2017-08-29 15:20:01,908 - Task:Scrapy_bills - INFO - The work on page330 has finished.
2017-08-29 15:22:13,305 - Task:Scrapy_bills - INFO - The work on page318 has finished.
2017-08-29 15:24:11,918 - Task:Scrapy_bills - INFO - The work on page331 has finished.
2017-08-29 15:24:57,564 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 15:24:57,566 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 503: Service Unavailable

2017-08-29 15:25:12,911 - Task:Scrapy_bills - INFO - The work on page333 has finished.
2017-08-29 15:26:05,864 - Task:Scrapy_bills - INFO - The work on page319 has finished.
2017-08-29 15:26:06,867 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation311-320.json
2017-08-29 15:29:34,160 - Task:Scrapy_bills - INFO - The work on page334 has finished.
2017-08-29 15:29:46,993 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 15:29:46,993 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-29 15:30:02,634 - Task:Scrapy_bills - INFO - The work on page321 has finished.
2017-08-29 15:30:07,107 - Task:Scrapy_bills - INFO - The work on page322 has finished.
2017-08-29 15:31:26,949 - Task:Scrapy_bills - INFO - The work on page323 has finished.
2017-08-29 15:34:01,191 - Task:Scrapy_bills - INFO - The work on page335 has finished.
2017-08-29 15:35:17,802 - Task:Scrapy_bills - INFO - The work on page324 has finished.
2017-08-29 15:36:52,227 - Task:Scrapy_bills - INFO - The work on page336 has finished.
2017-08-29 15:38:15,015 - Task:Scrapy_bills - INFO - The work on page337 has finished.
2017-08-29 15:39:07,356 - Task:Scrapy_bills - INFO - The work on page325 has finished.
2017-08-29 15:42:09,291 - Task:Scrapy_bills - INFO - The work on page338 has finished.
2017-08-29 15:42:55,225 - Task:Scrapy_bills - INFO - The work on page326 has finished.
2017-08-29 15:46:18,088 - Task:Scrapy_bills - INFO - The work on page339 has finished.
2017-08-29 15:46:18,891 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation331-340.json
2017-08-29 15:46:47,969 - Task:Scrapy_bills - INFO - The work on page327 has finished.
2017-08-29 15:50:22,395 - Task:Scrapy_bills - INFO - The work on page340 has finished.
2017-08-29 15:50:35,577 - Task:Scrapy_bills - INFO - The work on page328 has finished.
2017-08-29 15:54:24,897 - Task:Scrapy_bills - INFO - The work on page329 has finished.
2017-08-29 15:54:25,734 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation321-330.json
2017-08-29 15:54:36,478 - Task:Scrapy_bills - INFO - The work on page341 has finished.
2017-08-29 15:58:15,936 - Task:Scrapy_bills - INFO - The work on page330 has finished.
2017-08-29 15:58:53,620 - Task:Scrapy_bills - INFO - The work on page342 has finished.
2017-08-29 16:01:48,672 - Task:Scrapy_bills - INFO - The work on page331 has finished.
2017-08-29 16:03:10,560 - Task:Scrapy_bills - INFO - The work on page343 has finished.
2017-08-29 16:05:04,275 - Task:Scrapy_bills - INFO - The work on page332 has finished.
2017-08-29 16:07:30,335 - Task:Scrapy_bills - INFO - The work on page344 has finished.
2017-08-29 16:08:19,036 - Task:Scrapy_bills - INFO - The work on page333 has finished.
2017-08-29 16:11:33,943 - Task:Scrapy_bills - INFO - The work on page334 has finished.
2017-08-29 16:11:45,871 - Task:Scrapy_bills - INFO - The work on page345 has finished.
2017-08-29 16:14:46,684 - Task:Scrapy_bills - INFO - The work on page335 has finished.
2017-08-29 16:16:00,495 - Task:Scrapy_bills - INFO - The work on page346 has finished.
2017-08-29 16:18:00,317 - Task:Scrapy_bills - INFO - The work on page336 has finished.
2017-08-29 16:20:04,910 - Task:Scrapy_bills - INFO - The work on page347 has finished.
2017-08-29 16:21:15,990 - Task:Scrapy_bills - INFO - The work on page337 has finished.
2017-08-29 16:23:53,283 - Task:Scrapy_bills - INFO - The work on page348 has finished.
2017-08-29 16:24:28,877 - Task:Scrapy_bills - INFO - The work on page349 has finished.
2017-08-29 16:24:29,856 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation341-350.json
2017-08-29 16:24:32,382 - Task:Scrapy_bills - INFO - The work on page338 has finished.
2017-08-29 16:27:48,106 - Task:Scrapy_bills - INFO - The work on page339 has finished.
2017-08-29 16:27:48,906 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation331-340.json
2017-08-29 16:28:35,093 - Task:Scrapy_bills - INFO - The work on page350 has finished.
2017-08-29 16:31:02,089 - Task:Scrapy_bills - INFO - The work on page340 has finished.
2017-08-29 16:32:47,205 - Task:Scrapy_bills - INFO - The work on page351 has finished.
2017-08-29 16:34:16,691 - Task:Scrapy_bills - INFO - The work on page341 has finished.
2017-08-29 16:37:02,661 - Task:Scrapy_bills - INFO - The work on page352 has finished.
2017-08-29 16:37:30,280 - Task:Scrapy_bills - INFO - The work on page342 has finished.
2017-08-29 16:41:20,450 - Task:Scrapy_bills - INFO - The work on page353 has finished.
2017-08-29 16:41:20,757 - Task:Scrapy_bills - INFO - The work on page343 has finished.
2017-08-29 16:45:06,815 - Task:Scrapy_bills - INFO - The work on page344 has finished.
2017-08-29 16:45:29,449 - Task:Scrapy_bills - INFO - The work on page354 has finished.
2017-08-29 16:48:56,096 - Task:Scrapy_bills - INFO - The work on page345 has finished.
2017-08-29 16:49:42,158 - Task:Scrapy_bills - INFO - The work on page355 has finished.
2017-08-29 16:52:41,036 - Task:Scrapy_bills - INFO - The work on page346 has finished.
2017-08-29 16:53:56,347 - Task:Scrapy_bills - INFO - The work on page356 has finished.
2017-08-29 16:56:31,256 - Task:Scrapy_bills - INFO - The work on page347 has finished.
2017-08-29 16:58:11,977 - Task:Scrapy_bills - INFO - The work on page357 has finished.
2017-08-29 17:00:21,244 - Task:Scrapy_bills - INFO - The work on page348 has finished.
2017-08-29 17:01:29,573 - Task:Scrapy_bills - INFO - The work on page358 has finished.
2017-08-29 17:03:05,094 - Task:Scrapy_bills - INFO - The work on page359 has finished.
2017-08-29 17:03:06,016 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation351-360.json
2017-08-29 17:04:06,325 - Task:Scrapy_bills - INFO - The work on page349 has finished.
2017-08-29 17:04:07,210 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation341-350.json
2017-08-29 17:07:18,183 - Task:Scrapy_bills - INFO - The work on page360 has finished.
2017-08-29 17:07:57,804 - Task:Scrapy_bills - INFO - The work on page350 has finished.
2017-08-29 17:11:24,541 - Task:Scrapy_bills - INFO - The work on page361 has finished.
2017-08-29 17:11:50,593 - Task:Scrapy_bills - INFO - The work on page351 has finished.
2017-08-29 17:15:29,571 - Task:Scrapy_bills - INFO - The work on page362 has finished.
2017-08-29 17:15:35,565 - Task:Scrapy_bills - INFO - The work on page352 has finished.
2017-08-29 17:19:23,221 - Task:Scrapy_bills - INFO - The work on page353 has finished.
2017-08-29 17:19:36,772 - Task:Scrapy_bills - INFO - The work on page363 has finished.
2017-08-29 17:23:10,837 - Task:Scrapy_bills - INFO - The work on page354 has finished.
2017-08-29 17:23:40,177 - Task:Scrapy_bills - INFO - The work on page364 has finished.
2017-08-29 17:26:57,692 - Task:Scrapy_bills - INFO - The work on page355 has finished.
2017-08-29 17:27:45,433 - Task:Scrapy_bills - INFO - The work on page365 has finished.
2017-08-29 17:30:45,785 - Task:Scrapy_bills - INFO - The work on page356 has finished.
2017-08-29 17:31:51,224 - Task:Scrapy_bills - INFO - The work on page366 has finished.
2017-08-29 17:34:35,211 - Task:Scrapy_bills - INFO - The work on page357 has finished.
2017-08-29 17:36:02,341 - Task:Scrapy_bills - INFO - The work on page367 has finished.
2017-08-29 17:38:27,265 - Task:Scrapy_bills - INFO - The work on page358 has finished.
2017-08-29 17:40:12,803 - Task:Scrapy_bills - INFO - The work on page368 has finished.
2017-08-29 17:42:20,965 - Task:Scrapy_bills - INFO - The work on page359 has finished.
2017-08-29 17:42:21,899 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation351-360.json
2017-08-29 17:44:20,218 - Task:Scrapy_bills - INFO - The work on page369 has finished.
2017-08-29 17:44:21,136 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation361-370.json
2017-08-29 17:46:12,684 - Task:Scrapy_bills - INFO - The work on page360 has finished.
2017-08-29 17:46:14,436 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:14,439 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:16,487 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:16,488 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:25,637 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:25,639 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:27,681 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:27,683 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 42, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:36,841 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:36,843 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:38,676 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:38,678 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 42, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:48,039 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:48,040 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:46:49,865 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:46:49,867 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 42, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 472, in open
    response = meth(req, response)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 582, in http_response
    'http', request, response, code, msg, hdrs)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 510, in error
    return self._call_chain(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 590, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 429: Too many requests from 0.0.0.0, please try again later.

2017-08-29 17:47:06,153 - Task:Scrapy_bills - INFO - The work on page371 has finished.
2017-08-29 17:48:12,613 - Task:Scrapy_bills - INFO - The work on page372 has finished.
2017-08-29 17:50:50,210 - Task:Scrapy_bills - INFO - The work on page361 has finished.
2017-08-29 17:51:24,047 - Task:Scrapy_bills - INFO - The work on page373 has finished.
2017-08-29 17:54:44,019 - Task:Scrapy_bills - INFO - The work on page362 has finished.
2017-08-29 17:55:19,010 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 17:55:19,012 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 17:55:28,529 - Task:Scrapy_bills - INFO - The work on page374 has finished.
2017-08-29 17:59:19,490 - Task:Scrapy_bills - INFO - The work on page363 has finished.
2017-08-29 17:59:30,650 - Task:Scrapy_bills - INFO - The work on page375 has finished.
2017-08-29 18:03:12,105 - Task:Scrapy_bills - INFO - The work on page364 has finished.
2017-08-29 18:03:32,331 - Task:Scrapy_bills - INFO - The work on page376 has finished.
2017-08-29 18:07:06,022 - Task:Scrapy_bills - INFO - The work on page365 has finished.
2017-08-29 18:07:36,571 - Task:Scrapy_bills - INFO - The work on page377 has finished.
2017-08-29 18:11:00,236 - Task:Scrapy_bills - INFO - The work on page366 has finished.
2017-08-29 18:11:43,077 - Task:Scrapy_bills - INFO - The work on page378 has finished.
2017-08-29 18:15:03,364 - Task:Scrapy_bills - INFO - The work on page367 has finished.
2017-08-29 18:15:53,385 - Task:Scrapy_bills - INFO - The work on page379 has finished.
2017-08-29 18:15:54,214 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation371-380.json
2017-08-29 18:19:05,756 - Task:Scrapy_bills - INFO - The work on page368 has finished.
2017-08-29 18:20:07,019 - Task:Scrapy_bills - INFO - The work on page380 has finished.
2017-08-29 18:21:12,956 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 18:21:12,959 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 18:21:30,661 - Task:Scrapy_bills - INFO - The work on page382 has finished.
2017-08-29 18:23:06,895 - Task:Scrapy_bills - INFO - The work on page369 has finished.
2017-08-29 18:23:07,840 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation361-370.json
2017-08-29 18:23:45,445 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 18:23:45,447 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 18:24:07,966 - Task:Scrapy_bills - INFO - The work on page383 has finished.
2017-08-29 18:27:57,679 - Task:Scrapy_bills - INFO - The work on page370 has finished.
2017-08-29 18:28:10,030 - Task:Scrapy_bills - INFO - The work on page384 has finished.
2017-08-29 18:31:53,949 - Task:Scrapy_bills - INFO - The work on page371 has finished.
2017-08-29 18:32:15,901 - Task:Scrapy_bills - INFO - The work on page385 has finished.
2017-08-29 18:35:56,188 - Task:Scrapy_bills - INFO - The work on page372 has finished.
2017-08-29 18:36:26,101 - Task:Scrapy_bills - INFO - The work on page386 has finished.
2017-08-29 18:37:11,076 - Task:Scrapy_bills - INFO - The work on page373 has finished.
2017-08-29 18:40:27,381 - Task:Scrapy_bills - INFO - The work on page374 has finished.
2017-08-29 18:40:34,890 - Task:Scrapy_bills - INFO - The work on page387 has finished.
2017-08-29 18:44:31,564 - Task:Scrapy_bills - INFO - The work on page375 has finished.
2017-08-29 18:44:58,891 - Task:Scrapy_bills - INFO - The work on page388 has finished.
2017-08-29 18:48:23,252 - Task:Scrapy_bills - INFO - The work on page376 has finished.
2017-08-29 18:49:07,631 - Task:Scrapy_bills - INFO - The work on page389 has finished.
2017-08-29 18:49:08,453 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation381-390.json
2017-08-29 18:52:11,034 - Task:Scrapy_bills - INFO - The work on page377 has finished.
2017-08-29 18:53:23,931 - Task:Scrapy_bills - INFO - The work on page390 has finished.
2017-08-29 18:55:59,877 - Task:Scrapy_bills - INFO - The work on page378 has finished.
2017-08-29 18:58:04,848 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 18:58:04,849 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 18:58:22,488 - Task:Scrapy_bills - INFO - The work on page392 has finished.
2017-08-29 19:00:06,787 - Task:Scrapy_bills - INFO - The work on page379 has finished.
2017-08-29 19:00:07,689 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation371-380.json
2017-08-29 19:02:53,111 - Task:Scrapy_bills - INFO - The work on page393 has finished.
2017-08-29 19:03:57,901 - Task:Scrapy_bills - INFO - The work on page380 has finished.
2017-08-29 19:07:17,625 - Task:Scrapy_bills - INFO - The work on page394 has finished.
2017-08-29 19:07:56,140 - Task:Scrapy_bills - INFO - The work on page381 has finished.
2017-08-29 19:09:30,616 - Task:Scrapy_bills - INFO - The work on page395 has finished.
2017-08-29 19:11:44,229 - Task:Scrapy_bills - INFO - The work on page382 has finished.
2017-08-29 19:12:33,701 - Task:Scrapy_bills - INFO - The work on page396 has finished.
2017-08-29 19:15:28,545 - Task:Scrapy_bills - INFO - The work on page383 has finished.
2017-08-29 19:17:14,774 - Task:Scrapy_bills - INFO - The work on page397 has finished.
2017-08-29 19:19:30,110 - Task:Scrapy_bills - INFO - The work on page384 has finished.
2017-08-29 19:21:37,529 - Task:Scrapy_bills - INFO - The work on page398 has finished.
2017-08-29 19:23:03,672 - Task:Scrapy_bills - INFO - The work on page385 has finished.
2017-08-29 19:26:04,961 - Task:Scrapy_bills - INFO - The work on page399 has finished.
2017-08-29 19:26:05,879 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation391-400.json
2017-08-29 19:26:42,725 - Task:Scrapy_bills - INFO - The work on page386 has finished.
2017-08-29 19:30:05,344 - Task:Scrapy_bills - INFO - The work on page387 has finished.
2017-08-29 19:30:11,786 - Task:Scrapy_bills - INFO - The work on page400 has finished.
2017-08-29 19:33:46,350 - Task:Scrapy_bills - INFO - The work on page388 has finished.
2017-08-29 19:34:30,300 - Task:Scrapy_bills - INFO - The work on page401 has finished.
2017-08-29 19:37:17,245 - Task:Scrapy_bills - INFO - The work on page389 has finished.
2017-08-29 19:37:18,067 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation381-390.json
2017-08-29 19:38:49,145 - Task:Scrapy_bills - INFO - The work on page402 has finished.
2017-08-29 19:40:49,690 - Task:Scrapy_bills - INFO - The work on page390 has finished.
2017-08-29 19:43:17,805 - Task:Scrapy_bills - INFO - The work on page403 has finished.
2017-08-29 19:44:28,246 - Task:Scrapy_bills - INFO - The work on page391 has finished.
2017-08-29 19:47:29,576 - Task:Scrapy_bills - INFO - The work on page404 has finished.
2017-08-29 19:47:54,119 - Task:Scrapy_bills - INFO - The work on page392 has finished.
2017-08-29 19:51:15,645 - Task:Scrapy_bills - INFO - The work on page393 has finished.
2017-08-29 19:51:33,807 - Task:Scrapy_bills - INFO - The work on page405 has finished.
2017-08-29 19:53:24,042 - Task:Scrapy_bills - INFO - The work on page406 has finished.
2017-08-29 19:54:39,038 - Task:Scrapy_bills - INFO - The work on page394 has finished.
2017-08-29 19:55:28,562 - Task:Scrapy_bills - INFO - The work on page407 has finished.
2017-08-29 19:57:56,774 - Task:Scrapy_bills - INFO - The work on page395 has finished.
2017-08-29 19:59:28,893 - Task:Scrapy_bills - INFO - The work on page408 has finished.
2017-08-29 20:01:19,937 - Task:Scrapy_bills - INFO - The work on page396 has finished.
2017-08-29 20:03:29,288 - Task:Scrapy_bills - INFO - The work on page409 has finished.
2017-08-29 20:03:30,203 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation401-410.json
2017-08-29 20:04:41,254 - Task:Scrapy_bills - INFO - The work on page397 has finished.
2017-08-29 20:07:27,967 - Task:Scrapy_bills - INFO - The work on page410 has finished.
2017-08-29 20:08:04,301 - Task:Scrapy_bills - INFO - The work on page398 has finished.
2017-08-29 20:11:29,781 - Task:Scrapy_bills - INFO - The work on page399 has finished.
2017-08-29 20:11:30,569 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation391-400.json
2017-08-29 20:11:32,974 - Task:Scrapy_bills - INFO - The work on page411 has finished.
2017-08-29 20:14:52,845 - Task:Scrapy_bills - INFO - The work on page400 has finished.
2017-08-29 20:15:39,882 - Task:Scrapy_bills - INFO - The work on page412 has finished.
2017-08-29 20:18:31,948 - Task:Scrapy_bills - INFO - The work on page401 has finished.
2017-08-29 20:20:02,260 - Task:Scrapy_bills - INFO - The work on page413 has finished.
2017-08-29 20:22:07,386 - Task:Scrapy_bills - INFO - The work on page402 has finished.
2017-08-29 20:24:22,971 - Task:Scrapy_bills - INFO - The work on page414 has finished.
2017-08-29 20:25:50,007 - Task:Scrapy_bills - INFO - The work on page403 has finished.
2017-08-29 20:28:39,469 - Task:Scrapy_bills - INFO - The work on page415 has finished.
2017-08-29 20:29:18,232 - Task:Scrapy_bills - INFO - The work on page404 has finished.
2017-08-29 20:33:08,538 - Task:Scrapy_bills - INFO - The work on page405 has finished.
2017-08-29 20:33:20,320 - Task:Scrapy_bills - INFO - The work on page416 has finished.
2017-08-29 20:36:36,288 - Task:Scrapy_bills - INFO - The work on page406 has finished.
2017-08-29 20:37:28,748 - Task:Scrapy_bills - INFO - The work on page417 has finished.
2017-08-29 20:40:02,410 - Task:Scrapy_bills - INFO - The work on page418 has finished.
2017-08-29 20:40:15,762 - Task:Scrapy_bills - INFO - The work on page407 has finished.
2017-08-29 20:41:52,294 - Task:Scrapy_bills - INFO - The work on page419 has finished.
2017-08-29 20:41:53,187 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation411-420.json
2017-08-29 20:43:44,172 - Task:Scrapy_bills - INFO - The work on page408 has finished.
2017-08-29 20:46:03,895 - Task:Scrapy_bills - INFO - The work on page420 has finished.
2017-08-29 20:47:10,331 - Task:Scrapy_bills - INFO - The work on page409 has finished.
2017-08-29 20:47:11,113 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation401-410.json
2017-08-29 20:50:09,768 - Task:Scrapy_bills - INFO - The work on page421 has finished.
2017-08-29 20:50:37,385 - Task:Scrapy_bills - INFO - The work on page410 has finished.
2017-08-29 20:52:43,238 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 20:52:43,239 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-4df6c41e3088>", line 48, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 20:53:00,474 - Task:Scrapy_bills - INFO - The work on page423 has finished.
2017-08-29 20:53:57,322 - Task:Scrapy_bills - INFO - The work on page411 has finished.
2017-08-29 20:56:57,875 - Task:Scrapy_bills - INFO - The work on page424 has finished.
2017-08-29 20:57:16,019 - Task:Scrapy_bills - INFO - The work on page412 has finished.
2017-08-29 21:00:34,557 - Task:Scrapy_bills - INFO - The work on page413 has finished.
2017-08-29 21:00:58,504 - Task:Scrapy_bills - INFO - The work on page425 has finished.
2017-08-29 21:04:17,899 - Task:Scrapy_bills - INFO - The work on page414 has finished.
2017-08-29 21:05:20,501 - Task:Scrapy_bills - INFO - The work on page426 has finished.
2017-08-29 21:07:41,950 - Task:Scrapy_bills - INFO - The work on page415 has finished.
2017-08-29 21:09:25,860 - Task:Scrapy_bills - INFO - The work on page427 has finished.
2017-08-29 21:11:06,202 - Task:Scrapy_bills - INFO - The work on page416 has finished.
2017-08-29 21:13:32,858 - Task:Scrapy_bills - INFO - The work on page428 has finished.
2017-08-29 21:14:31,010 - Task:Scrapy_bills - INFO - The work on page417 has finished.
2017-08-29 21:16:56,220 - Task:Scrapy_bills - INFO - The work on page429 has finished.
2017-08-29 21:16:57,063 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation421-430.json
2017-08-29 21:17:54,105 - Task:Scrapy_bills - INFO - The work on page418 has finished.
2017-08-29 21:18:03,586 - Task:Scrapy_bills - INFO - The work on page430 has finished.
2017-08-29 21:21:19,290 - Task:Scrapy_bills - INFO - The work on page419 has finished.
2017-08-29 21:21:20,102 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation411-420.json
2017-08-29 21:22:02,415 - Task:Scrapy_bills - INFO - The work on page431 has finished.
2017-08-29 21:24:46,306 - Task:Scrapy_bills - INFO - The work on page420 has finished.
2017-08-29 21:25:49,041 - Task:Scrapy_bills - INFO - The work on page432 has finished.
2017-08-29 21:28:33,099 - Task:Scrapy_bills - INFO - The work on page421 has finished.
2017-08-29 21:29:33,407 - Task:Scrapy_bills - INFO - The work on page433 has finished.
2017-08-29 21:29:45,081 - Task:Scrapy_bills - INFO - The work on page434 has finished.
2017-08-29 21:29:50,160 - Task:Scrapy_bills - INFO - The work on page436 has finished.
2017-08-29 21:29:55,205 - Task:Scrapy_bills - INFO - The work on page438 has finished.
2017-08-29 21:30:00,234 - Task:Scrapy_bills - INFO - The work on page440 has finished.
2017-08-29 21:30:00,875 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_small/legislation431-440.json
2017-08-29 21:32:38,093 - Task:Scrapy_bills - INFO - The work on page422 has finished.
2017-08-29 21:36:34,689 - Task:Scrapy_bills - INFO - The work on page423 has finished.
2017-08-29 21:40:29,427 - Task:Scrapy_bills - INFO - The work on page424 has finished.
2017-08-29 21:44:25,936 - Task:Scrapy_bills - INFO - The work on page425 has finished.
2017-08-29 21:48:27,341 - Task:Scrapy_bills - INFO - The work on page426 has finished.
2017-08-29 21:52:31,601 - Task:Scrapy_bills - INFO - The work on page427 has finished.
2017-08-29 21:56:21,996 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-29 21:56:21,996 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-362cdb56df5d>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-29 21:56:46,103 - Task:Scrapy_bills - INFO - The work on page429 has finished.
2017-08-29 21:56:46,935 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation421-430.json
2017-08-31 12:26:51,496 - Task:Scrapy_bills - INFO - The number of the search result is:403660
2017-08-31 12:30:44,886 - Task:Scrapy_bills - INFO - The work on page430 has finished.
2017-08-31 12:34:38,237 - Task:Scrapy_bills - INFO - The work on page431 has finished.
2017-08-31 12:38:24,823 - Task:Scrapy_bills - INFO - The work on page432 has finished.
2017-08-31 12:42:13,540 - Task:Scrapy_bills - INFO - The work on page433 has finished.
2017-08-31 12:45:59,499 - Task:Scrapy_bills - INFO - The work on page434 has finished.
2017-08-31 12:49:50,249 - Task:Scrapy_bills - INFO - The work on page435 has finished.
2017-08-31 12:53:43,755 - Task:Scrapy_bills - INFO - The work on page436 has finished.
2017-08-31 12:57:38,028 - Task:Scrapy_bills - INFO - The work on page437 has finished.
2017-08-31 13:01:27,122 - Task:Scrapy_bills - INFO - The work on page438 has finished.
2017-08-31 13:05:13,400 - Task:Scrapy_bills - INFO - The work on page439 has finished.
2017-08-31 13:05:14,313 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation431-440.json
2017-08-31 13:09:16,797 - Task:Scrapy_bills - INFO - The work on page440 has finished.
2017-08-31 13:13:25,009 - Task:Scrapy_bills - INFO - The work on page441 has finished.
2017-08-31 13:17:38,514 - Task:Scrapy_bills - INFO - The work on page442 has finished.
2017-08-31 13:21:47,656 - Task:Scrapy_bills - INFO - The work on page443 has finished.
2017-08-31 13:26:01,339 - Task:Scrapy_bills - INFO - The work on page444 has finished.
2017-08-31 13:30:25,399 - Task:Scrapy_bills - INFO - The work on page445 has finished.
2017-08-31 13:34:41,914 - Task:Scrapy_bills - INFO - The work on page446 has finished.
2017-08-31 13:38:55,874 - Task:Scrapy_bills - INFO - The work on page447 has finished.
2017-08-31 13:43:05,883 - Task:Scrapy_bills - INFO - The work on page448 has finished.
2017-08-31 13:47:04,462 - Task:Scrapy_bills - INFO - The work on page449 has finished.
2017-08-31 13:47:05,443 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation441-450.json
2017-08-31 13:51:14,679 - Task:Scrapy_bills - INFO - The work on page450 has finished.
2017-08-31 13:55:12,689 - Task:Scrapy_bills - INFO - The work on page451 has finished.
2017-08-31 13:59:17,491 - Task:Scrapy_bills - INFO - The work on page452 has finished.
2017-08-31 14:03:19,155 - Task:Scrapy_bills - INFO - The work on page453 has finished.
2017-08-31 14:07:16,940 - Task:Scrapy_bills - INFO - The work on page454 has finished.
2017-08-31 14:11:13,410 - Task:Scrapy_bills - INFO - The work on page455 has finished.
2017-08-31 14:15:13,695 - Task:Scrapy_bills - INFO - The work on page456 has finished.
2017-08-31 14:19:09,378 - Task:Scrapy_bills - INFO - The work on page457 has finished.
2017-08-31 14:23:10,038 - Task:Scrapy_bills - INFO - The work on page458 has finished.
2017-08-31 14:27:06,806 - Task:Scrapy_bills - INFO - The work on page459 has finished.
2017-08-31 14:27:07,783 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation451-460.json
2017-08-31 14:31:06,848 - Task:Scrapy_bills - INFO - The work on page460 has finished.
2017-08-31 14:35:06,039 - Task:Scrapy_bills - INFO - The work on page461 has finished.
2017-08-31 14:39:08,808 - Task:Scrapy_bills - INFO - The work on page462 has finished.
2017-08-31 14:43:08,571 - Task:Scrapy_bills - INFO - The work on page463 has finished.
2017-08-31 14:47:09,239 - Task:Scrapy_bills - INFO - The work on page464 has finished.
2017-08-31 14:51:10,661 - Task:Scrapy_bills - INFO - The work on page465 has finished.
2017-08-31 14:55:08,119 - Task:Scrapy_bills - INFO - The work on page466 has finished.
2017-08-31 14:59:09,542 - Task:Scrapy_bills - INFO - The work on page467 has finished.
2017-08-31 15:03:14,153 - Task:Scrapy_bills - INFO - The work on page468 has finished.
2017-08-31 15:07:34,819 - Task:Scrapy_bills - INFO - The work on page469 has finished.
2017-08-31 15:07:35,812 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation461-470.json
2017-08-31 15:11:44,325 - Task:Scrapy_bills - INFO - The work on page470 has finished.
2017-08-31 15:15:42,315 - Task:Scrapy_bills - INFO - The work on page471 has finished.
2017-08-31 15:19:40,296 - Task:Scrapy_bills - INFO - The work on page472 has finished.
2017-08-31 15:23:43,232 - Task:Scrapy_bills - INFO - The work on page473 has finished.
2017-08-31 15:27:46,275 - Task:Scrapy_bills - INFO - The work on page474 has finished.
2017-08-31 15:31:46,501 - Task:Scrapy_bills - INFO - The work on page475 has finished.
2017-08-31 15:35:53,431 - Task:Scrapy_bills - INFO - The work on page476 has finished.
2017-08-31 15:39:52,012 - Task:Scrapy_bills - INFO - The work on page477 has finished.
2017-08-31 15:43:54,935 - Task:Scrapy_bills - INFO - The work on page478 has finished.
2017-08-31 15:47:53,711 - Task:Scrapy_bills - INFO - The work on page479 has finished.
2017-08-31 15:47:54,701 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation471-480.json
2017-08-31 15:52:02,757 - Task:Scrapy_bills - INFO - The work on page480 has finished.
2017-08-31 15:56:04,192 - Task:Scrapy_bills - INFO - The work on page481 has finished.
2017-08-31 16:00:14,228 - Task:Scrapy_bills - INFO - The work on page482 has finished.
2017-08-31 16:04:09,131 - Task:Scrapy_bills - INFO - The work on page483 has finished.
2017-08-31 16:08:10,317 - Task:Scrapy_bills - INFO - The work on page484 has finished.
2017-08-31 16:12:08,962 - Task:Scrapy_bills - INFO - The work on page485 has finished.
2017-08-31 16:16:07,732 - Task:Scrapy_bills - INFO - The work on page486 has finished.
2017-08-31 16:20:16,170 - Task:Scrapy_bills - INFO - The work on page487 has finished.
2017-08-31 16:22:26,573 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-31 16:22:26,573 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-08-31 16:22:42,378 - Task:Scrapy_bills - INFO - The work on page489 has finished.
2017-08-31 16:22:43,301 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation481-490.json
2017-08-31 16:22:51,751 - Task:Scrapy_bills - INFO - The work on page490 has finished.
2017-08-31 16:25:03,555 - Task:Scrapy_bills - INFO - The work on page491 has finished.
2017-08-31 16:28:55,254 - Task:Scrapy_bills - INFO - The work on page492 has finished.
2017-08-31 16:32:40,850 - Task:Scrapy_bills - INFO - The work on page493 has finished.
2017-08-31 16:36:33,671 - Task:Scrapy_bills - INFO - The work on page494 has finished.
2017-08-31 16:40:24,051 - Task:Scrapy_bills - INFO - The work on page495 has finished.
2017-08-31 16:44:15,867 - Task:Scrapy_bills - INFO - The work on page496 has finished.
2017-08-31 16:48:04,825 - Task:Scrapy_bills - INFO - The work on page497 has finished.
2017-08-31 16:51:52,525 - Task:Scrapy_bills - INFO - The work on page498 has finished.
2017-08-31 16:55:39,135 - Task:Scrapy_bills - INFO - The work on page499 has finished.
2017-08-31 16:55:40,014 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation491-500.json
2017-08-31 16:58:57,063 - Task:Scrapy_bills - INFO - The work on page500 has finished.
2017-08-31 17:02:09,339 - Task:Scrapy_bills - INFO - The work on page501 has finished.
2017-08-31 17:05:23,379 - Task:Scrapy_bills - INFO - The work on page502 has finished.
2017-08-31 17:08:37,142 - Task:Scrapy_bills - INFO - The work on page503 has finished.
2017-08-31 17:11:50,414 - Task:Scrapy_bills - INFO - The work on page504 has finished.
2017-08-31 17:15:03,661 - Task:Scrapy_bills - INFO - The work on page505 has finished.
2017-08-31 17:18:17,943 - Task:Scrapy_bills - INFO - The work on page506 has finished.
2017-08-31 17:21:32,695 - Task:Scrapy_bills - INFO - The work on page507 has finished.
2017-08-31 17:24:52,647 - Task:Scrapy_bills - INFO - The work on page508 has finished.
2017-08-31 17:28:14,589 - Task:Scrapy_bills - INFO - The work on page509 has finished.
2017-08-31 17:28:15,373 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation501-510.json
2017-08-31 17:31:32,709 - Task:Scrapy_bills - INFO - The work on page510 has finished.
2017-08-31 17:34:47,675 - Task:Scrapy_bills - INFO - The work on page511 has finished.
2017-08-31 17:38:03,962 - Task:Scrapy_bills - INFO - The work on page512 has finished.
2017-08-31 17:41:19,601 - Task:Scrapy_bills - INFO - The work on page513 has finished.
2017-08-31 17:44:38,620 - Task:Scrapy_bills - INFO - The work on page514 has finished.
2017-08-31 17:48:25,697 - Task:Scrapy_bills - INFO - The work on page515 has finished.
2017-08-31 17:52:15,542 - Task:Scrapy_bills - INFO - The work on page516 has finished.
2017-08-31 17:56:02,810 - Task:Scrapy_bills - INFO - The work on page517 has finished.
2017-08-31 17:59:49,808 - Task:Scrapy_bills - INFO - The work on page518 has finished.
2017-08-31 18:03:40,645 - Task:Scrapy_bills - INFO - The work on page519 has finished.
2017-08-31 18:03:41,544 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation511-520.json
2017-08-31 18:07:23,008 - Task:Scrapy_bills - INFO - The work on page520 has finished.
2017-08-31 18:11:03,311 - Task:Scrapy_bills - INFO - The work on page521 has finished.
2017-08-31 18:14:40,640 - Task:Scrapy_bills - INFO - The work on page522 has finished.
2017-08-31 18:18:18,043 - Task:Scrapy_bills - INFO - The work on page523 has finished.
2017-08-31 18:21:53,414 - Task:Scrapy_bills - INFO - The work on page524 has finished.
2017-08-31 18:25:31,463 - Task:Scrapy_bills - INFO - The work on page525 has finished.
2017-08-31 18:29:09,529 - Task:Scrapy_bills - INFO - The work on page526 has finished.
2017-08-31 18:32:48,791 - Task:Scrapy_bills - INFO - The work on page527 has finished.
2017-08-31 18:36:33,785 - Task:Scrapy_bills - INFO - The work on page528 has finished.
2017-08-31 18:40:23,672 - Task:Scrapy_bills - INFO - The work on page529 has finished.
2017-08-31 18:40:24,582 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation521-530.json
2017-08-31 18:44:15,101 - Task:Scrapy_bills - INFO - The work on page530 has finished.
2017-08-31 18:48:04,551 - Task:Scrapy_bills - INFO - The work on page531 has finished.
2017-08-31 18:51:58,056 - Task:Scrapy_bills - INFO - The work on page532 has finished.
2017-08-31 18:55:51,827 - Task:Scrapy_bills - INFO - The work on page533 has finished.
2017-08-31 18:59:50,774 - Task:Scrapy_bills - INFO - The work on page534 has finished.
2017-08-31 19:04:02,335 - Task:Scrapy_bills - INFO - The work on page535 has finished.
2017-08-31 19:08:15,122 - Task:Scrapy_bills - INFO - The work on page536 has finished.
2017-08-31 19:12:17,765 - Task:Scrapy_bills - INFO - The work on page537 has finished.
2017-08-31 19:16:26,375 - Task:Scrapy_bills - INFO - The work on page538 has finished.
2017-08-31 19:20:29,737 - Task:Scrapy_bills - INFO - The work on page539 has finished.
2017-08-31 19:20:30,715 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation531-540.json
2017-08-31 19:24:23,841 - Task:Scrapy_bills - INFO - The work on page540 has finished.
2017-08-31 19:28:11,919 - Task:Scrapy_bills - INFO - The work on page541 has finished.
2017-08-31 19:32:03,702 - Task:Scrapy_bills - INFO - The work on page542 has finished.
2017-08-31 19:35:54,222 - Task:Scrapy_bills - INFO - The work on page543 has finished.
2017-08-31 19:39:43,477 - Task:Scrapy_bills - INFO - The work on page544 has finished.
2017-08-31 19:43:32,805 - Task:Scrapy_bills - INFO - The work on page545 has finished.
2017-08-31 19:47:18,336 - Task:Scrapy_bills - INFO - The work on page546 has finished.
2017-08-31 19:51:04,430 - Task:Scrapy_bills - INFO - The work on page547 has finished.
2017-08-31 19:54:51,421 - Task:Scrapy_bills - INFO - The work on page548 has finished.
2017-08-31 19:58:41,337 - Task:Scrapy_bills - INFO - The work on page549 has finished.
2017-08-31 19:58:42,291 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation541-550.json
2017-08-31 20:02:28,350 - Task:Scrapy_bills - INFO - The work on page550 has finished.
2017-08-31 20:06:15,811 - Task:Scrapy_bills - INFO - The work on page551 has finished.
2017-08-31 20:06:41,167 - Task:Scrapy_bills - INFO - The work on page552 has finished.
2017-08-31 20:09:48,060 - Task:Scrapy_bills - INFO - The work on page553 has finished.
2017-08-31 20:10:22,557 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-31 20:10:22,560 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-31 20:14:18,197 - Task:Scrapy_bills - INFO - The work on page554 has finished.
2017-08-31 20:18:01,302 - Task:Scrapy_bills - INFO - The work on page555 has finished.
2017-08-31 20:21:47,242 - Task:Scrapy_bills - INFO - The work on page556 has finished.
2017-08-31 20:25:36,306 - Task:Scrapy_bills - INFO - The work on page557 has finished.
2017-08-31 20:29:29,200 - Task:Scrapy_bills - INFO - The work on page558 has finished.
2017-08-31 20:33:33,904 - Task:Scrapy_bills - INFO - The work on page559 has finished.
2017-08-31 20:33:34,798 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation551-560.json
2017-08-31 20:37:08,945 - Task:Scrapy_bills - INFO - The work on page560 has finished.
2017-08-31 20:40:29,213 - Task:Scrapy_bills - INFO - The work on page561 has finished.
2017-08-31 20:43:51,096 - Task:Scrapy_bills - INFO - The work on page562 has finished.
2017-08-31 20:47:41,284 - Task:Scrapy_bills - INFO - The work on page563 has finished.
2017-08-31 20:51:01,641 - Task:Scrapy_bills - INFO - The work on page564 has finished.
2017-08-31 20:54:26,258 - Task:Scrapy_bills - INFO - The work on page565 has finished.
2017-08-31 20:57:48,737 - Task:Scrapy_bills - INFO - The work on page566 has finished.
2017-08-31 21:01:09,805 - Task:Scrapy_bills - INFO - The work on page567 has finished.
2017-08-31 21:04:31,282 - Task:Scrapy_bills - INFO - The work on page568 has finished.
2017-08-31 21:08:01,106 - Task:Scrapy_bills - INFO - The work on page569 has finished.
2017-08-31 21:08:01,884 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation561-570.json
2017-08-31 21:11:32,676 - Task:Scrapy_bills - INFO - The work on page570 has finished.
2017-08-31 21:14:55,954 - Task:Scrapy_bills - INFO - The work on page571 has finished.
2017-08-31 21:18:23,895 - Task:Scrapy_bills - INFO - The work on page572 has finished.
2017-08-31 21:21:49,848 - Task:Scrapy_bills - INFO - The work on page573 has finished.
2017-08-31 21:25:15,278 - Task:Scrapy_bills - INFO - The work on page574 has finished.
2017-08-31 21:28:43,180 - Task:Scrapy_bills - INFO - The work on page575 has finished.
2017-08-31 21:32:04,263 - Task:Scrapy_bills - INFO - The work on page576 has finished.
2017-08-31 21:35:27,683 - Task:Scrapy_bills - INFO - The work on page577 has finished.
2017-08-31 21:38:48,197 - Task:Scrapy_bills - INFO - The work on page578 has finished.
2017-08-31 21:42:09,422 - Task:Scrapy_bills - INFO - The work on page579 has finished.
2017-08-31 21:42:10,198 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation571-580.json
2017-08-31 21:45:30,492 - Task:Scrapy_bills - INFO - The work on page580 has finished.
2017-08-31 21:48:46,655 - Task:Scrapy_bills - INFO - The work on page581 has finished.
2017-08-31 21:52:07,928 - Task:Scrapy_bills - INFO - The work on page582 has finished.
2017-08-31 21:55:25,804 - Task:Scrapy_bills - INFO - The work on page583 has finished.
2017-08-31 21:58:47,787 - Task:Scrapy_bills - INFO - The work on page584 has finished.
2017-08-31 22:02:08,978 - Task:Scrapy_bills - INFO - The work on page585 has finished.
2017-08-31 22:05:31,893 - Task:Scrapy_bills - INFO - The work on page586 has finished.
2017-08-31 22:08:59,339 - Task:Scrapy_bills - INFO - The work on page587 has finished.
2017-08-31 22:12:18,591 - Task:Scrapy_bills - INFO - The work on page588 has finished.
2017-08-31 22:15:35,551 - Task:Scrapy_bills - INFO - The work on page589 has finished.
2017-08-31 22:15:36,326 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation581-590.json
2017-08-31 22:18:57,820 - Task:Scrapy_bills - INFO - The work on page590 has finished.
2017-08-31 22:22:19,208 - Task:Scrapy_bills - INFO - The work on page591 has finished.
2017-08-31 22:25:41,271 - Task:Scrapy_bills - INFO - The work on page592 has finished.
2017-08-31 22:28:58,826 - Task:Scrapy_bills - INFO - The work on page593 has finished.
2017-08-31 22:32:48,114 - Task:Scrapy_bills - INFO - The work on page594 has finished.
2017-08-31 22:36:37,489 - Task:Scrapy_bills - INFO - The work on page595 has finished.
2017-08-31 22:40:20,800 - Task:Scrapy_bills - INFO - The work on page596 has finished.
2017-08-31 22:44:11,467 - Task:Scrapy_bills - INFO - The work on page597 has finished.
2017-08-31 22:48:06,126 - Task:Scrapy_bills - INFO - The work on page598 has finished.
2017-08-31 22:52:03,122 - Task:Scrapy_bills - INFO - The work on page599 has finished.
2017-08-31 22:52:04,008 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation591-600.json
2017-08-31 22:56:01,317 - Task:Scrapy_bills - INFO - The work on page600 has finished.
2017-08-31 22:58:02,510 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-08-31 22:58:02,518 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-08-31 22:58:18,760 - Task:Scrapy_bills - INFO - The work on page602 has finished.
2017-08-31 23:02:17,274 - Task:Scrapy_bills - INFO - The work on page603 has finished.
2017-08-31 23:06:10,960 - Task:Scrapy_bills - INFO - The work on page604 has finished.
2017-08-31 23:10:08,171 - Task:Scrapy_bills - INFO - The work on page605 has finished.
2017-08-31 23:14:05,377 - Task:Scrapy_bills - INFO - The work on page606 has finished.
2017-08-31 23:17:57,170 - Task:Scrapy_bills - INFO - The work on page607 has finished.
2017-08-31 23:22:00,656 - Task:Scrapy_bills - INFO - The work on page608 has finished.
2017-08-31 23:25:59,695 - Task:Scrapy_bills - INFO - The work on page609 has finished.
2017-08-31 23:26:00,593 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation601-610.json
2017-08-31 23:29:59,230 - Task:Scrapy_bills - INFO - The work on page610 has finished.
2017-08-31 23:34:06,288 - Task:Scrapy_bills - INFO - The work on page611 has finished.
2017-08-31 23:38:04,759 - Task:Scrapy_bills - INFO - The work on page612 has finished.
2017-08-31 23:41:57,573 - Task:Scrapy_bills - INFO - The work on page613 has finished.
2017-08-31 23:45:54,738 - Task:Scrapy_bills - INFO - The work on page614 has finished.
2017-08-31 23:49:50,627 - Task:Scrapy_bills - INFO - The work on page615 has finished.
2017-08-31 23:54:09,573 - Task:Scrapy_bills - INFO - The work on page616 has finished.
2017-08-31 23:58:47,883 - Task:Scrapy_bills - INFO - The work on page617 has finished.
2017-09-01 00:02:54,388 - Task:Scrapy_bills - INFO - The work on page618 has finished.
2017-09-01 00:06:55,976 - Task:Scrapy_bills - INFO - The work on page619 has finished.
2017-09-01 00:06:56,947 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation611-620.json
2017-09-01 00:11:02,031 - Task:Scrapy_bills - INFO - The work on page620 has finished.
2017-09-01 00:15:05,820 - Task:Scrapy_bills - INFO - The work on page621 has finished.
2017-09-01 00:19:17,473 - Task:Scrapy_bills - INFO - The work on page622 has finished.
2017-09-01 00:23:34,386 - Task:Scrapy_bills - INFO - The work on page623 has finished.
2017-09-01 00:27:45,215 - Task:Scrapy_bills - INFO - The work on page624 has finished.
2017-09-01 00:31:53,328 - Task:Scrapy_bills - INFO - The work on page625 has finished.
2017-09-01 00:36:06,176 - Task:Scrapy_bills - INFO - The work on page626 has finished.
2017-09-01 00:40:13,074 - Task:Scrapy_bills - INFO - The work on page627 has finished.
2017-09-01 00:44:28,247 - Task:Scrapy_bills - INFO - The work on page628 has finished.
2017-09-01 00:48:42,321 - Task:Scrapy_bills - INFO - The work on page629 has finished.
2017-09-01 00:48:43,323 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation621-630.json
2017-09-01 00:52:43,278 - Task:Scrapy_bills - INFO - The work on page630 has finished.
2017-09-01 00:56:38,553 - Task:Scrapy_bills - INFO - The work on page631 has finished.
2017-09-01 01:00:34,268 - Task:Scrapy_bills - INFO - The work on page632 has finished.
2017-09-01 01:04:31,842 - Task:Scrapy_bills - INFO - The work on page633 has finished.
2017-09-01 01:08:29,586 - Task:Scrapy_bills - INFO - The work on page634 has finished.
2017-09-01 01:12:30,421 - Task:Scrapy_bills - INFO - The work on page635 has finished.
2017-09-01 01:16:34,306 - Task:Scrapy_bills - INFO - The work on page636 has finished.
2017-09-01 01:20:36,319 - Task:Scrapy_bills - INFO - The work on page637 has finished.
2017-09-01 01:24:32,816 - Task:Scrapy_bills - INFO - The work on page638 has finished.
2017-09-01 01:28:31,840 - Task:Scrapy_bills - INFO - The work on page639 has finished.
2017-09-01 01:28:32,858 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation631-640.json
2017-09-01 01:32:28,827 - Task:Scrapy_bills - INFO - The work on page640 has finished.
2017-09-01 01:36:24,826 - Task:Scrapy_bills - INFO - The work on page641 has finished.
2017-09-01 01:40:27,721 - Task:Scrapy_bills - INFO - The work on page642 has finished.
2017-09-01 01:44:26,845 - Task:Scrapy_bills - INFO - The work on page643 has finished.
2017-09-01 01:48:22,678 - Task:Scrapy_bills - INFO - The work on page644 has finished.
2017-09-01 01:52:22,682 - Task:Scrapy_bills - INFO - The work on page645 has finished.
2017-09-01 01:56:22,665 - Task:Scrapy_bills - INFO - The work on page646 has finished.
2017-09-01 02:00:32,965 - Task:Scrapy_bills - INFO - The work on page647 has finished.
2017-09-01 02:04:32,924 - Task:Scrapy_bills - INFO - The work on page648 has finished.
2017-09-01 02:08:37,505 - Task:Scrapy_bills - INFO - The work on page649 has finished.
2017-09-01 02:08:38,508 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation641-650.json
2017-09-01 02:12:35,607 - Task:Scrapy_bills - INFO - The work on page650 has finished.
2017-09-01 02:16:28,589 - Task:Scrapy_bills - INFO - The work on page651 has finished.
2017-09-01 02:20:20,976 - Task:Scrapy_bills - INFO - The work on page652 has finished.
2017-09-01 02:24:17,986 - Task:Scrapy_bills - INFO - The work on page653 has finished.
2017-09-01 02:28:09,746 - Task:Scrapy_bills - INFO - The work on page654 has finished.
2017-09-01 02:32:02,500 - Task:Scrapy_bills - INFO - The work on page655 has finished.
2017-09-01 02:35:54,133 - Task:Scrapy_bills - INFO - The work on page656 has finished.
2017-09-01 02:39:44,742 - Task:Scrapy_bills - INFO - The work on page657 has finished.
2017-09-01 02:43:32,849 - Task:Scrapy_bills - INFO - The work on page658 has finished.
2017-09-01 02:45:58,064 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 02:45:58,065 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-09-01 02:46:14,257 - Task:Scrapy_bills - INFO - The work on page660 has finished.
2017-09-01 02:46:15,230 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation651-660.json
2017-09-01 02:46:38,956 - Task:Scrapy_bills - INFO - The work on page660 has finished.
2017-09-01 02:46:43,850 - Task:Scrapy_bills - INFO - The work on page661 has finished.
2017-09-01 02:47:18,096 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 02:47:18,096 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 35, in read_code
    data = f.read()
  File "D:\Applications\anaconda3\lib\http\client.py", line 455, in read
    return self._readall_chunked()
  File "D:\Applications\anaconda3\lib\http\client.py", line 558, in _readall_chunked
    chunk_left = self._get_chunk_left()
  File "D:\Applications\anaconda3\lib\http\client.py", line 541, in _get_chunk_left
    chunk_left = self._read_next_chunk_size()
  File "D:\Applications\anaconda3\lib\http\client.py", line 501, in _read_next_chunk_size
    line = self.fp.readline(_MAXLINE + 1)
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

2017-09-01 02:47:32,380 - Task:Scrapy_bills - INFO - The work on page662 has finished.
2017-09-01 02:47:37,653 - Task:Scrapy_bills - INFO - The work on page663 has finished.
2017-09-01 02:50:59,378 - Task:Scrapy_bills - INFO - The work on page664 has finished.
2017-09-01 02:54:52,793 - Task:Scrapy_bills - INFO - The work on page665 has finished.
2017-09-01 02:58:41,986 - Task:Scrapy_bills - INFO - The work on page666 has finished.
2017-09-01 03:02:37,506 - Task:Scrapy_bills - INFO - The work on page667 has finished.
2017-09-01 03:06:29,964 - Task:Scrapy_bills - INFO - The work on page668 has finished.
2017-09-01 03:10:24,801 - Task:Scrapy_bills - INFO - The work on page669 has finished.
2017-09-01 03:10:25,571 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation661-670.json
2017-09-01 03:14:18,419 - Task:Scrapy_bills - INFO - The work on page670 has finished.
2017-09-01 03:18:15,814 - Task:Scrapy_bills - INFO - The work on page671 has finished.
2017-09-01 03:22:07,901 - Task:Scrapy_bills - INFO - The work on page672 has finished.
2017-09-01 03:26:04,527 - Task:Scrapy_bills - INFO - The work on page673 has finished.
2017-09-01 03:30:02,506 - Task:Scrapy_bills - INFO - The work on page674 has finished.
2017-09-01 03:33:55,045 - Task:Scrapy_bills - INFO - The work on page675 has finished.
2017-09-01 03:37:53,268 - Task:Scrapy_bills - INFO - The work on page676 has finished.
2017-09-01 03:41:52,280 - Task:Scrapy_bills - INFO - The work on page677 has finished.
2017-09-01 03:45:50,874 - Task:Scrapy_bills - INFO - The work on page678 has finished.
2017-09-01 03:49:46,969 - Task:Scrapy_bills - INFO - The work on page679 has finished.
2017-09-01 03:49:47,958 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation671-680.json
2017-09-01 03:53:49,443 - Task:Scrapy_bills - INFO - The work on page680 has finished.
2017-09-01 03:57:42,923 - Task:Scrapy_bills - INFO - The work on page681 has finished.
2017-09-01 04:00:57,377 - Task:Scrapy_bills - INFO - The work on page682 has finished.
2017-09-01 04:04:13,426 - Task:Scrapy_bills - INFO - The work on page683 has finished.
2017-09-01 04:07:28,220 - Task:Scrapy_bills - INFO - The work on page684 has finished.
2017-09-01 04:10:49,472 - Task:Scrapy_bills - INFO - The work on page685 has finished.
2017-09-01 04:14:04,641 - Task:Scrapy_bills - INFO - The work on page686 has finished.
2017-09-01 04:17:19,023 - Task:Scrapy_bills - INFO - The work on page687 has finished.
2017-09-01 04:20:33,294 - Task:Scrapy_bills - INFO - The work on page688 has finished.
2017-09-01 04:23:51,615 - Task:Scrapy_bills - INFO - The work on page689 has finished.
2017-09-01 04:23:52,429 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation681-690.json
2017-09-01 04:27:34,757 - Task:Scrapy_bills - INFO - The work on page690 has finished.
2017-09-01 04:31:15,998 - Task:Scrapy_bills - INFO - The work on page691 has finished.
2017-09-01 04:35:02,347 - Task:Scrapy_bills - INFO - The work on page692 has finished.
2017-09-01 04:38:51,153 - Task:Scrapy_bills - INFO - The work on page693 has finished.
2017-09-01 04:42:39,001 - Task:Scrapy_bills - INFO - The work on page694 has finished.
2017-09-01 04:46:25,246 - Task:Scrapy_bills - INFO - The work on page695 has finished.
2017-09-01 04:50:09,101 - Task:Scrapy_bills - INFO - The work on page696 has finished.
2017-09-01 04:53:57,061 - Task:Scrapy_bills - INFO - The work on page697 has finished.
2017-09-01 04:57:49,116 - Task:Scrapy_bills - INFO - The work on page698 has finished.
2017-09-01 05:01:44,817 - Task:Scrapy_bills - INFO - The work on page699 has finished.
2017-09-01 05:01:45,792 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation691-700.json
2017-09-01 05:05:32,740 - Task:Scrapy_bills - INFO - The work on page700 has finished.
2017-09-01 05:09:21,817 - Task:Scrapy_bills - INFO - The work on page701 has finished.
2017-09-01 05:13:07,521 - Task:Scrapy_bills - INFO - The work on page702 has finished.
2017-09-01 05:16:43,630 - Task:Scrapy_bills - INFO - The work on page703 has finished.
2017-09-01 05:20:17,516 - Task:Scrapy_bills - INFO - The work on page704 has finished.
2017-09-01 05:23:51,385 - Task:Scrapy_bills - INFO - The work on page705 has finished.
2017-09-01 05:27:26,556 - Task:Scrapy_bills - INFO - The work on page706 has finished.
2017-09-01 05:30:58,466 - Task:Scrapy_bills - INFO - The work on page707 has finished.
2017-09-01 05:34:35,245 - Task:Scrapy_bills - INFO - The work on page708 has finished.
2017-09-01 05:38:08,583 - Task:Scrapy_bills - INFO - The work on page709 has finished.
2017-09-01 05:38:09,511 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation701-710.json
2017-09-01 05:41:49,507 - Task:Scrapy_bills - INFO - The work on page710 has finished.
2017-09-01 05:45:22,398 - Task:Scrapy_bills - INFO - The work on page711 has finished.
2017-09-01 05:49:04,731 - Task:Scrapy_bills - INFO - The work on page712 has finished.
2017-09-01 05:52:53,238 - Task:Scrapy_bills - INFO - The work on page713 has finished.
2017-09-01 05:56:40,176 - Task:Scrapy_bills - INFO - The work on page714 has finished.
2017-09-01 06:00:25,725 - Task:Scrapy_bills - INFO - The work on page715 has finished.
2017-09-01 06:04:17,171 - Task:Scrapy_bills - INFO - The work on page716 has finished.
2017-09-01 06:08:05,881 - Task:Scrapy_bills - INFO - The work on page717 has finished.
2017-09-01 06:11:55,148 - Task:Scrapy_bills - INFO - The work on page718 has finished.
2017-09-01 06:15:45,508 - Task:Scrapy_bills - INFO - The work on page719 has finished.
2017-09-01 06:15:46,466 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation711-720.json
2017-09-01 06:19:42,145 - Task:Scrapy_bills - INFO - The work on page720 has finished.
2017-09-01 06:23:30,164 - Task:Scrapy_bills - INFO - The work on page721 has finished.
2017-09-01 06:27:22,157 - Task:Scrapy_bills - INFO - The work on page722 has finished.
2017-09-01 06:31:13,764 - Task:Scrapy_bills - INFO - The work on page723 has finished.
2017-09-01 06:35:00,089 - Task:Scrapy_bills - INFO - The work on page724 has finished.
2017-09-01 06:38:53,334 - Task:Scrapy_bills - INFO - The work on page725 has finished.
2017-09-01 06:42:44,306 - Task:Scrapy_bills - INFO - The work on page726 has finished.
2017-09-01 06:46:29,268 - Task:Scrapy_bills - INFO - The work on page727 has finished.
2017-09-01 06:50:15,063 - Task:Scrapy_bills - INFO - The work on page728 has finished.
2017-09-01 06:53:57,556 - Task:Scrapy_bills - INFO - The work on page729 has finished.
2017-09-01 06:53:58,509 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation721-730.json
2017-09-01 06:55:55,895 - Task:Scrapy_bills - INFO - The work on page730 has finished.
2017-09-01 06:57:25,381 - Task:Scrapy_bills - INFO - The work on page731 has finished.
2017-09-01 07:01:14,029 - Task:Scrapy_bills - INFO - The work on page732 has finished.
2017-09-01 07:04:59,753 - Task:Scrapy_bills - INFO - The work on page733 has finished.
2017-09-01 07:08:46,670 - Task:Scrapy_bills - INFO - The work on page734 has finished.
2017-09-01 07:12:32,554 - Task:Scrapy_bills - INFO - The work on page735 has finished.
2017-09-01 07:16:19,349 - Task:Scrapy_bills - INFO - The work on page736 has finished.
2017-09-01 07:20:03,451 - Task:Scrapy_bills - INFO - The work on page737 has finished.
2017-09-01 07:23:40,622 - Task:Scrapy_bills - INFO - The work on page738 has finished.
2017-09-01 07:26:56,002 - Task:Scrapy_bills - INFO - The work on page739 has finished.
2017-09-01 07:26:56,884 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation731-740.json
2017-09-01 07:30:24,379 - Task:Scrapy_bills - INFO - The work on page740 has finished.
2017-09-01 07:33:39,398 - Task:Scrapy_bills - INFO - The work on page741 has finished.
2017-09-01 07:36:52,040 - Task:Scrapy_bills - INFO - The work on page742 has finished.
2017-09-01 07:40:14,524 - Task:Scrapy_bills - INFO - The work on page743 has finished.
2017-09-01 07:43:30,137 - Task:Scrapy_bills - INFO - The work on page744 has finished.
2017-09-01 07:46:49,508 - Task:Scrapy_bills - INFO - The work on page745 has finished.
2017-09-01 07:50:06,523 - Task:Scrapy_bills - INFO - The work on page746 has finished.
2017-09-01 07:53:22,547 - Task:Scrapy_bills - INFO - The work on page747 has finished.
2017-09-01 07:56:41,286 - Task:Scrapy_bills - INFO - The work on page748 has finished.
2017-09-01 07:59:59,646 - Task:Scrapy_bills - INFO - The work on page749 has finished.
2017-09-01 08:00:00,431 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation741-750.json
2017-09-01 08:03:17,866 - Task:Scrapy_bills - INFO - The work on page750 has finished.
2017-09-01 08:06:31,856 - Task:Scrapy_bills - INFO - The work on page751 has finished.
2017-09-01 08:09:45,125 - Task:Scrapy_bills - INFO - The work on page752 has finished.
2017-09-01 08:12:58,838 - Task:Scrapy_bills - INFO - The work on page753 has finished.
2017-09-01 08:16:16,577 - Task:Scrapy_bills - INFO - The work on page754 has finished.
2017-09-01 08:19:32,739 - Task:Scrapy_bills - INFO - The work on page755 has finished.
2017-09-01 08:22:52,701 - Task:Scrapy_bills - INFO - The work on page756 has finished.
2017-09-01 08:26:08,140 - Task:Scrapy_bills - INFO - The work on page757 has finished.
2017-09-01 08:29:23,382 - Task:Scrapy_bills - INFO - The work on page758 has finished.
2017-09-01 08:32:40,760 - Task:Scrapy_bills - INFO - The work on page759 has finished.
2017-09-01 08:32:41,542 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation751-760.json
2017-09-01 08:35:54,160 - Task:Scrapy_bills - INFO - The work on page760 has finished.
2017-09-01 08:39:05,820 - Task:Scrapy_bills - INFO - The work on page761 has finished.
2017-09-01 08:42:18,651 - Task:Scrapy_bills - INFO - The work on page762 has finished.
2017-09-01 08:45:30,286 - Task:Scrapy_bills - INFO - The work on page763 has finished.
2017-09-01 08:48:42,174 - Task:Scrapy_bills - INFO - The work on page764 has finished.
2017-09-01 08:51:55,598 - Task:Scrapy_bills - INFO - The work on page765 has finished.
2017-09-01 08:55:12,666 - Task:Scrapy_bills - INFO - The work on page766 has finished.
2017-09-01 08:58:27,601 - Task:Scrapy_bills - INFO - The work on page767 has finished.
2017-09-01 09:01:42,765 - Task:Scrapy_bills - INFO - The work on page768 has finished.
2017-09-01 09:05:17,843 - Task:Scrapy_bills - INFO - The work on page769 has finished.
2017-09-01 09:05:18,609 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation761-770.json
2017-09-01 09:08:45,665 - Task:Scrapy_bills - INFO - The work on page770 has finished.
2017-09-01 09:12:04,428 - Task:Scrapy_bills - INFO - The work on page771 has finished.
2017-09-01 09:15:37,777 - Task:Scrapy_bills - INFO - The work on page772 has finished.
2017-09-01 09:19:01,553 - Task:Scrapy_bills - INFO - The work on page773 has finished.
2017-09-01 09:22:19,269 - Task:Scrapy_bills - INFO - The work on page774 has finished.
2017-09-01 09:25:44,837 - Task:Scrapy_bills - INFO - The work on page775 has finished.
2017-09-01 09:29:10,073 - Task:Scrapy_bills - INFO - The work on page776 has finished.
2017-09-01 09:32:35,470 - Task:Scrapy_bills - INFO - The work on page777 has finished.
2017-09-01 09:35:50,341 - Task:Scrapy_bills - INFO - The work on page778 has finished.
2017-09-01 09:39:08,059 - Task:Scrapy_bills - INFO - The work on page779 has finished.
2017-09-01 09:39:08,843 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation771-780.json
2017-09-01 09:42:31,797 - Task:Scrapy_bills - INFO - The work on page780 has finished.
2017-09-01 09:45:46,484 - Task:Scrapy_bills - INFO - The work on page781 has finished.
2017-09-01 09:49:05,204 - Task:Scrapy_bills - INFO - The work on page782 has finished.
2017-09-01 09:52:27,327 - Task:Scrapy_bills - INFO - The work on page783 has finished.
2017-09-01 09:55:56,681 - Task:Scrapy_bills - INFO - The work on page784 has finished.
2017-09-01 09:59:15,777 - Task:Scrapy_bills - INFO - The work on page785 has finished.
2017-09-01 10:02:46,934 - Task:Scrapy_bills - INFO - The work on page786 has finished.
2017-09-01 10:06:14,970 - Task:Scrapy_bills - INFO - The work on page787 has finished.
2017-09-01 10:10:07,967 - Task:Scrapy_bills - INFO - The work on page788 has finished.
2017-09-01 10:14:05,232 - Task:Scrapy_bills - INFO - The work on page789 has finished.
2017-09-01 10:14:06,036 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation781-790.json
2017-09-01 10:18:06,863 - Task:Scrapy_bills - INFO - The work on page790 has finished.
2017-09-01 10:21:55,820 - Task:Scrapy_bills - INFO - The work on page791 has finished.
2017-09-01 10:25:54,097 - Task:Scrapy_bills - INFO - The work on page792 has finished.
2017-09-01 10:29:48,570 - Task:Scrapy_bills - INFO - The work on page793 has finished.
2017-09-01 10:33:46,152 - Task:Scrapy_bills - INFO - The work on page794 has finished.
2017-09-01 10:37:40,367 - Task:Scrapy_bills - INFO - The work on page795 has finished.
2017-09-01 10:42:07,865 - Task:Scrapy_bills - INFO - The work on page796 has finished.
2017-09-01 10:46:23,936 - Task:Scrapy_bills - INFO - The work on page797 has finished.
2017-09-01 10:50:47,253 - Task:Scrapy_bills - INFO - The work on page798 has finished.
2017-09-01 10:55:17,535 - Task:Scrapy_bills - INFO - The work on page799 has finished.
2017-09-01 10:55:18,490 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation791-800.json
2017-09-01 10:59:57,091 - Task:Scrapy_bills - INFO - The work on page800 has finished.
2017-09-01 11:04:07,468 - Task:Scrapy_bills - INFO - The work on page801 has finished.
2017-09-01 11:08:09,631 - Task:Scrapy_bills - INFO - The work on page802 has finished.
2017-09-01 11:12:18,205 - Task:Scrapy_bills - INFO - The work on page803 has finished.
2017-09-01 11:16:21,915 - Task:Scrapy_bills - INFO - The work on page804 has finished.
2017-09-01 11:20:36,234 - Task:Scrapy_bills - INFO - The work on page805 has finished.
2017-09-01 11:24:38,257 - Task:Scrapy_bills - INFO - The work on page806 has finished.
2017-09-01 11:28:46,622 - Task:Scrapy_bills - INFO - The work on page807 has finished.
2017-09-01 11:32:57,606 - Task:Scrapy_bills - INFO - The work on page808 has finished.
2017-09-01 11:36:58,642 - Task:Scrapy_bills - INFO - The work on page809 has finished.
2017-09-01 11:36:59,597 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation801-810.json
2017-09-01 11:41:11,470 - Task:Scrapy_bills - INFO - The work on page810 has finished.
2017-09-01 11:45:19,277 - Task:Scrapy_bills - INFO - The work on page811 has finished.
2017-09-01 11:49:34,171 - Task:Scrapy_bills - INFO - The work on page812 has finished.
2017-09-01 11:54:02,587 - Task:Scrapy_bills - INFO - The work on page813 has finished.
2017-09-01 11:58:24,286 - Task:Scrapy_bills - INFO - The work on page814 has finished.
2017-09-01 12:02:43,159 - Task:Scrapy_bills - INFO - The work on page815 has finished.
2017-09-01 12:06:55,968 - Task:Scrapy_bills - INFO - The work on page816 has finished.
2017-09-01 12:11:08,382 - Task:Scrapy_bills - INFO - The work on page817 has finished.
2017-09-01 12:15:14,332 - Task:Scrapy_bills - INFO - The work on page818 has finished.
2017-09-01 12:19:23,279 - Task:Scrapy_bills - INFO - The work on page819 has finished.
2017-09-01 12:19:24,209 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation811-820.json
2017-09-01 12:23:39,842 - Task:Scrapy_bills - INFO - The work on page820 has finished.
2017-09-01 12:27:50,606 - Task:Scrapy_bills - INFO - The work on page821 has finished.
2017-09-01 12:31:57,437 - Task:Scrapy_bills - INFO - The work on page822 has finished.
2017-09-01 12:36:13,577 - Task:Scrapy_bills - INFO - The work on page823 has finished.
2017-09-01 12:40:19,286 - Task:Scrapy_bills - INFO - The work on page824 has finished.
2017-09-01 12:44:23,667 - Task:Scrapy_bills - INFO - The work on page825 has finished.
2017-09-01 12:48:49,838 - Task:Scrapy_bills - INFO - The work on page826 has finished.
2017-09-01 12:51:27,128 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:51:27,129 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 47, in <module>
    data = sm.bills_process(elem)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 79, in bills_process
    all_information=str(self.read_code(all_infor_url))#when use  write bs(,'lxml')
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1257, in do_open
    r = h.getresponse()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1197, in getresponse
    response.begin()
  File "D:\Applications\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Applications\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Applications\anaconda3\lib\socket.py", line 575, in readinto
    return self._sock.recv_into(b)
  File "D:\Applications\anaconda3\lib\ssl.py", line 929, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 791, in read
    return self._sslobj.read(len, buffer)
  File "D:\Applications\anaconda3\lib\ssl.py", line 575, in read
    v = self._sslobj.read(len, buffer)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

2017-09-01 12:51:49,135 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:51:49,136 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:51:59,138 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:51:59,139 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:52:21,143 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:52:21,144 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:52:43,149 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:52:43,151 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:52:53,151 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:52:53,152 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:53:15,157 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:53:15,158 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:53:25,158 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:53:25,159 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:53:47,162 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:53:47,163 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:53:57,164 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:53:57,165 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:54:07,166 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:54:07,167 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:54:17,170 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:54:17,171 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:54:39,174 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:54:39,175 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:54:49,175 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:54:49,176 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:54:59,177 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:54:59,178 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:55:11,181 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:55:11,182 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:55:33,186 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:55:33,187 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:55:43,188 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:55:43,189 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:56:05,193 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:56:05,194 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:56:27,199 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:56:27,200 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:56:49,205 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:56:49,206 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:56:59,206 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:56:59,207 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:57:21,212 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:57:21,213 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:57:31,213 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:57:31,214 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:57:53,220 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:57:53,221 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:58:03,222 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:58:03,223 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:58:25,228 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:58:25,229 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:58:47,234 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:58:47,235 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:58:57,235 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:58:57,236 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:07,236 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:07,238 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:17,241 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:17,243 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:27,244 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:27,245 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:37,246 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:37,247 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:47,247 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:47,248 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 12:59:57,249 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 12:59:57,251 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:07,252 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:07,253 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:17,254 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:17,255 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:27,257 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:27,258 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:37,258 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:37,259 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:47,263 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:47,264 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:00:57,264 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:00:57,265 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:01:07,266 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 13:01:07,267 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1254, in do_open
    h.request(req.get_method(), req.selector, req.data, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1151, in _send_request
    self.endheaders(body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "D:\Applications\anaconda3\lib\http\client.py", line 934, in _send_output
    self.send(msg)
  File "D:\Applications\anaconda3\lib\http\client.py", line 877, in send
    self.connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 1252, in connect
    super().connect()
  File "D:\Applications\anaconda3\lib\http\client.py", line 849, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "D:\Applications\anaconda3\lib\socket.py", line 693, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "D:\Applications\anaconda3\lib\socket.py", line 732, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 41, in <module>
    soup = sm.read_code(url)
  File "D:\project\graph embedding\scrapy\util_scrapy.py", line 34, in read_code
    f = urllib.request.urlopen(req, timeout=30)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 163, in urlopen
    return opener.open(url, data, timeout)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 466, in open
    response = self._open(req, data)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 484, in _open
    '_open', req)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 444, in _call_chain
    result = func(*args)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1297, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "D:\Applications\anaconda3\lib\urllib\request.py", line 1256, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>

2017-09-01 13:01:34,529 - Task:Scrapy_bills - INFO - The work on page828 has finished.
2017-09-01 13:06:13,201 - Task:Scrapy_bills - INFO - The work on page829 has finished.
2017-09-01 13:06:14,116 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation821-830.json
2017-09-01 13:10:52,821 - Task:Scrapy_bills - INFO - The work on page830 has finished.
2017-09-01 13:15:34,257 - Task:Scrapy_bills - INFO - The work on page831 has finished.
2017-09-01 13:20:14,675 - Task:Scrapy_bills - INFO - The work on page832 has finished.
2017-09-01 13:24:56,004 - Task:Scrapy_bills - INFO - The work on page833 has finished.
2017-09-01 13:29:23,162 - Task:Scrapy_bills - INFO - The work on page834 has finished.
2017-09-01 13:33:44,633 - Task:Scrapy_bills - INFO - The work on page835 has finished.
2017-09-01 13:37:56,033 - Task:Scrapy_bills - INFO - The work on page836 has finished.
2017-09-01 13:42:27,659 - Task:Scrapy_bills - INFO - The work on page837 has finished.
2017-09-01 13:46:49,373 - Task:Scrapy_bills - INFO - The work on page838 has finished.
2017-09-01 13:51:12,779 - Task:Scrapy_bills - INFO - The work on page839 has finished.
2017-09-01 13:51:13,857 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation831-840.json
2017-09-01 13:55:43,448 - Task:Scrapy_bills - INFO - The work on page840 has finished.
2017-09-01 13:59:45,572 - Task:Scrapy_bills - INFO - The work on page841 has finished.
2017-09-01 14:04:00,246 - Task:Scrapy_bills - INFO - The work on page842 has finished.
2017-09-01 14:08:03,558 - Task:Scrapy_bills - INFO - The work on page843 has finished.
2017-09-01 14:12:15,193 - Task:Scrapy_bills - INFO - The work on page844 has finished.
2017-09-01 14:16:36,322 - Task:Scrapy_bills - INFO - The work on page845 has finished.
2017-09-01 14:20:43,235 - Task:Scrapy_bills - INFO - The work on page846 has finished.
2017-09-01 14:24:56,711 - Task:Scrapy_bills - INFO - The work on page847 has finished.
2017-09-01 14:29:52,724 - Task:Scrapy_bills - INFO - The work on page848 has finished.
2017-09-01 14:34:01,300 - Task:Scrapy_bills - INFO - The work on page849 has finished.
2017-09-01 14:34:02,519 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation841-850.json
2017-09-01 14:38:10,152 - Task:Scrapy_bills - INFO - The work on page850 has finished.
2017-09-01 14:42:19,606 - Task:Scrapy_bills - INFO - The work on page851 has finished.
2017-09-01 14:46:26,072 - Task:Scrapy_bills - INFO - The work on page852 has finished.
2017-09-01 14:50:40,401 - Task:Scrapy_bills - INFO - The work on page853 has finished.
2017-09-01 14:54:53,983 - Task:Scrapy_bills - INFO - The work on page854 has finished.
2017-09-01 14:59:03,579 - Task:Scrapy_bills - INFO - The work on page855 has finished.
2017-09-01 15:03:21,054 - Task:Scrapy_bills - INFO - The work on page856 has finished.
2017-09-01 15:07:52,517 - Task:Scrapy_bills - INFO - The work on page857 has finished.
2017-09-01 15:12:26,930 - Task:Scrapy_bills - INFO - The work on page858 has finished.
2017-09-01 15:17:23,550 - Task:Scrapy_bills - INFO - The work on page859 has finished.
2017-09-01 15:17:24,812 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation851-860.json
2017-09-01 15:22:19,606 - Task:Scrapy_bills - INFO - The work on page860 has finished.
2017-09-01 15:23:33,251 - Task:Scrapy_bills - WARNING - Something wrong with network
2017-09-01 15:23:33,252 - Task:Scrapy_bills - ERROR - Traceback (most recent call last):
  File "<ipython-input-2-44b4e11eec0e>", line 48, in <module>
    print(data['number'])
TypeError: 'NoneType' object is not subscriptable

2017-09-01 15:23:51,532 - Task:Scrapy_bills - INFO - The work on page862 has finished.
2017-09-01 15:23:59,719 - Task:Scrapy_bills - INFO - The work on page863 has finished.
2017-09-01 15:24:06,597 - Task:Scrapy_bills - INFO - The work on page864 has finished.
2017-09-01 15:24:13,603 - Task:Scrapy_bills - INFO - The work on page865 has finished.
2017-09-01 15:25:22,606 - Task:Scrapy_bills - INFO - The work on page866 has finished.
2017-09-01 15:29:42,819 - Task:Scrapy_bills - INFO - The work on page867 has finished.
2017-09-01 15:34:09,985 - Task:Scrapy_bills - INFO - The work on page868 has finished.
2017-09-01 15:38:43,476 - Task:Scrapy_bills - INFO - The work on page869 has finished.
2017-09-01 15:38:44,288 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation861-870.json
2017-09-01 15:43:22,053 - Task:Scrapy_bills - INFO - The work on page870 has finished.
2017-09-01 15:47:35,950 - Task:Scrapy_bills - INFO - The work on page871 has finished.
2017-09-01 15:52:04,127 - Task:Scrapy_bills - INFO - The work on page872 has finished.
2017-09-01 15:57:02,444 - Task:Scrapy_bills - INFO - The work on page873 has finished.
2017-09-01 16:02:07,026 - Task:Scrapy_bills - INFO - The work on page874 has finished.
2017-09-01 16:07:04,707 - Task:Scrapy_bills - INFO - The work on page875 has finished.
2017-09-01 16:12:07,318 - Task:Scrapy_bills - INFO - The work on page876 has finished.
2017-09-01 16:17:11,709 - Task:Scrapy_bills - INFO - The work on page877 has finished.
2017-09-01 16:22:10,884 - Task:Scrapy_bills - INFO - The work on page878 has finished.
2017-09-01 16:27:18,575 - Task:Scrapy_bills - INFO - The work on page879 has finished.
2017-09-01 16:27:19,653 - Task:Scrapy_bills - INFO - Successfully save the file in ./database_all/legislation871-880.json
2017-09-01 16:32:28,267 - Task:Scrapy_bills - INFO - The work on page880 has finished.
2017-09-01 16:38:03,388 - Task:Scrapy_bills - INFO - The work on page881 has finished.
2017-09-01 16:40:39,093 - Task:Scrapy_bills - WARNING - Something wrong with network
